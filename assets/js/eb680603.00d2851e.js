"use strict";(self.webpackChunklinkis_web_apache=self.webpackChunklinkis_web_apache||[]).push([[54150],{3905:(t,e,a)=>{a.d(e,{Zo:()=>d,kt:()=>k});var n=a(67294);function r(t,e,a){return e in t?Object.defineProperty(t,e,{value:a,enumerable:!0,configurable:!0,writable:!0}):t[e]=a,t}function l(t,e){var a=Object.keys(t);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(t);e&&(n=n.filter((function(e){return Object.getOwnPropertyDescriptor(t,e).enumerable}))),a.push.apply(a,n)}return a}function i(t){for(var e=1;e<arguments.length;e++){var a=null!=arguments[e]?arguments[e]:{};e%2?l(Object(a),!0).forEach((function(e){r(t,e,a[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(t,Object.getOwnPropertyDescriptors(a)):l(Object(a)).forEach((function(e){Object.defineProperty(t,e,Object.getOwnPropertyDescriptor(a,e))}))}return t}function o(t,e){if(null==t)return{};var a,n,r=function(t,e){if(null==t)return{};var a,n,r={},l=Object.keys(t);for(n=0;n<l.length;n++)a=l[n],e.indexOf(a)>=0||(r[a]=t[a]);return r}(t,e);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(t);for(n=0;n<l.length;n++)a=l[n],e.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(t,a)&&(r[a]=t[a])}return r}var p=n.createContext({}),s=function(t){var e=n.useContext(p),a=e;return t&&(a="function"==typeof t?t(e):i(i({},e),t)),a},d=function(t){var e=s(t.components);return n.createElement(p.Provider,{value:e},t.children)},m="mdxType",u={inlineCode:"code",wrapper:function(t){var e=t.children;return n.createElement(n.Fragment,{},e)}},g=n.forwardRef((function(t,e){var a=t.components,r=t.mdxType,l=t.originalType,p=t.parentName,d=o(t,["components","mdxType","originalType","parentName"]),m=s(a),g=r,k=m["".concat(p,".").concat(g)]||m[g]||u[g]||l;return a?n.createElement(k,i(i({ref:e},d),{},{components:a})):n.createElement(k,i({ref:e},d))}));function k(t,e){var a=arguments,r=e&&e.mdxType;if("string"==typeof t||r){var l=a.length,i=new Array(l);i[0]=g;var o={};for(var p in e)hasOwnProperty.call(e,p)&&(o[p]=e[p]);o.originalType=t,o[m]="string"==typeof t?t:r,i[1]=o;for(var s=2;s<l;s++)i[s]=a[s];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}g.displayName="MDXCreateElement"},96626:(t,e,a)=>{a.r(e),a.d(e,{assets:()=>p,contentTitle:()=>i,default:()=>u,frontMatter:()=>l,metadata:()=>o,toc:()=>s});var n=a(87462),r=(a(67294),a(3905));const l={title:"Sqoop Engine",sidebar_position:9},i=void 0,o={unversionedId:"engine-usage/sqoop",id:"version-1.5.0/engine-usage/sqoop",title:"Sqoop Engine",description:"This article mainly introduces the installation, usage and configuration of the Sqoop engine plugin in Linkis.",source:"@site/versioned_docs/version-1.5.0/engine-usage/sqoop.md",sourceDirName:"engine-usage",slug:"/engine-usage/sqoop",permalink:"/docs/latest/engine-usage/sqoop",draft:!1,editUrl:"https://github.com/apache/linkis-website/edit/dev/versioned_docs/version-1.5.0/engine-usage/sqoop.md",tags:[],version:"1.5.0",sidebarPosition:9,frontMatter:{title:"Sqoop Engine",sidebar_position:9},sidebar:"version-1.5.0/tutorialSidebar",previous:{title:"OpenLooKeng Engine",permalink:"/docs/latest/engine-usage/openlookeng"},next:{title:"Pipeline Engine",permalink:"/docs/latest/engine-usage/pipeline"}},p={},s=[{value:"1. Preliminary work",id:"1-preliminary-work",level:2},{value:"1.1 Environment Installation",id:"11-environment-installation",level:3},{value:"1.2 Environment verification",id:"12-environment-verification",level:3},{value:"2. Engine plugin deployment",id:"2-engine-plugin-deployment",level:2},{value:"2.1 Engine plugin preparation (choose one) non-default engine",id:"21-engine-plugin-preparation-choose-one-non-default-engine",level:3},{value:"2.2 Upload and load engine plugins",id:"22-upload-and-load-engine-plugins",level:3},{value:"2.3 Engine refresh",id:"23-engine-refresh",level:3},{value:"2.3.1 Restart and refresh",id:"231-restart-and-refresh",level:4},{value:"2.3.2 Check if the engine is refreshed successfully",id:"232-check-if-the-engine-is-refreshed-successfully",level:3},{value:"3 <code>Sqoop</code> engine usage",id:"3-sqoop-engine-usage",level:2},{value:"3.1 Submitting tasks via <code>Linkis-cli</code>",id:"31-submitting-tasks-via-linkis-cli",level:3},{value:"3.1.1 <code>hdfs</code> file export to <code>mysql</code>",id:"311-hdfs-file-export-to-mysql",level:4},{value:"3.1.2 <code>mysql</code> data import to <code>hive</code> library",id:"312-mysql-data-import-to-hive-library",level:4},{value:"3.2 Submit tasks through <code>OnceEngineConn</code>",id:"32-submit-tasks-through-onceengineconn",level:3},{value:"4 Engine configuration instructions",id:"4-engine-configuration-instructions",level:2},{value:"4.1 Default Configuration Description",id:"41-default-configuration-description",level:3},{value:"4.2 Import and export parameters",id:"42-import-and-export-parameters",level:3},{value:"4.3 Import control parameters",id:"43-import-control-parameters",level:3},{value:"4.4 Incremental import parameters",id:"44-incremental-import-parameters",level:3},{value:"4.5 Output line formatting parameters",id:"45-output-line-formatting-parameters",level:3},{value:"4.6 Input parsing parameters",id:"46-input-parsing-parameters",level:3},{value:"4.7 <code>Hive</code> parameters",id:"47-hive-parameters",level:3},{value:"4.8 <code>HBase</code> parameters",id:"48-hbase-parameters",level:3},{value:"4.9 <code>HCatalog</code> parameters",id:"49-hcatalog-parameters",level:3},{value:"4.10 <code>Accumulo</code> parameters",id:"410-accumulo-parameters",level:3},{value:"4.11 Code Generation Parameters",id:"411-code-generation-parameters",level:3},{value:"4.12 Generic <code>Hadoop</code> command line arguments",id:"412-generic-hadoop-command-line-arguments",level:3}],d={toc:s},m="wrapper";function u(t){let{components:e,...a}=t;return(0,r.kt)(m,(0,n.Z)({},d,a,{components:e,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"This article mainly introduces the installation, usage and configuration of the ",(0,r.kt)("inlineCode",{parentName:"p"},"Sqoop")," engine plugin in ",(0,r.kt)("inlineCode",{parentName:"p"},"Linkis"),"."),(0,r.kt)("h2",{id:"1-preliminary-work"},"1. Preliminary work"),(0,r.kt)("h3",{id:"11-environment-installation"},"1.1 Environment Installation"),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"Sqoop")," engine mainly depends on the ",(0,r.kt)("inlineCode",{parentName:"p"},"Hadoop")," basic environment. If the node needs to deploy the ",(0,r.kt)("inlineCode",{parentName:"p"},"Sqoop")," engine, you need to deploy the ",(0,r.kt)("inlineCode",{parentName:"p"},"Hadoop")," client environment, and ","![Download]","(",(0,r.kt)("a",{parentName:"p",href:"https://archive.apache.org/dist/sqoop"},"https://archive.apache.org/dist/sqoop")," /) Install the ",(0,r.kt)("inlineCode",{parentName:"p"},"Sqoop")," client."),(0,r.kt)("h3",{id:"12-environment-verification"},"1.2 Environment verification"),(0,r.kt)("p",null,"Before executing the ",(0,r.kt)("inlineCode",{parentName:"p"},"Sqoop")," task, use the native ",(0,r.kt)("inlineCode",{parentName:"p"},"Sqoop")," to execute the test task on the node to check whether the node environment is normal."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"#Verify whether the sqoop environment is available Reference example: Import the /user/hive/warehouse/hadoop/test_linkis_sqoop file data of hdfs into the mysql table test_sqoop\n\nsqoop export \\\n--connect jdbc:mysql://10.10.10.10/test \\\n--username test \\\n--password test123\\\n--table test_sqoop \\\n--columns user_id,user_code,user_name,email,status \\\n--export-dir /user/hive/warehouse/hadoop/test_linkis_sqoop \\\n--update-mode allowinsert \\\n--verbose ;\n")),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Environment variable name"),(0,r.kt)("th",{parentName:"tr",align:null},"Environment variable content"),(0,r.kt)("th",{parentName:"tr",align:null},"Remarks"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"JAVA_HOME"),(0,r.kt)("td",{parentName:"tr",align:null},"JDK installation path"),(0,r.kt)("td",{parentName:"tr",align:null},"Required")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"HADOOP_HOME"),(0,r.kt)("td",{parentName:"tr",align:null},"Hadoop installation path"),(0,r.kt)("td",{parentName:"tr",align:null},"Required")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"HADOOP_CONF_DIR"),(0,r.kt)("td",{parentName:"tr",align:null},"Hadoop configuration path"),(0,r.kt)("td",{parentName:"tr",align:null},"required")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"SQOOP_HOME"),(0,r.kt)("td",{parentName:"tr",align:null},"Sqoop installation path"),(0,r.kt)("td",{parentName:"tr",align:null},"Required")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"SQOOP_CONF_DIR"),(0,r.kt)("td",{parentName:"tr",align:null},"Sqoop configuration path"),(0,r.kt)("td",{parentName:"tr",align:null},"not required")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"HCAT_HOME"),(0,r.kt)("td",{parentName:"tr",align:null},"HCAT configuration path"),(0,r.kt)("td",{parentName:"tr",align:null},"not required")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"HBASE_HOME"),(0,r.kt)("td",{parentName:"tr",align:null},"HBASE configuration path"),(0,r.kt)("td",{parentName:"tr",align:null},"not required")))),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Linkis System Parameters"),(0,r.kt)("th",{parentName:"tr",align:null},"Parameters"),(0,r.kt)("th",{parentName:"tr",align:null},"Remarks"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"wds.linkis.hadoop.site.xml"),(0,r.kt)("td",{parentName:"tr",align:null},"Set sqoop to load hadoop parameter file location"),(0,r.kt)("td",{parentName:"tr",align:null},'Generally, no separate configuration is required, the default value is "core-site.xml;hdfs-site.xml;yarn-site.xml;mapred-site. xml"')),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.fetch.status.interval"),(0,r.kt)("td",{parentName:"tr",align:null},"Set the interval for obtaining sqoop execution status"),(0,r.kt)("td",{parentName:"tr",align:null},"Generally, no separate configuration is required, the default value is 5s")))),(0,r.kt)("h2",{id:"2-engine-plugin-deployment"},"2. Engine plugin deployment"),(0,r.kt)("h3",{id:"21-engine-plugin-preparation-choose-one-non-default-engine"},"2.1 Engine plugin preparation (choose one) ",(0,r.kt)("a",{parentName:"h3",href:"/docs/latest/engine-usage/overview"},"non-default engine")),(0,r.kt)("p",null,"Method 1: Download the engine plug-in package directly"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://linkis.apache.org/zh-CN/blog/2022/04/15/how-to-download-engineconn-plugin"},"Linkis Engine Plugin Download")),(0,r.kt)("p",null,"Method 2: Compile the engine plug-in separately (requires a ",(0,r.kt)("inlineCode",{parentName:"p"},"maven")," environment)"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"# compile\ncd ${linkis_code_dir}/linkis-engineconn-plugins/sqoop/\nmvn clean install\n# The compiled engine plug-in package is located in the following directory\n${linkis_code_dir}/linkis-engineconn-plugins/sqoop/target/out/\n")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"/docs/latest/deployment/install-engineconn"},"EngineConnPlugin engine plugin installation")),(0,r.kt)("h3",{id:"22-upload-and-load-engine-plugins"},"2.2 Upload and load engine plugins"),(0,r.kt)("p",null,"Upload the engine package in 2.1 to the engine directory of the server"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"${LINKIS_HOME}/lib/linkis-engineconn-plugins\n")),(0,r.kt)("p",null,"The directory structure after uploading is as follows"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"linkis-engineconn-plugins/\n\u251c\u2500\u2500 sqoop\n\u2502 \u251c\u2500\u2500 dist\n\u2502 \u2502 \u2514\u2500\u2500 1.4.6\n\u2502 \u2502 \u251c\u2500\u2500 conf\n\u2502 \u2502 \u2514\u2500\u2500 lib\n\u2502 \u2514\u2500\u2500 plugin\n\u2502 \u2514\u2500\u2500 1.4.6\n")),(0,r.kt)("h3",{id:"23-engine-refresh"},"2.3 Engine refresh"),(0,r.kt)("h4",{id:"231-restart-and-refresh"},"2.3.1 Restart and refresh"),(0,r.kt)("p",null,"Refresh the engine by restarting the ",(0,r.kt)("inlineCode",{parentName:"p"},"linkis-cg-linkismanager")," service"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"cd ${LINKIS_HOME}/sbin\nsh linkis-daemon.sh restart cg-linkismanager\n")),(0,r.kt)("h3",{id:"232-check-if-the-engine-is-refreshed-successfully"},"2.3.2 Check if the engine is refreshed successfully"),(0,r.kt)("p",null,"You can check whether the ",(0,r.kt)("inlineCode",{parentName:"p"},"last_update_time")," of the ",(0,r.kt)("inlineCode",{parentName:"p"},"linkis_engine_conn_plugin_bml_resources")," table in the database is the time to trigger the refresh."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"#Login to the `linkis` database\nselect * from linkis_cg_engine_conn_plugin_bml_resources;\n")),(0,r.kt)("h2",{id:"3-sqoop-engine-usage"},"3 ",(0,r.kt)("inlineCode",{parentName:"h2"},"Sqoop")," engine usage"),(0,r.kt)("h3",{id:"31-submitting-tasks-via-linkis-cli"},"3.1 Submitting tasks via ",(0,r.kt)("inlineCode",{parentName:"h3"},"Linkis-cli")),(0,r.kt)("h4",{id:"311-hdfs-file-export-to-mysql"},"3.1.1 ",(0,r.kt)("inlineCode",{parentName:"h4"},"hdfs")," file export to ",(0,r.kt)("inlineCode",{parentName:"h4"},"mysql")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"sh linkis-cli-sqoop export \\\n-D mapreduce.job.queuename=ide\\\n--connect jdbc:mysql://10.10.10.10:9600/testdb\\\n--username password@123 \\\n--password password@123 \\\n--table test_sqoop_01_copy \\\n--columns user_id,user_code,user_name,email,status \\\n--export-dir /user/hive/warehouse/hadoop/test_linkis_sqoop_2 \\\n--update-mode allowinsert --verbose ;  \n")),(0,r.kt)("h4",{id:"312-mysql-data-import-to-hive-library"},"3.1.2 ",(0,r.kt)("inlineCode",{parentName:"h4"},"mysql")," data import to ",(0,r.kt)("inlineCode",{parentName:"h4"},"hive")," library"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"`mysql` is imported into `hive` library `linkis_test_ind.test_import_sqoop_1`, table `test_import_sqoop_1` does not exist, need to add parameter `--create-hive-table`\n\nsh linkis-cli-sqoop import -D mapreduce.job.queuename=dws\\\n--connect jdbc:mysql://10.10.10.10:3306/casion_test\\\n--username hadoop\\\n--password password@123 \\\n--table test_sqoop_01 \\\n--columns user_id,user_code,user_name,email,status \\\n--fields-terminated-by ',' \\\n--hive-import --create-hive-table \\\n--hive-database casionxia_ind\\\n--hive-table test_import_sqoop_1 \\\n--hive-drop-import-delims \\\n--delete-target-dir \\\n--input-null-non-string '\\\\N' \\\n--input-null-string '\\\\N' \\\n--verbose ;\n\n\n`mysql` is imported into the `hive` library `linkis_test_ind.test_import_sqoop_1`, the table `test_import_sqoop_1` exists to remove the parameter `--create-hive-table`\n\nsh linkis-cli-sqoop import -D mapreduce.job.queuename=dws\\\n--connect jdbc:mysql://10.10.10.10:9600/testdb\\\n--username testdb \\\n--password password@123 \\\n--table test_sqoop_01 \\\n--columns user_id,user_code,user_name,email,status \\\n--fields-terminated-by ',' \\\n--hive-import \\\n--hive-database linkis_test_ind \\\n--hive-table test_import_sqoop_1 \\\n--hive-overwrite \\\n--hive-drop-import-delims \\\n--delete-target-dir \\\n--input-null-non-string '\\\\N' \\\n--input-null-string '\\\\N' \\\n--verbose ;\n\n")),(0,r.kt)("h3",{id:"32-submit-tasks-through-onceengineconn"},"3.2 Submit tasks through ",(0,r.kt)("inlineCode",{parentName:"h3"},"OnceEngineConn")),(0,r.kt)("p",null,"The usage of ",(0,r.kt)("inlineCode",{parentName:"p"},"OnceEngineConn")," is to call the ",(0,r.kt)("inlineCode",{parentName:"p"},"createEngineConn")," interface of ",(0,r.kt)("inlineCode",{parentName:"p"},"LinkisManager")," through ",(0,r.kt)("inlineCode",{parentName:"p"},"LinkisManagerClient"),", and send the code to the created ",(0,r.kt)("inlineCode",{parentName:"p"},"Sqoop")," engine, and then the ",(0,r.kt)("inlineCode",{parentName:"p"},"Sqoop")," engine starts to execute, which can be performed by other systems. Calls such as ",(0,r.kt)("inlineCode",{parentName:"p"},"Exchangeis"),". The usage of ",(0,r.kt)("inlineCode",{parentName:"p"},"Client")," is also very simple, first create a ",(0,r.kt)("inlineCode",{parentName:"p"},"maven")," project, or introduce the following dependencies into your project"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-xml"},"<dependency>\n    <groupId>org.apache.linkis</groupId>\n    <artifactId>linkis-computation-client</artifactId>\n    <version>${linkis.version}</version>\n</dependency>\n")),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Test case:")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-java"},'\nimport java.util.concurrent.TimeUnit\n\nimport java.util\n\nimport org.apache.linkis.computation.client.LinkisJobBuilder\nimport org.apache.linkis.computation.client.once.simple.{SimpleOnceJob, SimpleOnceJobBuilder, SubmittableSimpleOnceJob}\nimport org.apache.linkis.computation.client.operator.impl.{EngineConnLogOperator, EngineConnMetricsOperator, EngineConnProgressOperator}\nimport org.apache.linkis.computation.client.utils.LabelKeyUtils\n\nimport scala.collection.JavaConverters._\n\nobject SqoopOnceJobTest extends App {\n  LinkisJobBuilder.setDefaultServerUrl("http://127.0.0.1:9001")\n  val logPath = "C:\\\\Users\\\\resources\\\\log4j.properties"\n  System.setProperty("log4j.configurationFile", logPath)\n  val startUpMap = new util. HashMap[String, Any]\n  startUpMap.put("wds.linkis.engineconn.java.driver.memory", "1g")\n   val builder = SimpleOnceJob. builder(). setCreateService("Linkis-Client")\n     .addLabel(LabelKeyUtils.ENGINE_TYPE_LABEL_KEY, "sqoop-1.4.6")\n     .addLabel(LabelKeyUtils.USER_CREATOR_LABEL_KEY, "Client")\n     .addLabel(LabelKeyUtils.ENGINE_CONN_MODE_LABEL_KEY, "once")\n     .setStartupParams(startUpMap)\n     .setMaxSubmitTime(30000)\n     .addExecuteUser("freeuser")\n  val onceJob = importJob(builder)\n  val time = System. currentTimeMillis()\n  onceJob.submit()\n\n  println(onceJob. getId)\n  val logOperator = onceJob.getOperator(EngineConnLogOperator.OPERATOR_NAME).asInstanceOf[EngineConnLogOperator]\n  println(onceJob.getECMServiceInstance)\n  logOperator.setFromLine(0)\n  logOperator.setECMServiceInstance(onceJob.getECMServiceInstance)\n  logOperator.setEngineConnType("sqoop")\n  logOperator.setIgnoreKeywords("[main],[SpringContextShutdownHook]")\n  var progressOperator = onceJob.getOperator(EngineConnProgressOperator.OPERATOR_NAME).asInstanceOf[EngineConnProgressOperator]\n  var metricOperator = onceJob.getOperator(EngineConnMetricsOperator.OPERATOR_NAME).asInstanceOf[EngineConnMetricsOperator]\n  var end = false\n  var rowBefore = 1\n  while (!end || rowBefore > 0){\n       if(onceJob.isCompleted) {\n         end = true\n         metricOperator = null\n       }\n      logOperator.setPageSize(100)\n      Utils. tryQuietly{\n        val logs = logOperator.apply()\n        logs.logs.asScala.foreach( log => {\n          println(log)\n        })\n        rowBefore = logs. logs. size\n    }\n    Thread.sleep(3000)\n    Option(metricOperator).foreach( operator => {\n      if (!onceJob.isCompleted){\n        println(s"Metric monitoring: ${operator.apply()}")\n        println(s"Progress: ${progressOperator.apply()}")\n      }\n    })\n  }\n  onceJob. isCompleted\n  onceJob.waitForCompleted()\n  println(onceJob. getStatus)\n  println(TimeUnit. SECONDS. convert(System. currentTimeMillis() - time, TimeUnit. MILLISECONDS) + "s")\n  System. exit(0)\n\n\n   def importJob(jobBuilder: SimpleOnceJobBuilder): SubmittableSimpleOnceJob = {\n     jobBuilder\n       .addJobContent("sqoop.env.mapreduce.job.queuename", "queue_10")\n       .addJobContent("sqoop. mode", "import")\n       .addJobContent("sqoop.args.connect", "jdbc:mysql://127.0.0.1:3306/exchangis")\n       .addJobContent("sqoop.args.username", "free")\n       .addJobContent("sqoop.args.password", "testpwd")\n       .addJobContent("sqoop.args.query", "select id as order_number, sno as time from" +\n         "exchangis where sno =1 and $CONDITIONS")\n       .addJobContent("sqoop.args.hcatalog.database", "freedb")\n       .addJobContent("sqoop.args.hcatalog.table", "zy_test")\n       .addJobContent("sqoop.args.hcatalog.partition.keys", "month")\n       .addJobContent("sqoop.args.hcatalog.partition.values", "3")\n       .addJobContent("sqoop.args.num.mappers", "1")\n       .build()\n   }\n\n   def exportJob(jobBuilder: SimpleOnceJobBuilder): SubmittableSimpleOnceJob = {\n      jobBuilder\n        .addJobContent("sqoop.env.mapreduce.job.queuename", "queue1")\n        .addJobContent("sqoop.mode", "import")\n        .addJobContent("sqoop.args.connect", "jdbc:mysql://127.0.0.1:3306/exchangis")\n        .addJobContent("sqoop.args.query", "select id as order, sno as great_time from" +\n          "exchangis_table where sno =1 and $CONDITIONS")\n        .addJobContent("sqoop.args.hcatalog.database", "hadoop")\n        .addJobContent("sqoop.args.hcatalog.table", "partition_33")\n        .addJobContent("sqoop.args.hcatalog.partition.keys", "month")\n        .addJobContent("sqoop.args.hcatalog.partition.values", "4")\n        .addJobContent("sqoop.args.num.mappers", "1")\n        .build()\n   }\n')),(0,r.kt)("h2",{id:"4-engine-configuration-instructions"},"4 Engine configuration instructions"),(0,r.kt)("h3",{id:"41-default-configuration-description"},"4.1 Default Configuration Description"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"key"),(0,r.kt)("th",{parentName:"tr",align:null},"description"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.mode"),(0,r.kt)("td",{parentName:"tr",align:null},"import/export/\u2026")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-Dmapreduce.job.queuename"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.env.mapreduce.job.queuename"),(0,r.kt)("td",{parentName:"tr",align:null})),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-connect <jdbc-uri",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.connect"),(0,r.kt)("td",{parentName:"tr",align:null},"Specify JDBC connect string")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-connection-manager <class-name",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.connection.manager"),(0,r.kt)("td",{parentName:"tr",align:null},"Specify connection manager class name")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-connection-param-file <properties-file",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.connection.param.file"),(0,r.kt)("td",{parentName:"tr",align:null},"Specify connection parameters file")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-driver <class-name",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.driver"),(0,r.kt)("td",{parentName:"tr",align:null},"Manually specify JDBC driver class to use")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-hadoop-home <hdir",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.hadoop.home"),(0,r.kt)("td",{parentName:"tr",align:null},"Override $HADOOP","_","MAPRED","_","HOME","_","ARG")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-hadoop-mapred-home <dir",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.hadoop.mapred.home"),(0,r.kt)("td",{parentName:"tr",align:null},"Override $HADOOP","_","MAPRED","_","HOME","_","ARG")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-help"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.help"),(0,r.kt)("td",{parentName:"tr",align:null},"Print usage instructions")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","P"),(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null},"Read password from console")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-password <password",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.password"),(0,r.kt)("td",{parentName:"tr",align:null},"Set authentication password")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-password-alias <password-alias",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.password.alias"),(0,r.kt)("td",{parentName:"tr",align:null},"Credential provider password alias")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-password-file <password-file",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.password.file"),(0,r.kt)("td",{parentName:"tr",align:null},"Set authentication password file path")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-relaxed-isolation"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.relaxed.isolation"),(0,r.kt)("td",{parentName:"tr",align:null},"Use read-uncommitted isolation for imports")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-skip-dist-cache"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.skip.dist.cache"),(0,r.kt)("td",{parentName:"tr",align:null},"Skip copying jars to distributed cache")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-username <username",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.username"),(0,r.kt)("td",{parentName:"tr",align:null},"Set authentication username")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-verbose"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.verbose"),(0,r.kt)("td",{parentName:"tr",align:null},"Print more information while working")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null})))),(0,r.kt)("h3",{id:"42-import-and-export-parameters"},"4.2 Import and export parameters"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"key"),(0,r.kt)("th",{parentName:"tr",align:null},"description"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-batch"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.batch"),(0,r.kt)("td",{parentName:"tr",align:null},"Indicates underlying statements to be executed in batch mode")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-call <arg",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.call"),(0,r.kt)("td",{parentName:"tr",align:null},"Populate the table using this stored procedure (one call per row)")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-clear-staging-table"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.clear.staging.table"),(0,r.kt)("td",{parentName:"tr",align:null},"Indicates that any data in staging table can be deleted")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-columns <col,col,col...",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.columns"),(0,r.kt)("td",{parentName:"tr",align:null},"Columns to export to table")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-direct"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.direct"),(0,r.kt)("td",{parentName:"tr",align:null},"Use direct export fast path")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-export-dir <dir",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.export.dir"),(0,r.kt)("td",{parentName:"tr",align:null},"HDFS source path for the export")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","m,--num-mappers <n",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.num.mappers"),(0,r.kt)("td",{parentName:"tr",align:null},"Use 'n' map tasks to export in parallel")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-mapreduce-job-name <name",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.mapreduce.job.name"),(0,r.kt)("td",{parentName:"tr",align:null},"Set name for generated mapreduce job")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-staging-table <table-name",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.staging.table"),(0,r.kt)("td",{parentName:"tr",align:null},"Intermediate staging table")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-table <table-name",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.table"),(0,r.kt)("td",{parentName:"tr",align:null},"Table to populate")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-update-key <key",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.update.key"),(0,r.kt)("td",{parentName:"tr",align:null},"Update records by specified key column")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-update-mode <mode",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.update.mode"),(0,r.kt)("td",{parentName:"tr",align:null},"Specifies how updates are performed when new rows are found with non-matching keys in database")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-validate"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.validate"),(0,r.kt)("td",{parentName:"tr",align:null},"Validate the copy using the configured validator")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-validation-failurehandler <validation-failurehandler",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.validation.failurehandler"),(0,r.kt)("td",{parentName:"tr",align:null},"Validate the copy using the configured validator")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-validation-threshold <validation-threshold",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.validation.threshold"),(0,r.kt)("td",{parentName:"tr",align:null},"Fully qualified class name for ValidationThreshold")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-validator <validator",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.validator"),(0,r.kt)("td",{parentName:"tr",align:null},"Fully qualified class name for the Validator")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null})))),(0,r.kt)("h3",{id:"43-import-control-parameters"},"4.3 Import control parameters"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"key"),(0,r.kt)("th",{parentName:"tr",align:null},"description"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-append"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.append"),(0,r.kt)("td",{parentName:"tr",align:null},"Imports data in append mode")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-as-avrodatafile"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.as.avrodatafile"),(0,r.kt)("td",{parentName:"tr",align:null},"Imports data to Avro data files")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-as-parquetfile"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.as.parquetfile"),(0,r.kt)("td",{parentName:"tr",align:null},"Imports data to Parquet files")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-as-sequencefile"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.as.sequencefile"),(0,r.kt)("td",{parentName:"tr",align:null},"Imports data to SequenceFiles")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-as-textfile"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.as.textfile"),(0,r.kt)("td",{parentName:"tr",align:null},"Imports data as plain text (default)")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-autoreset-to-one-mapper"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.autoreset.to.one.mapper"),(0,r.kt)("td",{parentName:"tr",align:null},"Reset the number of mappers to one mapper if no split key available")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-boundary-query <statement",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.boundary.query"),(0,r.kt)("td",{parentName:"tr",align:null},"Set boundary query for retrieving max and min value of the primary key")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-case-insensitive"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.case.insensitive"),(0,r.kt)("td",{parentName:"tr",align:null},"Data Base is case insensitive, split where condition transfrom to lower case!")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-columns <col,col,col...",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.columns"),(0,r.kt)("td",{parentName:"tr",align:null},"Columns to import from table")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-compression-codec <codec",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.compression.codec"),(0,r.kt)("td",{parentName:"tr",align:null},"Compression codec to use for import")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-delete-target-dir"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.delete.target.dir"),(0,r.kt)("td",{parentName:"tr",align:null},"Imports data in delete mode")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-direct"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.direct"),(0,r.kt)("td",{parentName:"tr",align:null},"Use direct import fast path")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-direct-split-size <n",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.direct.split.size"),(0,r.kt)("td",{parentName:"tr",align:null},"Split the input stream every 'n' bytes when importing in direct mode")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","e,--query <statement",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.query"),(0,r.kt)("td",{parentName:"tr",align:null},"Import results of SQL 'statement'")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-fetch-size <n",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.fetch.size"),(0,r.kt)("td",{parentName:"tr",align:null},"Set number 'n' of rows to fetch from the database when more rows are needed")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-inline-lob-limit <n",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.inline.lob.limit"),(0,r.kt)("td",{parentName:"tr",align:null},"Set the maximum size for an inline LOB")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","m,--num-mappers <n",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.num.mappers"),(0,r.kt)("td",{parentName:"tr",align:null},"Use 'n' map tasks to import in parallel")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-mapreduce-job-name <name",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.mapreduce.job.name"),(0,r.kt)("td",{parentName:"tr",align:null},"Set name for generated mapreduce job")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-merge-key <column",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.merge.key"),(0,r.kt)("td",{parentName:"tr",align:null},"Key column to use to join results")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-split-by <column-name",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.split.by"),(0,r.kt)("td",{parentName:"tr",align:null},"Column of the table used to split work units")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-table <table-name",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.table"),(0,r.kt)("td",{parentName:"tr",align:null},"Table to read")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-target-dir <dir",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.target.dir"),(0,r.kt)("td",{parentName:"tr",align:null},"HDFS plain table destination")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-validate"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.validate"),(0,r.kt)("td",{parentName:"tr",align:null},"Validate the copy using the configured validator")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-validation-failurehandler <validation-failurehandler",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.validation.failurehandler"),(0,r.kt)("td",{parentName:"tr",align:null},"Fully qualified class name for ValidationFa ilureHandler")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-validation-threshold <validation-threshold",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.validation.threshold"),(0,r.kt)("td",{parentName:"tr",align:null},"Fully qualified class name for ValidationThreshold")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-validator <validator",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.validator"),(0,r.kt)("td",{parentName:"tr",align:null},"Fully qualified class name for the Validator")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-warehouse-dir <dir",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.warehouse.dir"),(0,r.kt)("td",{parentName:"tr",align:null},"HDFS parent for table destination")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-where <where clause",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.where"),(0,r.kt)("td",{parentName:"tr",align:null},"WHERE clause to use during import")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","z,--compress"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.compress"),(0,r.kt)("td",{parentName:"tr",align:null},"Enable compression")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null})))),(0,r.kt)("h3",{id:"44-incremental-import-parameters"},"4.4 Incremental import parameters"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"key"),(0,r.kt)("th",{parentName:"tr",align:null},"description"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-check-column <column",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.check.column"),(0,r.kt)("td",{parentName:"tr",align:null},"Source column to check for incremental change")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-incremental <import-type",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.incremental"),(0,r.kt)("td",{parentName:"tr",align:null},"Define an incremental import of type 'append' or 'lastmodified'")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-last-value <value",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.last.value"),(0,r.kt)("td",{parentName:"tr",align:null},"Last imported value in the incremental check column")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null})))),(0,r.kt)("h3",{id:"45-output-line-formatting-parameters"},"4.5 Output line formatting parameters"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"key"),(0,r.kt)("th",{parentName:"tr",align:null},"description"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-enclosed-by <char",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.enclosed.by"),(0,r.kt)("td",{parentName:"tr",align:null},"Sets a required field enclosing character")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-escaped-by <char",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.escaped.by"),(0,r.kt)("td",{parentName:"tr",align:null},"Sets the escape character")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-fields-terminated-by <char",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.fields.terminated.by"),(0,r.kt)("td",{parentName:"tr",align:null},"Sets the field separator character")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-lines-terminated-by <char",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.lines.terminated.by"),(0,r.kt)("td",{parentName:"tr",align:null},"Sets the end-of-line character")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-mysql-delimiters"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.mysql.delimiters"),(0,r.kt)("td",{parentName:"tr",align:null},"Uses MySQL's default delimiter set: fields: , lines: ","\\","n escaped-by: ","\\"," optionally-enclosed-by: '")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-optionally-enclosed-by <char",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.optionally.enclosed.by"),(0,r.kt)("td",{parentName:"tr",align:null},"Sets a field enclosing character")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null})))),(0,r.kt)("h3",{id:"46-input-parsing-parameters"},"4.6 Input parsing parameters"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"key"),(0,r.kt)("th",{parentName:"tr",align:null},"description"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-input-enclosed-by <char",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.input.enclosed.by"),(0,r.kt)("td",{parentName:"tr",align:null},"Sets a required field enclosure")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-input-escaped-by <char",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.input.escaped.by"),(0,r.kt)("td",{parentName:"tr",align:null},"Sets the input escape character")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-input-fields-terminated-by <char",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.input.fields.terminated.by"),(0,r.kt)("td",{parentName:"tr",align:null},"Sets the input field separator")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-input-lines-terminated-by <char",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.input.lines.terminated.by"),(0,r.kt)("td",{parentName:"tr",align:null},"Sets the input end-of-line char")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-input-optionally-enclosed-by <char",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.input.optionally.enclosed.by"),(0,r.kt)("td",{parentName:"tr",align:null},"Sets a field enclosing character")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null})))),(0,r.kt)("h3",{id:"47-hive-parameters"},"4.7 ",(0,r.kt)("inlineCode",{parentName:"h3"},"Hive")," parameters"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"key"),(0,r.kt)("th",{parentName:"tr",align:null},"description"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-create-hive-table"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.create.hive.table"),(0,r.kt)("td",{parentName:"tr",align:null},"Fail if the target hive table exists")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-hive-database <database-name",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.hive.database"),(0,r.kt)("td",{parentName:"tr",align:null},"Sets the database name to use when importing to hive")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-hive-delims-replacement <arg",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.hive.delims.replacement"),(0,r.kt)("td",{parentName:"tr",align:null},"Replace Hive record ","\\","0x01 and row delimiters (","\\","n","\\","r) from imported string fields with user-defined string")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-hive-drop-import-delims"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.hive.drop.import.delims"),(0,r.kt)("td",{parentName:"tr",align:null},"Drop Hive record ","\\","0x01 and row delimiters (","\\","n","\\","r) from imported string fields")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-hive-home <dir",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.hive.home"),(0,r.kt)("td",{parentName:"tr",align:null},"Override $HIVE","_","HOME")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-hive-import"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.hive.import"),(0,r.kt)("td",{parentName:"tr",align:null},"Import tables into Hive (Uses Hive's default delimiters if none are set.)")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-hive-overwrite"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.hive.overwrite"),(0,r.kt)("td",{parentName:"tr",align:null},"Overwrite existing data in the Hive table")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-hive-partition-key <partition-key",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.hive.partition.key"),(0,r.kt)("td",{parentName:"tr",align:null},"Sets the partition key to use when importing to hive")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-hive-partition-value <partition-value",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.hive.partition.value"),(0,r.kt)("td",{parentName:"tr",align:null},"Sets the partition value to use when importing to hive")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-hive-table <table-name",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.hive.table"),(0,r.kt)("td",{parentName:"tr",align:null},"Sets the table name to use when importing to hive")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-map-column-hive <arg",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.map.column.hive"),(0,r.kt)("td",{parentName:"tr",align:null},"Override mapping for specific column to hive types.")))),(0,r.kt)("h3",{id:"48-hbase-parameters"},"4.8 ",(0,r.kt)("inlineCode",{parentName:"h3"},"HBase")," parameters"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"key"),(0,r.kt)("th",{parentName:"tr",align:null},"description"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-column-family <family",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.column.family"),(0,r.kt)("td",{parentName:"tr",align:null},"Sets the target column family for the import")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-hbase-bulkload"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.hbase.bulkload"),(0,r.kt)("td",{parentName:"tr",align:null},"Enables HBase bulk loading")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-hbase-create-table"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.hbase.create.table"),(0,r.kt)("td",{parentName:"tr",align:null},"If specified, create missing HBase tables")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-hbase-row-key <col",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.hbase.row.key"),(0,r.kt)("td",{parentName:"tr",align:null},"Specifies which input column to use as the row key")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-hbase-table <table",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.hbase.table"),(0,r.kt)("td",{parentName:"tr",align:null},"Import to <table",">","in HBase")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null})))),(0,r.kt)("h3",{id:"49-hcatalog-parameters"},"4.9 ",(0,r.kt)("inlineCode",{parentName:"h3"},"HCatalog")," parameters"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"key"),(0,r.kt)("th",{parentName:"tr",align:null},"description"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-hcatalog-database <arg",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.hcatalog.database"),(0,r.kt)("td",{parentName:"tr",align:null},"HCatalog database name")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-hcatalog-home <hdir",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.hcatalog.home"),(0,r.kt)("td",{parentName:"tr",align:null},"Override $HCAT","_","HOME")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-hcatalog-partition-keys <partition-key",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.hcatalog.partition.keys"),(0,r.kt)("td",{parentName:"tr",align:null},"Sets the partition keys to use when importing to hive")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-hcatalog-partition-values \u200b\u200b<partition-value",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.hcatalog.partition.values \u200b\u200b"),(0,r.kt)("td",{parentName:"tr",align:null},"Sets the partition values \u200b\u200bto use when importing to hive")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-hcatalog-table <arg",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.hcatalog.table"),(0,r.kt)("td",{parentName:"tr",align:null},"HCatalog table name")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-hive-home <dir",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.hive.home"),(0,r.kt)("td",{parentName:"tr",align:null},"Override $HIVE","_","HOME")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-hive-partition-key <partition-key",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.hive.partition.key"),(0,r.kt)("td",{parentName:"tr",align:null},"Sets the partition key to use when importing to hive")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-hive-partition-value <partition-value",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.hive.partition.value"),(0,r.kt)("td",{parentName:"tr",align:null},"Sets the partition value to use when importing to hive")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-map-column-hive <arg",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.map.column.hive"),(0,r.kt)("td",{parentName:"tr",align:null},"Override mapping for specific column to hive types.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null})),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"HCatalog import specific options:"),(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null})),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-create-hcatalog-table"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.create.hcatalog.table"),(0,r.kt)("td",{parentName:"tr",align:null},"Create HCatalog before import")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-hcatalog-storage-stanza <arg",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.hcatalog.storage.stanza"),(0,r.kt)("td",{parentName:"tr",align:null},"HCatalog storage stanza for table creation")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null})))),(0,r.kt)("h3",{id:"410-accumulo-parameters"},"4.10 ",(0,r.kt)("inlineCode",{parentName:"h3"},"Accumulo")," parameters"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"key"),(0,r.kt)("th",{parentName:"tr",align:null},"description"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-accumulo-batch-size <size",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.accumulo.batch.size"),(0,r.kt)("td",{parentName:"tr",align:null},"Batch size in bytes")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-accumulo-column-family <family",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.accumulo.column.family"),(0,r.kt)("td",{parentName:"tr",align:null},"Sets the target column family for the import")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-accumulo-create-table"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.accumulo.create.table"),(0,r.kt)("td",{parentName:"tr",align:null},"If specified, create missing Accumulo tables")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-accumulo-instance <instance",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.accumulo.instance"),(0,r.kt)("td",{parentName:"tr",align:null},"Accumulo instance name.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-accumulo-max-latency <latency",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.accumulo.max.latency"),(0,r.kt)("td",{parentName:"tr",align:null},"Max write latency in milliseconds")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-accumulo-password <password",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.accumulo.password"),(0,r.kt)("td",{parentName:"tr",align:null},"Accumulo password.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-accumulo-row-key <col",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.accumulo.row.key"),(0,r.kt)("td",{parentName:"tr",align:null},"Specifies which input column to use as the row key")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-accumulo-table <table",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.accumulo.table"),(0,r.kt)("td",{parentName:"tr",align:null},"Import to <table",">","in Accumulo")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-accumulo-user <user",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.accumulo.user"),(0,r.kt)("td",{parentName:"tr",align:null},"Accumulo user name.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-accumulo-visibility <vis",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.accumulo.visibility"),(0,r.kt)("td",{parentName:"tr",align:null},"Visibility token to be applied to all rows imported")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-accumulo-zookeepers <zookeepers",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.accumulo.zookeepers"),(0,r.kt)("td",{parentName:"tr",align:null},"Comma-separated list of zookeepers (host:port)")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null})))),(0,r.kt)("h3",{id:"411-code-generation-parameters"},"4.11 Code Generation Parameters"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"key"),(0,r.kt)("th",{parentName:"tr",align:null},"description"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-bindir <dir",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.bindir"),(0,r.kt)("td",{parentName:"tr",align:null},"Output directory for compiled objects")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-class-name <name",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.class.name"),(0,r.kt)("td",{parentName:"tr",align:null},"Sets the generated class name. This overrides --package-name. When combined with --jar-file, sets the input class.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-input-null-non-string <null-str",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.input.null.non.string"),(0,r.kt)("td",{parentName:"tr",align:null},"Input null non-string representation")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-input-null-string <null-str",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.input.null.string"),(0,r.kt)("td",{parentName:"tr",align:null},"Input null string representation")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-jar-file <file",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.jar.file"),(0,r.kt)("td",{parentName:"tr",align:null},"Disable code generation; use specified jar")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-map-column-java <arg",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.map.column.java"),(0,r.kt)("td",{parentName:"tr",align:null},"Override mapping for specific columns to java types")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-null-non-string <null-str",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.null.non.string"),(0,r.kt)("td",{parentName:"tr",align:null},"Null non-string representation")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-null-string <null-str",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.null.string"),(0,r.kt)("td",{parentName:"tr",align:null},"Null string representation")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-outdir <dir",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.outdir"),(0,r.kt)("td",{parentName:"tr",align:null},"Output directory for generated code")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","-package-name <name",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.package.name"),(0,r.kt)("td",{parentName:"tr",align:null},"Put auto-generated classes in this package")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null})))),(0,r.kt)("h3",{id:"412-generic-hadoop-command-line-arguments"},"4.12 Generic ",(0,r.kt)("inlineCode",{parentName:"h3"},"Hadoop")," command line arguments"),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"must preceed any tool-specific arguments,Generic options supported are")),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"parameter"),(0,r.kt)("th",{parentName:"tr",align:null},"key"),(0,r.kt)("th",{parentName:"tr",align:null},"description"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","conf <configuration file",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.conf"),(0,r.kt)("td",{parentName:"tr",align:null},"specify an application configuration file")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","D <property=value",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.D"),(0,r.kt)("td",{parentName:"tr",align:null},"use value for given property")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","fs <local"),(0,r.kt)("td",{parentName:"tr",align:null},"namenode:port",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.fs")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","jt <local"),(0,r.kt)("td",{parentName:"tr",align:null},"resourcemanager:port",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.jt")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","files <comma separated list of files",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.files"),(0,r.kt)("td",{parentName:"tr",align:null},"specify comma separated files to be copied to the map reduce cluster")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","libjars <comma separated list of jars",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.libjars"),(0,r.kt)("td",{parentName:"tr",align:null},"specify comma separated jar files to include in the classpath.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"-","archives <comma separated list of archives",">"),(0,r.kt)("td",{parentName:"tr",align:null},"sqoop.args.archives"),(0,r.kt)("td",{parentName:"tr",align:null},"specify comma separated archives to be unarchived on the compute machines.")))))}u.isMDXComponent=!0}}]);