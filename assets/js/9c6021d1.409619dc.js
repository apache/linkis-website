"use strict";(self.webpackChunklinkis_web_apache=self.webpackChunklinkis_web_apache||[]).push([[96867],{3905:(e,n,t)=>{t.d(n,{Zo:()=>p,kt:()=>u});var i=t(67294);function o(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function a(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);n&&(i=i.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,i)}return t}function s(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?a(Object(t),!0).forEach((function(n){o(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):a(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function r(e,n){if(null==e)return{};var t,i,o=function(e,n){if(null==e)return{};var t,i,o={},a=Object.keys(e);for(i=0;i<a.length;i++)t=a[i],n.indexOf(t)>=0||(o[t]=e[t]);return o}(e,n);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(i=0;i<a.length;i++)t=a[i],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(o[t]=e[t])}return o}var l=i.createContext({}),c=function(e){var n=i.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):s(s({},n),e)),t},p=function(e){var n=c(e.components);return i.createElement(l.Provider,{value:n},e.children)},d={inlineCode:"code",wrapper:function(e){var n=e.children;return i.createElement(i.Fragment,{},n)}},m=i.forwardRef((function(e,n){var t=e.components,o=e.mdxType,a=e.originalType,l=e.parentName,p=r(e,["components","mdxType","originalType","parentName"]),m=c(t),u=o,h=m["".concat(l,".").concat(u)]||m[u]||d[u]||a;return t?i.createElement(h,s(s({ref:n},p),{},{components:t})):i.createElement(h,s({ref:n},p))}));function u(e,n){var t=arguments,o=n&&n.mdxType;if("string"==typeof e||o){var a=t.length,s=new Array(a);s[0]=m;var r={};for(var l in n)hasOwnProperty.call(n,l)&&(r[l]=n[l]);r.originalType=e,r.mdxType="string"==typeof e?e:o,s[1]=r;for(var c=2;c<a;c++)s[c]=t[c];return i.createElement.apply(null,s)}return i.createElement.apply(null,t)}m.displayName="MDXCreateElement"},46126:(e,n,t)=>{t.r(n),t.d(n,{contentTitle:()=>s,default:()=>p,frontMatter:()=>a,metadata:()=>r,toc:()=>l});var i=t(87462),o=(t(67294),t(3905));const a={title:"Development & Debugging with Kubernetes",sidebar_position:2.1},s=void 0,r={unversionedId:"development/debug-with-helm-charts",id:"version-1.3.0/development/debug-with-helm-charts",isDocsHomePage:!1,title:"Development & Debugging with Kubernetes",description:"Preface",source:"@site/versioned_docs/version-1.3.0/development/debug-with-helm-charts.md",sourceDirName:"development",slug:"/development/debug-with-helm-charts",permalink:"/docs/latest/development/debug-with-helm-charts",editUrl:"https://github.com/apache/incubator-linkis-website/edit/dev/versioned_docs/version-1.3.0/development/debug-with-helm-charts.md",tags:[],version:"1.3.0",sidebarPosition:2.1,frontMatter:{title:"Development & Debugging with Kubernetes",sidebar_position:2.1},sidebar:"version-1.3.0/tutorialSidebar",previous:{title:"Service Debugging Guide",permalink:"/docs/latest/development/debug"},next:{title:"Quickly Implement New Engine",permalink:"/docs/latest/development/new-engine-conn"}},l=[{value:"Preface",id:"preface",children:[]},{value:"Introduction to Dependency Tools",id:"introduction-to-dependency-tools",children:[{value:"Version Requirements",id:"version-requirements",children:[]},{value:"Introduction to Helm Charts",id:"introduction-to-helm-charts",children:[]},{value:"Introduction to KinD",id:"introduction-to-kind",children:[]}]},{value:"Linkis Containerized Components",id:"linkis-containerized-components",children:[{value:"Linkis Images",id:"linkis-images",children:[]},{value:"Linkis Helm Chart",id:"linkis-helm-chart",children:[]},{value:"LDH",id:"ldh",children:[]},{value:"KinD Cluster",id:"kind-cluster",children:[]}]},{value:"Developing and Debugging with Linkis Containerized Components",id:"developing-and-debugging-with-linkis-containerized-components",children:[{value:"Create Debugging Environment",id:"create-debugging-environment",children:[]},{value:"Debugging Components",id:"debugging-components",children:[]},{value:"Clean Up the Environment",id:"clean-up-the-environment",children:[]},{value:"Other Useful Operations",id:"other-useful-operations",children:[]}]}],c={toc:l};function p(e){let{components:n,...a}=e;return(0,o.kt)("wrapper",(0,i.Z)({},c,a,{components:n,mdxType:"MDXLayout"}),(0,o.kt)("h2",{id:"preface"},"Preface"),(0,o.kt)("p",null,"This document describes how to use Kubernetes technology to simplify the development and debugging of Linkis projects. Before the introduction of Kubernetes tools, debugging Linkis was a very tedious and complex task, and sometimes it might be necessary to set up a Hadoop cluster for test. To improve this problem, we introduce an alternative approach , using Kubernetes technology, to create a Hadoop cluster on the development machine and pull up all Linkis services, which is a distributed environment and can be pulled up and destroyed at any time, and the developer connects to these services to performs step-by-step debugging through the JVM remote debugger. Here we use the following technologies:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Docker: A containerization technology to support the creation and use of Linux containers;"),(0,o.kt)("li",{parentName:"ul"},"Kubernetes: An open source platform that automates the deployment and management of Linux containers, Kubernetes also integrates networking, storage, security, telemetry and other services to provide a comprehensive container-based infrastructure;"),(0,o.kt)("li",{parentName:"ul"},'KinD: A tool that uses Docker containers as "Kubernetes nodes" to run local Kubernetes clusters;'),(0,o.kt)("li",{parentName:"ul"},"Helm: An open source package management tool on Kubernetes that manages user resources on Kubernetes via the Helm command line tool and installation package (Chart);")),(0,o.kt)("h2",{id:"introduction-to-dependency-tools"},"Introduction to Dependency Tools"),(0,o.kt)("h3",{id:"version-requirements"},"Version Requirements"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://docs.docker.com/get-docker/"},"Docker"),", minimum version v20.10.8+"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://kubernetes.io/docs/setup/"},"Kubernetes"),", minimum version v1.21.0+"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://helm.sh/docs/intro/install/"},"Helm"),", minimum version v3.0.0+."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://kind.sigs.k8s.io/docs/user/quick-start/"},"KinD"),", minimum version v0.11.0+.")),(0,o.kt)("h3",{id:"introduction-to-helm-charts"},"Introduction to Helm Charts"),(0,o.kt)("p",null,"Helm is an open source package management tool on Kubernetes. Helm's original goal was to provide users with a better way to manage all Kubernetes YAML files created on Kubernetes. When using Charts, the user provides a variable file, Helm uses the variables defined in this variable file to render the corresponding Chart, produce a Kubernetes YAML file, and then invoke the Kubernetes api to create the resources. Each Charts released to Kubernetes is called a Release, and a Chart can typically be installed multiple times into the same cluster, with a new Release being created each time it is installed."),(0,o.kt)("p",null,"Helm is relatively simple to install, please refer to the official documentation for installation: ",(0,o.kt)("a",{parentName:"p",href:"https://helm.sh/docs/intro/install/"},"Installing Helm")),(0,o.kt)("h3",{id:"introduction-to-kind"},"Introduction to KinD"),(0,o.kt)("p",null,"Creating a Kubernetes test environment locally is a very common requirement, and the Kubernetes community offers a variety of solutions, such as MiniKube or MicroK8s. KinD, as the name suggests (Kubernetes in Docker), it uses Docker container to host nodes to create a test-oriented Kubernetes cluster."),(0,o.kt)("p",null,"KinD Architecture"),(0,o.kt)("p",null,(0,o.kt)("img",{src:t(86278).Z})),(0,o.kt)("p",null,"Deploying KinD is also very easy, please refer to the official deployment documentation: ",(0,o.kt)("a",{parentName:"p",href:"https://kind.sigs.k8s.io/docs/user/quick-start/#installation"},"KinD Installation"),", please install Docker before install KinD."),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},"\u26a0\ufe0f Note:\nKinD is a tool for testing purposes and cannot be used for production deployments. For example, KinD clusters cannot be used after the development machine is rebooted and need to be recreated (because KinD performs a series of initialization tasks after the Node container is created, which cannot be automatically reverted after the machine is rebooted).")),(0,o.kt)("h2",{id:"linkis-containerized-components"},"Linkis Containerized Components"),(0,o.kt)("h3",{id:"linkis-images"},"Linkis Images"),(0,o.kt)("p",null,"Linkis provides several images, all of which have their Dockerfile and related scripts in the ",(0,o.kt)("inlineCode",{parentName:"p"},"linkis-dist/docker")," directory. Linkis images include the following."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"linkis"),": The Linkis service image, which contains binary packages of all components of Apache Linkis and various scripts."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"linkis-web"),": Linkis Web console image, which contains the binary packages and various scripts of the Apache Linkis Web console, using nginx as the web server."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"linkis-ldh"),": LDH is a test-oriented image, LDH image provides a complete, pseudo-distributed mode Apache Hadoop runtime environment, including HDFS, YARN, HIVE, Spark, Flink and Zookeeper, can be easily pulled up in the development environment of a fully real Hadoop environment to test the functionality of Linkis.")),(0,o.kt)("p",null,"For details, please refer to: ",(0,o.kt)("a",{parentName:"p",href:"https://linkis.apache.org/zh-CN/docs/latest/development/linkis_docker_build_instrument"},"Linkis Docker Image Package"),". "),(0,o.kt)("h3",{id:"linkis-helm-chart"},"Linkis Helm Chart"),(0,o.kt)("p",null,"Linkis Helm Chart is a Helm installation package developed according to the Helm Chart specification and is located in the ",(0,o.kt)("inlineCode",{parentName:"p"},"linkis-dist/helm")," directory. The module directory structure is as follows:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"linkis-dist/helm\n\u251c\u2500\u2500 charts                                 # Charts directory, currently only contains Linkis Helm Chart\n\u2502 \u2514\u2500\u2500 linkis                               # Linkis Helm Chart directory\n\u2502 \u251c\u2500\u2500 Chart.yaml                           # - Chart metadata\n\u2502 \u251c\u2500\u2500 templates                            # - Chart template file containing Kubernetes YAML templates for all linkis components\n\u2502 \u2502 \u251c\u2500\u2500 NOTES.txt                          #   - Chart notes\n\u2502 \u2502 \u251c\u2500\u2500 _helpers.tpl                       #   - Chart variable helper templates\n\u2502 \u2502 \u251c\u2500\u2500 configmap-init-sql.yaml            #   - Database initialization SQL script template\n\u2502 \u2502 \u251c\u2500\u2500 configmap-linkis-config.yaml       #   - Linkis service configuration file template\n\u2502 \u2502 \u251c\u2500\u2500 configmap-linkis-web-config.yaml   #   - Linkis Web Console configuration file template\n\u2502 \u2502 \u251c\u2500\u2500 jobs.yaml                          #   - Kubernetes Job template, currently only includes a database initialization job, the database\n| | |                                      #     initialization SQL script will be executed by the job\n\u2502 \u2502 \u251c\u2500\u2500 linkis-cg-engineconnmanager.yaml   #   - Linkis EngineConnManager deployment template, which is a Kubernetes Deployment type workload\n\u2502 \u2502 \u251c\u2500\u2500 linkis-cg-engineplugin.yaml        #   - Linkis EngineConn deployment template, a Kubernetes Deployment type workload\n\u2502 \u2502 \u251c\u2500\u2500 linkis-cg-entrance.yaml            #   - Linkis Entrance deployment template, a Kubernetes Deployment type workload\n\u2502 \u2502 \u251c\u2500\u2500 linkis-cg-linkismanager.yaml       #   - Linkis Manager deployment template, a Kubernetes Deployment type workload\n\u2502 \u2502 \u251c\u2500\u2500 linkis-mg-eureka.yaml              #   - Linkis Eureka deployment template, a Kubernetes Statefulset type workload\n\u2502 \u2502 \u251c\u2500\u2500 linkis-mg-gateway.yaml             #   - Linkis Gateway deployment template, a Kubernetes Deployment type workload\n\u2502 \u2502 \u251c\u2500\u2500 linkis-ps-publicservice.yaml       #   - Linkis PublicService deployment template, a Kubernetes Deployment type workload\n\u2502 \u2502 \u251c\u2500\u2500 linkis-web.yaml                    #   - Linkis Web Console deployment template, a Kubernetes Deployment type workload\n\u2502 \u2502 \u2514\u2500\u2500 serviceaccount.yaml                #   - Linkis related Kubernetes Service Account template\n\u2502 \u2514\u2500\u2500 values.yaml                          # - Linkis Helm Chart variable file, which provides Linkis Local schema related variables by default\n\u251c\u2500\u2500 scripts                                # Some tool scripts to simplify development and debugging\n\u2502 \u251c\u2500\u2500 common.sh                            #   - public scripts, defining some public methods and variables\n\u2502 \u251c\u2500\u2500 create-kind-cluster.sh               #   - Creates KinD clusters\n\u2502 \u251c\u2500\u2500 install-charts-with-ldh.sh           #   - Deploy Linkis service on KinD cluster, using On-LDH deployment method, calling install-linkis.sh\n\u2502 \u251c\u2500\u2500 install-charts.sh                    #   - Deploy Linkis service on KinD cluster, use Local deployment method, call install-linkis.sh\n\u2502 \u251c\u2500\u2500 install-ldh.sh                       #   - Deploy LDH deployments on KinD clusters\n\u2502 \u251c\u2500\u2500 install-linkis.sh                    #   - Deploy the Linkis service on the KinD cluster, either in Local or On-LDH mode\n\u2502 \u251c\u2500\u2500 install-mysql.sh                     #   - Deploy a MySQL instance on the KinD cluster\n\u2502 \u251c\u2500\u2500 login-pod.sh                         #   - Login to a Pod and open Bash for interaction\n\u2502 \u251c\u2500\u2500 remote-debug-proxy.sh                #   - Turn on the JVM remote debug proxy\n\u2502 \u2514\u2500\u2500 resources                            #   - some resource files\n\u2502 \u251c\u2500\u2500 kind-cluster.yaml                    #   - KinD cluster configuration, default is single Node \n\u2502 \u251c\u2500\u2500 ldh                                  #   - LDH related resource files\n\u2502 \u2502 \u2502 \u251c\u2500\u2500 configmaps                       #     - LDH configuration files for each component\n\u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 configmap-flink.yaml           #       - Flink configuration file\n\u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 configmap-hadoop.yaml          #       - Hdfs & Yarn configuration file\n\u2502 \u2502 \u2502 \u251c\u2500\u2500 configmap-hive.yaml              #       - Hive configuration file\n\u2502 \u2502 \u2502 \u251c\u2500\u2500 configmap-spark.yaml             #       - Spark configuration file\n\u2502 \u2502 \u2502 \u2514\u2500\u2500 configmap-zookeeper.yaml         #       - Zookeeper configuration file\n\u2502 \u2502 \u2514\u2500\u2500 ldh.yaml                           #   - LDH Kubernetes YAML, used to deploy LDH instances on KinD\n\u2502 \u2514\u2500\u2500 mysql.yaml                           # - MySQL Kubernetes YAML, for deploying MySQL instances on KinD\n\n")),(0,o.kt)("p",null,"This project provides a set of tool scripts for quickly creating a Linkis environment for development testing. For production deployment, you need to modify the ",(0,o.kt)("inlineCode",{parentName:"p"},"values.yaml")," file according to the actual cluster, and then deploy it using the Helm CLI. There are two common approaches to deploying with the Helm CLI:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"deploy directly using the ",(0,o.kt)("inlineCode",{parentName:"li"},"helm install")," command. This is suitable for non-customized deployments."),(0,o.kt)("li",{parentName:"ol"},"use the ",(0,o.kt)("inlineCode",{parentName:"li"},"helm template")," command to generate Kubernetes YAML files, then manually modify these files, add custom configuration, and then deploy using the ",(0,o.kt)("inlineCode",{parentName:"li"},"kubectl apply")," command. For advanced users who need to customize Kubernetes features that are not supported by Linkis Helm Charts, such as the need to use specific StorageClass or PVs.")),(0,o.kt)("h3",{id:"ldh"},"LDH"),(0,o.kt)("p",null,"LDH is a Hadoop cluster image for testing purposes, which provides a pseudo-distributed hadoop cluster for quick testing of On Hadoop deployment mode.\nThis image contains the following hadoop components, and the default mode of the engine in LDH is on-yarn."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Hadoop 2.7.2 , included HDFS and YARN"),(0,o.kt)("li",{parentName:"ul"},"Hive 2.3.3"),(0,o.kt)("li",{parentName:"ul"},"Spark 2.4.3"),(0,o.kt)("li",{parentName:"ul"},"Flink 1.12.2"),(0,o.kt)("li",{parentName:"ul"},"ZooKeeper 3.5.9")),(0,o.kt)("p",null,"LDH will start some initialization operations, such as format hdfs, create the initialization directory on HDFS, etc., these operations are defined in ",(0,o.kt)("inlineCode",{parentName:"p"},"linkis-dist/docker/scripts/entry-point-ldh.sh")," file, add, modify, delete some initialization operations need to recreate LDH image to take effect. "),(0,o.kt)("p",null,"In addition, the Hive component in LDH depends on external MySQL instance, you need to deploy MySQL instance first before you can use the Hive component in LDH."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"# Create a KinD cluster and deploy Linkis and LDH instances\n$> sh ./scripts/create-kind-cluster.sh \\\n   && sh ./scripts/install-mysql.sh \\\n   && sh ./scripts/install-ldh.sh\n\n# Quick Experience on LDH\n$> kubectl exec -it -n ldh $(kubectl get pod -n ldh -o jsonpath='{.items[0].metadata.name}') -- bash\n\n[root@ldh-96bdc757c-dnkbs /]# hdfs dfs -ls /\nFound 4 items\ndrwxrwxrwx   - root supergroup          0 2022-07-31 02:48 /completed-jobs\ndrwxrwxrwx   - root supergroup          0 2022-07-31 02:48 /spark2-history\ndrwxrwxrwx   - root supergroup          0 2022-07-31 02:49 /tmp\ndrwxrwxrwx   - root supergroup          0 2022-07-31 02:48 /user\n\n[root@ldh-96bdc757c-dnkbs /]# beeline -u jdbc:hive2://ldh.ldh.svc.cluster.local:10000/ -n hadoop\nConnecting to jdbc:hive2://ldh.ldh.svc.cluster.local:10000/\nConnected to: Apache Hive (version 2.3.3)\nDriver: Hive JDBC (version 2.3.3)\nTransaction isolation: TRANSACTION_REPEATABLE_READ\nBeeline version 2.3.3 by Apache Hive\n0: jdbc:hive2://ldh.ldh.svc.cluster.local:100> create database demo;\nNo rows affected (1.306 seconds)\n0: jdbc:hive2://ldh.ldh.svc.cluster.local:100> use demo;\nNo rows affected (0.046 seconds)\n0: jdbc:hive2://ldh.ldh.svc.cluster.local:100> create table t1 (id int, data string);\nNo rows affected (0.709 seconds)\n0: jdbc:hive2://ldh.ldh.svc.cluster.local:100> insert into t1 values(1, 'linikis demo');\nWARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.\nNo rows affected (5.491 seconds)\n0: jdbc:hive2://ldh.ldh.svc.cluster.local:100> select * from t1;\n+--------+---------------+\n| t1.id  |    t1.data    |\n+--------+---------------+\n| 1      | linikis demo  |\n+--------+---------------+\n1 row selected (0.39 seconds)\n0: jdbc:hive2://ldh.ldh.svc.cluster.local:100> !q\n\n[root@ldh-96bdc757c-dnkbs /]# spark-sql\n22/07/31 02:53:18 INFO hive.metastore: Trying to connect to metastore with URI thrift://ldh.ldh.svc.cluster.local:9083\n22/07/31 02:53:18 INFO hive.metastore: Connected to metastore.\n...\n22/07/31 02:53:19 INFO spark.SparkContext: Running Spark version 2.4.3\n22/07/31 02:53:19 INFO spark.SparkContext: Submitted application: SparkSQL::10.244.0.6\n...\n22/07/31 02:53:27 INFO yarn.Client: Submitting application application_1659235712576_0001 to ResourceManager\n22/07/31 02:53:27 INFO impl.YarnClientImpl: Submitted application application_1659235712576_0001\n22/07/31 02:53:27 INFO cluster.SchedulerExtensionServices: Starting Yarn extension services with app application_1659235712576_0001 and attemptId None\n22/07/31 02:53:28 INFO yarn.Client: Application report for application_1659235712576_0001 (state: ACCEPTED)\n...\n22/07/31 02:53:36 INFO yarn.Client: Application report for application_1659235712576_0001 (state: RUNNING)\n...\nSpark master: yarn, Application Id: application_1659235712576_0001\n22/07/31 02:53:46 INFO thriftserver.SparkSQLCLIDriver: Spark master: yarn, Application Id: application_1659235712576_0001\nspark-sql> use demo;\nTime taken: 0.074 seconds\n22/07/31 02:58:02 INFO thriftserver.SparkSQLCLIDriver: Time taken: 0.074 seconds\nspark-sql> select * from t1;\n...\n1       linikis demo\n2       linkis demo spark sql\nTime taken: 3.352 seconds, Fetched 2 row(s)\nspark-sql> quit;\n\n[root@ldh-96bdc757c-dnkbs /]# zkCli.sh\nConnecting to localhost:2181\nWelcome to ZooKeeper!\nJLine support is enabled\nWATCHER::\n\nWatchedEvent state:SyncConnected type:None path:null\n\n[zk: localhost:2181(CONNECTED) 0] get -s /zookeeper/quota\n\ncZxid = 0x0\nctime = Thu Jan 01 00:00:00 UTC 1970\nmZxid = 0x0\nmtime = Thu Jan 01 00:00:00 UTC 1970\npZxid = 0x0\ncversion = 0\ndataVersion = 0\naclVersion = 0\nephemeralOwner = 0x0\ndataLength = 0\nnumChildren = 0\n[zk: localhost:2181(CONNECTED) 1] quit\n\n# Start a Flink job in per-job cluster mode\n[root@ldh-96bdc757c-dnkbs /]# HADOOP_CLASSPATH=`hadoop classpath` flink run -t yarn-per-job /opt/ldh/current/flink/examples/streaming/TopSpeedWindowing.jar\n# Start Flink jobs in session mode,\n# Flink session is started when LDH Pod starts.\n[root@ldh-96bdc757c-dnkbs /]# flink run /opt/ldh/current/flink/examples/streaming/TopSpeedWindowing.jar\nExecuting TopSpeedWindowing example with default input data set.\nUse --input to specify file input.\nPrinting result to stdout. Use --output to specify output path.\n...\n")),(0,o.kt)("h3",{id:"kind-cluster"},"KinD Cluster"),(0,o.kt)("p",null,"The default KinD cluster description file used by the Linkis project is ",(0,o.kt)("inlineCode",{parentName:"p"},"linkis-dist/helm/scripts/resources/kind-cluster.yaml"),", which creates a KinD cluster with one node by default. Multiple nodes can be added by remove the comments."),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},"\u26a0\ufe0fNote that KinD clusters are for testing purposes only.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"# linkis-dist/helm/scripts/resources/kind-cluster.yaml\nkind: Cluster\napiVersion: kind.x-k8s.io/v1alpha4\nnodes:\n  - role: control-plane\n    extraMounts:\n      - hostPath: ${KIND_CLUSTER_HOST_PATH}     # Points to a directory on the development machine. This directory \n                                                # is mapped to the `/data` directory in the Kind Node container, which\n                                                # Linkis Helm Charts uses by default as the data directory to mount into \n                                                # the Pod of each Linkis component. When Linkis is deployed in Local mode, \n                                                # all components actually use the same directory on the development machine\n                                                # as if they were on the same machine, thus emulating the behavior of Local\n                                                # mode. When deployed in On-Hadoop mode, this directory is not used.\n        containerPath: /data\n#  - role: worker                               # Remove comments to add 2 KinD nodes. Adding KinD nodes increases the time \n                                                # it takes to load Docker images to the KinD cluster, so it is not turned on \n                                                # by default. \n#    extraMounts:\n#      - hostPath: ${KIND_CLUSTER_HOST_PATH}\n#        containerPath: /data\n#  - role: worker\n#    extraMounts:\n#      - hostPath: ${KIND_CLUSTER_HOST_PATH}\n#        containerPath: /data\n\n")),(0,o.kt)("h2",{id:"developing-and-debugging-with-linkis-containerized-components"},"Developing and Debugging with Linkis Containerized Components"),(0,o.kt)("p",null,"The following steps describe how to develop and debug using Linkis containerized components (currently only supported for Linux and MacOS). Please confirm the following before proceeding."),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"whether the Docker engine is already installed on the development machine"),(0,o.kt)("li",{parentName:"ol"},"whether Helm is installed on the development machine "),(0,o.kt)("li",{parentName:"ol"},"whether KinD has been installed on the development machine "),(0,o.kt)("li",{parentName:"ol"},"whether the Linkis image has been created as described in ",(0,o.kt)("a",{parentName:"li",href:"https://linkis.apache.org/zh-CN/docs/latest/development/linkis_docker_build_instrument"},"Linkis Docker image packaging"))),(0,o.kt)("h3",{id:"create-debugging-environment"},"Create Debugging Environment"),(0,o.kt)("p",null,"This step will create a KinD cluster and deploy MySQL, Linkis and LDH instances on it."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},'$> cd linkis-dist/helm\n$> sh ./scripts/create-kind-cluster.sh \\\n>    && sh ./scripts/install-mysql.sh \\\n>    && sh ./scripts/install-ldh.sh \\\n>    && sh ./scripts/install-charts-with-ldh.sh\n\n# Creating KinD cluster ...\n- kind cluster config: /var/folders/9d/bb6ggdm177j25q40yf5d50dm0000gn/T/kind-XXXXX.Fc2dFJbG/kind-cluster.yaml\n...\nkind: Cluster\napiVersion: kind.x-k8s.io/v1alpha4\nnodes:\n  - role: control-plane\n    extraMounts:\n      - hostPath: /var/folders/9d/bb6ggdm177j25q40yf5d50dm0000gn/T/kind-XXXXX.Fc2dFJbG/data\n        containerPath: /data\n...\nCreating cluster "test-helm" ...\n \u2713 Ensuring node image (kindest/node:v1.21.1) \ud83d\uddbc \n \u2713 Preparing nodes \ud83d\udce6  \n \u2713 Writing configuration \ud83d\udcdc \n \u2713 Starting control-plane \ud83d\udd79\ufe0f \n \u2713 Installing CNI \ud83d\udd0c \n \u2713 Installing StorageClass \ud83d\udcbe \nSet kubectl context to "kind-test-helm"\nYou can now use your cluster with:\n\nkubectl cluster-info --context kind-test-helm\n\nHave a nice day! \ud83d\udc4b\n# Loading MySQL image ...\nImage: "mysql:5.7" with ID "sha256:3147495b3a5ce957dee2319099a8808c1418e0b0a2c82c9b2396c5fb4b688509" not yet present on node "test-helm-control-plane", loading...\n# Deploying MySQL ...\nnamespace/mysql created\nservice/mysql created\ndeployment.apps/mysql created\n# LDH version: dev\n# Loading LDH image ...\nImage: "linkis-ldh:dev" with ID "sha256:aa3bde0a31bf704413fb75673fc2894b03a0840473d8fe15e2d7f7dd22f1f854" not yet present on node "test-helm-control-plane", loading...\n# Deploying LDH ...\nnamespace/ldh created\nconfigmap/flink-conf created\nconfigmap/hadoop-conf created\nconfigmap/hive-conf created\nconfigmap/spark-conf created\nconfigmap/zookeeper-conf created\nservice/ldh created\ndeployment.apps/ldh created\n# Loading Linkis image ...\nImage: "linkis:dev" with ID "sha256:0dfa7882c4216305a80cf57efa8cfb483d006bae5ba931288ffb8025e1db4e58" not yet present on node "test-helm-control-plane", loading...\nImage: "linkis-web:dev" with ID "sha256:1dbe0e9319761dbe0e93197665d38077cb2432b8b755dee834928694875c8a22" not yet present on node "test-helm-control-plane", loading...\n# Installing linkis, image tag=dev,local mode=false ...\nNAME: linkis-demo\nNAMESPACE: linkis\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\nNOTES:\n...\n\n---\nWelcome to Apache Linkis (v1.3.0)!\n\n.___    .___ .______  .____/\\ .___ .________\n|   |   : __|:      \\ :   /  \\: __||    ___/\n|   |   | : ||       ||.  ___/| : ||___    \\\n|   |/\\ |   ||   |   ||     \\ |   ||       /\n|   /  \\|   ||___|   ||      \\|   ||__:___/\n|______/|___|    |___||___\\  /|___|   : v1.3.0\n                           \\/\n\nLinkis builds a layer of computation middleware between upper applications and underlying engines.\nPlease visit https://linkis.apache.org/ for details.\n\nEnjoy!\nconfigmap/flink-conf created\nconfigmap/hadoop-conf created\nconfigmap/hive-conf created\nconfigmap/spark-conf created\nconfigmap/zookeeper-conf created\n\n$> kubectl get pods -n ldh -o wide\nNAME                   READY   STATUS    RESTARTS   AGE     IP           NODE                      NOMINATED NODE   READINESS GATES\nldh-6648554447-ml2bn   1/1     Running   0          6m25s   10.244.0.6   test-helm-control-plane   <none>           <none>\n\n$> kubectl get pods -n linkis -o wide\nNAME                                                READY   STATUS             RESTARTS   AGE     IP            NODE                      NOMINATED NODE   READINESS GATES\ninit-db-bcp85                                       0/1     Completed          0          4m52s   10.244.0.14   test-helm-control-plane   <none>           <none>\nlinkis-demo-cg-engineconnmanager-659bf85689-ddvhw   1/1     Running            1          4m52s   10.244.0.7    test-helm-control-plane   <none>           <none>\nlinkis-demo-cg-engineplugin-98bd6945-tsgjl          1/1     Running            1          4m52s   10.244.0.10   test-helm-control-plane   <none>           <none>\nlinkis-demo-cg-entrance-858f74c868-xrd82            1/1     Running            0          4m52s   10.244.0.12   test-helm-control-plane   <none>           <none>\nlinkis-demo-cg-linkismanager-6f96f69b8b-ns6st       1/1     Running            0          4m52s   10.244.0.11   test-helm-control-plane   <none>           <none>\nlinkis-demo-mg-eureka-0                             1/1     Running            0          4m52s   10.244.0.13   test-helm-control-plane   <none>           <none>\nlinkis-demo-mg-gateway-68ddb8c547-xgvhn             1/1     Running            0          4m52s   10.244.0.15   test-helm-control-plane   <none>           <none>\nlinkis-demo-ps-publicservice-6bbf99fcd7-sc922       1/1     Running            0          4m52s   10.244.0.8    test-helm-control-plane   <none>           <none>\nlinkis-demo-web-554bd7659f-nmdjl                    1/1     Running            0          4m52s   10.244.0.9    test-helm-control-plane   <none>           <none>\n\n')),(0,o.kt)("h3",{id:"debugging-components"},"Debugging Components"),(0,o.kt)("h4",{id:"enable-port-forwarding"},"Enable Port Forwarding"),(0,o.kt)("p",null,"Each component has a JVM remote debug port of 5005 within the container, and these ports are mapped to different ports on the host as follows."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"mg-eureka: 5001"),(0,o.kt)("li",{parentName:"ul"},"mg-gateway: 5002"),(0,o.kt)("li",{parentName:"ul"},"ps-publicservice: 5004"),(0,o.kt)("li",{parentName:"ul"},"cg-linkismanager: 5007"),(0,o.kt)("li",{parentName:"ul"},"cg-entrance: 5008"),(0,o.kt)("li",{parentName:"ul"},"cg-engineconnmanager: 5009"),(0,o.kt)("li",{parentName:"ul"},"cg-engineplugin: 5010")),(0,o.kt)("p",null,"In addition, the Web Console is mapped to port 8087 on the host, which can be accessed by typing ",(0,o.kt)("inlineCode",{parentName:"p"},"http://localhost:8087")," in your browser."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"$> ./scripts/remote-debug-proxy.sh start      \n- starting port-forwad for [web] with mapping [local->8087:8087->pod] ...\n- starting port-forwad for [mg-eureka] with mapping [local->5001:5005->pod] ...\n- starting port-forwad for [mg-gateway] with mapping [local->5002:5005->pod] ...\n- starting port-forwad for [ps-publicservice] with mapping [local->5004:5005->pod] ...\n- starting port-forwad for [cg-linkismanager] with mapping [local->5007:5005->pod] ...\n- starting port-forwad for [cg-entrance] with mapping [local->5008:5005->pod] ...\n- starting port-forwad for [cg-engineconnmanager] with mapping [local->5009:5005->pod] ...\n- starting port-forwad for [cg-engineplugin] with mapping [local->5010:5005->pod] ..\n\n$> ./scripts/remote-debug-proxy.sh list \nuser            10972   0.0  0.1  5052548  31244 s001  S    12:57AM   0:00.10 kubectl port-forward -n linkis pod/linkis-demo-cg-engineplugin-98bd6945-tsgjl 5010:5005 --address=0.0.0.0\nuser            10970   0.0  0.1  5053060  30988 s001  S    12:57AM   0:00.12 kubectl port-forward -n linkis pod/linkis-demo-cg-engineconnmanager-659bf85689-ddvhw 5009:5005 --address=0.0.0.0\nuser            10968   0.0  0.1  5054084  30428 s001  S    12:57AM   0:00.10 kubectl port-forward -n linkis pod/linkis-demo-cg-entrance-858f74c868-xrd82 5008:5005 --address=0.0.0.0\nuser            10966   0.0  0.1  5053316  30620 s001  S    12:57AM   0:00.11 kubectl port-forward -n linkis pod/linkis-demo-cg-linkismanager-6f96f69b8b-ns6st 5007:5005 --address=0.0.0.0\nuser            10964   0.0  0.1  5064092  31152 s001  S    12:57AM   0:00.10 kubectl port-forward -n linkis pod/linkis-demo-ps-publicservice-6bbf99fcd7-sc922 5004:5005 --address=0.0.0.0\nuser            10962   0.0  0.1  5051012  31244 s001  S    12:57AM   0:00.12 kubectl port-forward -n linkis pod/linkis-demo-mg-gateway-68ddb8c547-xgvhn 5002:5005 --address=0.0.0.0\nuser            10960   0.0  0.1  5053060  31312 s001  S    12:57AM   0:00.13 kubectl port-forward -n linkis pod/linkis-demo-mg-eureka-0 5001:5005 --address=0.0.0.0\n\n...\n\n# After debugging is complete, you can stop port forwarding with the following command\n$> ./scripts/remote-debug-proxy.sh stop \n- stopping port-forward for [web] with mapping [local->8087:8087->pod] ...\n- stopping port-forward for [mg-eureka] with mapping [local->5001:5005->pod] ...\n- stopping port-forward for [mg-gateway] with mapping [local->5002:5005->pod] ...\n- stopping port-forward for [ps-publicservice] with mapping [local->5004:5005->pod] ...\n- stopping port-forward for [cg-linkismanager] with mapping [local->5007:5005->pod] ...\n- stopping port-forward for [cg-entrance] with mapping [local->5008:5005->pod] ...\n- stopping port-forward for [cg-engineconnmanager] with mapping [local->5009:5005->pod] ...\n- stopping port-forward for [cg-engineplugin] with mapping [local->5010:5005->pod] ...\n")),(0,o.kt)("h4",{id:"configure-the-ide-for-remote-debugging"},"Configure the IDE for Remote Debugging"),(0,o.kt)("p",null,"Configure the IDE as follows to enable remote debugging:"),(0,o.kt)("p",null,(0,o.kt)("img",{src:t(62168).Z})),(0,o.kt)("p",null,"Turn on remote debugger\n",(0,o.kt)("img",{src:t(56150).Z})),(0,o.kt)("p",null,"Set a breakpoint and submit a job for debugging"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},'$> ./scripts/login-pod.sh mg-gateway\n\n- login [mg-gateway]\'s bash ...\nbash-4.2$ ./bin/./linkis-cli -engineType shell-1 -codeType shell -code "echo \\"hello\\" "  -submitUser hadoop -proxyUser hadoop\n=====Java Start Command=====\nexec /etc/alternatives/jre/bin/java -server -Xms32m -Xmx2048m -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/opt/linkis/logs/linkis-cli -XX:ErrorFile=/opt/linkis/logs/linkis-cli/ps_err_pid%p.log -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=80 -XX:+DisableExplicitGC    -classpath /opt/linkis/conf/linkis-cli:/opt/linkis/lib/linkis-computation-governance/linkis-client/linkis-cli/*:/opt/linkis/lib/linkis-commons/public-module/*: -Dconf.root=/etc/linkis-conf -Dconf.file=linkis-cli.properties -Dlog.path=/opt/linkis/logs/linkis-cli -Dlog.file=linkis-client..log.20220925171540947077800  org.apache.linkis.cli.application.LinkisClientApplication \'-engineType shell-1 -codeType shell -code echo "hello"  -submitUser hadoop -proxyUser hadoop\'\n...\n')),(0,o.kt)("p",null,(0,o.kt)("img",{src:t(42336).Z})),(0,o.kt)("h3",{id:"clean-up-the-environment"},"Clean Up the Environment"),(0,o.kt)("p",null,"After debugging, you can use the following command to clean up the entire environment:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},'$> kind delete clusters test-helm                                              \nDeleted clusters: ["test-helm"]\n')),(0,o.kt)("h3",{id:"other-useful-operations"},"Other Useful Operations"),(0,o.kt)("h4",{id:"fetch-logs"},"Fetch Logs"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"$> kubectl logs -n linkis linkis-demo-cg-engineconnmanager-659bf85689-ddvhw -f\n\n+ RUN_IN_FOREGROUND=true\n+ /opt/linkis/sbin/linkis-daemon.sh start cg-engineconnmanager\nStart to check whether the cg-engineconnmanager is running\nStart server, startup script:  /opt/linkis/sbin/ext/linkis-cg-engineconnmanager\n=====Java Start Command=====\njava   -DserviceName=linkis-cg-engineconnmanager -Xmx512M -XX:+UseG1GC -Xloggc:/var/logs/linkis/linkis-cg-engineconnmanager-gc.log -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005  -cp /etc/linkis-conf:/opt/linkis/lib/linkis-commons/public-module/*:/opt/linkis/lib/linkis-computation-governance/linkis-cg-engineconnmanager/* org.apache.linkis.ecm.server.LinkisECMApplication  --eureka.instance.prefer-ip-address=true  --eureka.instance.instance-id=${spring.cloud.client.ip-address}:${spring.application.name}:${server.port} 2>&1\nOpenJDK 64-Bit Server VM warning: If the number of processors is expected to increase from one, then you should configure the number of parallel GC threads appropriately using -XX:ParallelGCThreads=N\nListening for transport dt_socket at address: 5005\n16:32:41.101 [main] INFO  org.apache.linkis.common.conf.BDPConfiguration$ - ******************* Notice: The Linkis configuration file is linkis.properties ! *******************\n16:32:41.130 [main] INFO  org.apache.linkis.common.conf.BDPConfiguration$ - *********************** Notice: The Linkis serverConf file is linkis-cg-engineconnmanager.properties ! ******************\n16:32:41.222 [main] INFO  org.apache.linkis.LinkisBaseServerApp - Ready to start linkis-cg-engineconnmanager with args: --eureka.instance.prefer-ip-address=true\n--eureka.instance.instance-id=${spring.cloud.client.ip-address}:${spring.application.name}:${server.port}\n...\n")),(0,o.kt)("h4",{id:"entry-into-the-component-pod"},"Entry into the Component Pod"),(0,o.kt)("p",null,"Use ",(0,o.kt)("inlineCode",{parentName:"p"},". /scripts/login-pod.sh <component name>")," to access the component's Pod to open a Bash for interactive operation, where the component name can be :"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"cg-engineconnmanager"),(0,o.kt)("li",{parentName:"ul"},"cg-engineplugin"),(0,o.kt)("li",{parentName:"ul"},"cg-entrance"),(0,o.kt)("li",{parentName:"ul"},"cg-linkismanager"),(0,o.kt)("li",{parentName:"ul"},"mg-eureka"),(0,o.kt)("li",{parentName:"ul"},"mg-gateway"),(0,o.kt)("li",{parentName:"ul"},"ps-publicservice"),(0,o.kt)("li",{parentName:"ul"},"web")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"$> ./scripts/login-pod.sh cg-engineconnmanager\n- login [cg-engineconnmanager]'s bash ...\nbash-4.2$ pwd\n/opt/linkis\nbash-4.2$  env |grep LINKIS\nLINKIS_DEMO_PS_PUBLICSERVICE_SERVICE_HOST=10.96.93.45\nLINKIS_DEMO_CG_LINKISMANAGER_PORT_9101_TCP_PROTO=tcp\nLINKIS_DEMO_WEB_PORT_8087_TCP_PORT=8087\n...\nLINKIS_CLIENT_CONF_DIR=/etc/linkis-conf\nbash-4.2$ ps aux |grep linkis\nhadoop         1  0.0  0.0  11708  2664 ?        Ss   16:32   0:00 /bin/bash /opt/linkis/sbin/linkis-daemon.sh start cg-engineconnmanager\nhadoop        10  0.0  0.0  11708  2624 ?        S    16:32   0:00 sh /opt/linkis/sbin/ext/linkis-cg-engineconnmanager\nhadoop        11  0.0  0.0  11712  2536 ?        S    16:32   0:00 sh /opt/linkis/sbin/ext/linkis-common-start\nhadoop        12  4.0  3.2 4146404 400084 ?      Sl   16:32   0:35 java -DserviceName=linkis-cg-engineconnmanager -Xmx512M -XX:+UseG1GC -Xloggc:/var/logs/linkis/linkis-cg-engineconnmanager-gc.log -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005 -cp /etc/linkis-conf:/opt/linkis/lib/linkis-commons/public-module/*:/opt/linkis/lib/linkis-computation-governance/linkis-cg-engineconnmanager/* org.apache.linkis.ecm.server.LinkisECMApplication --eureka.instance.prefer-ip-address=true --eureka.instance.instance-id=${spring.cloud.client.ip-address}:${spring.application.name}:${server.port}\nbash-4.2$ exit\nexit\n")))}p.isMDXComponent=!0},86278:(e,n,t)=>{t.d(n,{Z:()=>i});const i=t.p+"assets/images/kind-arc-02ed1f9367e7e49f600fa20cf3cf952f.png"},42336:(e,n,t)=>{t.d(n,{Z:()=>i});const i=t.p+"assets/images/kube-jvm-remote-debug-breakpoint-2e8a5c98809db9e83cab0d249ee1e042.png"},56150:(e,n,t)=>{t.d(n,{Z:()=>i});const i=t.p+"assets/images/kube-jvm-remote-debug-start-0d2691c107f093e17c24113050336d4a.png"},62168:(e,n,t)=>{t.d(n,{Z:()=>i});const i=t.p+"assets/images/kube-jvm-remote-debug-0fbc0ecd7d2d6950369e95c80712c59f.png"}}]);