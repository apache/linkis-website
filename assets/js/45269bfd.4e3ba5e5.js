"use strict";(self.webpackChunklinkis_web_apache=self.webpackChunklinkis_web_apache||[]).push([[72744],{3905:(e,t,n)=>{n.d(t,{Zo:()=>d,kt:()=>m});var a=n(67294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var l=a.createContext({}),p=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},d=function(e){var t=p(e.components);return a.createElement(l.Provider,{value:t},e.children)},c="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},h=a.forwardRef((function(e,t){var n=e.components,i=e.mdxType,o=e.originalType,l=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),c=p(n),h=i,m=c["".concat(l,".").concat(h)]||c[h]||u[h]||o;return n?a.createElement(m,r(r({ref:t},d),{},{components:n})):a.createElement(m,r({ref:t},d))}));function m(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var o=n.length,r=new Array(o);r[0]=h;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[c]="string"==typeof e?e:i,r[1]=s;for(var p=2;p<o;p++)r[p]=n[p];return a.createElement.apply(null,r)}return a.createElement.apply(null,n)}h.displayName="MDXCreateElement"},26472:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>u,frontMatter:()=>o,metadata:()=>s,toc:()=>p});var a=n(87462),i=(n(67294),n(3905));const o={title:"Stand-alone deployment",sidebar_position:1},r=void 0,s={unversionedId:"deployment/deploy-quick",id:"deployment/deploy-quick",title:"Stand-alone deployment",description:"1. First-time installation preparations",source:"@site/docs/deployment/deploy-quick.md",sourceDirName:"deployment",slug:"/deployment/deploy-quick",permalink:"/docs/1.5.0/deployment/deploy-quick",draft:!1,editUrl:"https://github.com/apache/linkis-website/edit/dev/docs/deployment/deploy-quick.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{title:"Stand-alone deployment",sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"Deploy without HDFS",permalink:"/docs/1.5.0/quick/deploy-without-hdfs"},next:{title:"Cluster Deployment",permalink:"/docs/1.5.0/deployment/deploy-cluster"}},l={},p=[{value:"1. First-time installation preparations",id:"1-first-time-installation-preparations",level:2},{value:"1.1 Linux server",id:"11-linux-server",level:3},{value:"1.2 Add deployment user",id:"12-add-deployment-user",level:3},{value:"2. Configuration modification",id:"2-configuration-modification",level:2},{value:"2.1 Installation package preparation",id:"21-installation-package-preparation",level:3},{value:"2.2 Configure database information",id:"22-configure-database-information",level:3},{value:"2.3 Configure basic variables",id:"23-configure-basic-variables",level:3},{value:"Deploy User",id:"deploy-user",level:4},{value:"Basic directory configuration (optional)",id:"basic-directory-configuration-optional",level:4},{value:"Yarn&#39;s ResourceManager address",id:"yarns-resourcemanager-address",level:4},{value:"Basic component environment information",id:"basic-component-environment-information",level:4},{value:"LDAP login configuration (optional)",id:"ldap-login-configuration-optional",level:4},{value:"JVM memory configuration (optional)",id:"jvm-memory-configuration-optional",level:4},{value:"Installation directory configuration (optional)",id:"installation-directory-configuration-optional",level:4},{value:"No HDFS mode deployment (optional &gt;1.1.2 version support)",id:"no-hdfs-mode-deployment-optional-112-version-support",level:4},{value:"kerberos authentication (optional)",id:"kerberos-authentication-optional",level:4},{value:"2.4 Configure Token",id:"24-configure-token",level:3},{value:"2.5 Precautions",id:"25-precautions",level:3},{value:"3. Install and start",id:"3-install-and-start",level:2},{value:"3.1 Execute the installation script:",id:"31-execute-the-installation-script",level:3},{value:'<font color="red">3.2 Add mysql driver package</font>',id:"32-add-mysql-driver-package",level:3},{value:"3.3 Add postgresql driver package (optional)",id:"33-add-postgresql-driver-package-optional",level:3},{value:"3.4 Configuration adjustment (optional)",id:"34-configuration-adjustment-optional",level:3},{value:"3.4.1 Yarn authentication",id:"341-yarn-authentication",level:4},{value:"3.4.2 session",id:"342-session",level:4},{value:"3.4.3 S3 mode",id:"343-s3-mode",level:4},{value:"3.5 Start the service",id:"35-start-the-service",level:3},{value:"3.6 Modification of configuration after installation",id:"36-modification-of-configuration-after-installation",level:3},{value:"3.7 Check whether the service starts normally",id:"37-check-whether-the-service-starts-normally",level:3},{value:"3.8 Configure Token",id:"38-configure-token",level:3},{value:"View Token",id:"view-token",level:4},{value:"Check Token configuration",id:"check-token-configuration",level:4},{value:"4. Install the web front end",id:"4-install-the-web-front-end",level:2},{value:"4.1 Download the front-end installation package and decompress it",id:"41-download-the-front-end-installation-package-and-decompress-it",level:3},{value:"4.2 Modify configuration config.sh",id:"42-modify-configuration-configsh",level:3},{value:"4.3 Execute the deployment script",id:"43-execute-the-deployment-script",level:3},{value:"4.4 Log in to the management console",id:"44-log-in-to-the-management-console",level:3},{value:"5. Verify basic functions",id:"5-verify-basic-functions",level:2},{value:"6. Installation of development tool IDE (Scriptis) (optional)",id:"6-installation-of-development-tool-ide-scriptis-optional",level:2},{value:"7. Supported engines",id:"7-supported-engines",level:2},{value:"7.1 Engine adaptation list",id:"71-engine-adaptation-list",level:3},{value:"7.2 View deployed engines",id:"72-view-deployed-engines",level:3},{value:"Method 1: View the engine lib package directory",id:"method-1-view-the-engine-lib-package-directory",level:4},{value:"Method 2: View the database table of linkis",id:"method-2-view-the-database-table-of-linkis",level:4},{value:"8. Troubleshooting guidelines for common abnormal problems",id:"8-troubleshooting-guidelines-for-common-abnormal-problems",level:2},{value:"8.1. Yarn queue check",id:"81-yarn-queue-check",level:3},{value:"8.1.1 Check whether the yarn address is configured correctly",id:"811-check-whether-the-yarn-address-is-configured-correctly",level:4},{value:"8.1.2 Check whether the yarn queue exists",id:"812-check-whether-the-yarn-queue-exists",level:4},{value:"8.2 Check whether the engine material resources are uploaded successfully",id:"82-check-whether-the-engine-material-resources-are-uploaded-successfully",level:3},{value:"8.3 Login password problem",id:"83-login-password-problem",level:3},{value:"8.4 version compatibility issues",id:"84-version-compatibility-issues",level:3},{value:"8.5 How to locate server-side exception logs",id:"85-how-to-locate-server-side-exception-logs",level:3},{value:"8.6 Execution engine task exception troubleshooting",id:"86-execution-engine-task-exception-troubleshooting",level:3},{value:"8.7 How to modify the port of the registration center eureka",id:"87-how-to-modify-the-port-of-the-registration-center-eureka",level:3},{value:"8.8 Notes for CDH adaptation version",id:"88-notes-for-cdh-adaptation-version",level:3},{value:"8.9 Debugging of Http interface",id:"89-debugging-of-http-interface",level:3},{value:"8.10 Troubleshooting process for abnormal problems",id:"810-troubleshooting-process-for-abnormal-problems",level:3},{value:"9. How to obtain relevant information",id:"9-how-to-obtain-relevant-information",level:2}],d={toc:p},c="wrapper";function u(e){let{components:t,...o}=e;return(0,i.kt)(c,(0,a.Z)({},d,o,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h2",{id:"1-first-time-installation-preparations"},"1. First-time installation preparations"),(0,i.kt)("h3",{id:"11-linux-server"},"1.1 Linux server"),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Hardware Requirements"),(0,i.kt)("br",{parentName:"p"}),"\n","Install nearly 6 linkis microservices, at least 3G memory. The default jvm -Xmx memory size of each microservice is 512M (if the memory is not enough, you can try to reduce it to 256/128M, and you can also increase it if the memory is enough)."),(0,i.kt)("h3",{id:"12-add-deployment-user"},"1.2 Add deployment user"),(0,i.kt)("blockquote",null,(0,i.kt)("p",{parentName:"blockquote"},"Deployment user: The starting user of the linkis core process, and this user will be the administrator by default. ",(0,i.kt)("font",{color:"red"},"The corresponding administrator login password will be generated during the deployment process, located in ",(0,i.kt)("inlineCode",{parentName:"p"},"conf/linkis-mg-gateway .properties"),"file"),"\nLinkis supports specifying users for submission and execution. The linkis main process service will switch to the corresponding user through ",(0,i.kt)("inlineCode",{parentName:"p"},"sudo -u ${linkis-user}"),", and then execute the corresponding engine start command, so the user of the engine ",(0,i.kt)("inlineCode",{parentName:"p"},"linkis-engine")," process is the executor of the task (so the deployment The user needs to have sudo authority, and it is password-free).")),(0,i.kt)("p",null,"Take hadoop users as an example (",(0,i.kt)("font",{color:"red"},"Many configuration users in linkis use hadoop users by default. It is recommended that first-time installers use hadoop users, otherwise many unexpected errors may be encountered during the installation process"),"):"),(0,i.kt)("p",null,"First check whether there is already a hadoop user in the system, if it already exists, just authorize it directly, if not, create a user first, and then authorize."),(0,i.kt)("p",null,"Check if hadoop user already exists"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"$ id hadoop\nuid=2001(hadoop) gid=2001(hadoop) groups=2001(hadoop)\n")),(0,i.kt)("p",null,"If it does not exist, you need to create a hadoop user and join the hadoop user group"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"$ sudo useradd hadoop -g hadoop\n$ vi /etc/sudoers\n#Secret-free configuration\nhadoop ALL=(ALL) NOPASSWD: NOPASSWD: ALL\n")),(0,i.kt)("font",{color:"red"},"The following operations are performed under the hadoop user"),(0,i.kt)("h2",{id:"2-configuration-modification"},"2. Configuration modification"),(0,i.kt)("h3",{id:"21-installation-package-preparation"},"2.1 Installation package preparation"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Method 1: From the official website ","[download address]"," (",(0,i.kt)("a",{parentName:"li",href:"https://linkis.apache.org/zh-CN/download/main"},"https://linkis.apache.org/zh-CN/download/main"),"): ",(0,i.kt)("a",{parentName:"li",href:"https://linkis.apache.org/zh-CN/download/main"},"https://linkis.apache.org/zh-CN/download/main"),"\n, download the corresponding installation package (project installation package and management console installation package)."),(0,i.kt)("li",{parentName:"ul"},"Method 2: Compile the project installation package and console installation package according to ",(0,i.kt)("a",{parentName:"li",href:"../development/build"},"Linkis Compilation and Packaging")," and ",(0,i.kt)("a",{parentName:"li",href:"../development/build-console"},"Front-end Console Compilation"),".")),(0,i.kt)("p",null,"After uploading the installation package ",(0,i.kt)("inlineCode",{parentName:"p"},"apache-linkis-xxx-bin.tar.gz"),", decompress the installation package"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"$ tar -xvf apache-linkis-xxx-bin.tar.gz\n")),(0,i.kt)("p",null,"The directory structure after decompression is as follows"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"-rw-r--r-- 1 hadoop hadoop 518192043 Jun 20 09:50 apache-linkis-xxx-bin.tar.gz\ndrwxrwxr-x 2 hadoop hadoop 4096 Jun 20 09:56 bin //execute environment check and install script\ndrwxrwxr-x 2 hadoop hadoop 4096 Jun 20 09:56 deploy-config // Deployment dependent DB and other environment configuration information\ndrwxrwxr-x 4 hadoop hadoop 4096 Jun 20 09:56 docker\ndrwxrwxr-x 4 hadoop hadoop 4096 Jun 20 09:56 helm\n-rwxrwxr-x 1 hadoop hadoop 84732 Jan 22 2020 LICENSE\ndrwxr-xr-x 2 hadoop hadoop 20480 Jun 20 09:56 licenses\ndrwxrwxr-x 7 hadoop hadoop 4096 Jun 20 09:56 linkis-package // actual software package, including lib/service startup script tool/db initialization script/microservice configuration file, etc.\n-rwxrwxr-x 1 hadoop hadoop 119503 Jan 22 2020 NOTICE\n-rw-r--r-- 1 hadoop hadoop 11959 Jan 22 2020 README_CN.md\n-rw-r--r-- 1 hadoop hadoop 12587 Jan 22 2020 README.md\n\n")),(0,i.kt)("h3",{id:"22-configure-database-information"},"2.2 Configure database information"),(0,i.kt)("p",null,(0,i.kt)("inlineCode",{parentName:"p"},"vim deploy-config/linkis-env.sh")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"# Select linkis business database type, default mysql\n# If using postgresql, please change to postgresql\n# Note: The current configuration only applies to linkis>=1.4.0\ndbType=mysql\n")),(0,i.kt)("p",null,(0,i.kt)("inlineCode",{parentName:"p"},"vim deploy-config/db.sh")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"# Linkis's own business database information - mysql\nMYSQL_HOST=xx.xx.xx.xx\nMYSQL_PORT=3306\nMYSQL_DB=linkis_test\nMYSQL_USER=test\nMYSQL_PASSWORD=xxxxx\n\n# Linkis's own business database information - postgresql\n# Note: The following configuration is only applicable to linkis>=1.4.0\nPG_HOST=xx.xx.xx.xx\nPG_PORT=5432\nPG_DB=linkis_test\nPG_SCHEMA=linkis_test\nPG_USER=test\nPG_PASSWORD=123456\n\n# Provide the DB information of the Hive metadata database. If the hive engine is not involved (or just a simple trial), it is not necessary to configure\n#Mainly used together with scriptis, if not configured, it will try to get it through the configuration file in $HIVE_CONF_DIR by default\nHIVE_META_URL=\"jdbc:mysql://10.10.10.10:3306/hive_meta_demo?useUnicode=true&characterEncoding=UTF-8\"\nHIVE_META_USER=demo # User of the HiveMeta metabase\nHIVE_META_PASSWORD=demo123 # Password of the HiveMeta metabase\n")),(0,i.kt)("h3",{id:"23-configure-basic-variables"},"2.3 Configure basic variables"),(0,i.kt)("p",null,"The file is located at ",(0,i.kt)("inlineCode",{parentName:"p"},"deploy-config/linkis-env.sh"),"."),(0,i.kt)("h4",{id:"deploy-user"},"Deploy User"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"deployUser=hadoop #The user who executes the deployment is the user created in step 1.2\n")),(0,i.kt)("h4",{id:"basic-directory-configuration-optional"},"Basic directory configuration (optional)"),(0,i.kt)("admonition",{title:"Caution",type:"caution"},(0,i.kt)("p",{parentName:"admonition"},"Determine whether it needs to be adjusted according to the actual situation, and you can choose to use the default value")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"\n# Specify the directory path used by the user, which is generally used to store the user's script files and log files, etc., and is the user's workspace. The corresponding configuration file configuration item is wds.linkis.filesystem.root.path(linkis.properties)\nWORKSPACE_USER_ROOT_PATH=file:///tmp/linkis\n\n# The result set log and other file paths are used to store the result set file of the Job wds.linkis.resultSet.store.path(linkis-cg-entrance.properties) //If the configuration of HDFS_USER_ROOT_PATH is not configured\nRESULT_SET_ROOT_PATH=file:///tmp/linkis\n\n# Result set log and other file paths, used to store the result set file of Job wds.linkis.filesystem.hdfs.root.path(linkis.properties)\nHDFS_USER_ROOT_PATH=hdfs:///tmp/linkis\n  \n# To store the working path of the execution engine, a local directory wds.linkis.engineconn.root.dir(linkis-cg-engineconnmanager.properties) where the deployment user has write permissions is required\nENGINECONN_ROOT_PATH=/appcom/tmp\n")),(0,i.kt)("h4",{id:"yarns-resourcemanager-address"},"Yarn's ResourceManager address"),(0,i.kt)("admonition",{title:"Caution",type:"caution"},(0,i.kt)("p",{parentName:"admonition"},"If you need to use the Spark engine, you need to configure")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"\n#You can check whether it can be accessed normally by visiting http://xx.xx.xx.xx:8088/ws/v1/cluster/scheduler interface\nYARN_RESTFUL_URL=http://xx.xx.xx.xx:8088\n")),(0,i.kt)("p",null,"When executing the spark task, you need to use the ResourceManager of yarn. Linkis defaults that permission verification is not enabled. If the ResourceManager has enabled password permission verification, please install and deploy.\nModify the database table ",(0,i.kt)("inlineCode",{parentName:"p"},"linkis_cg_rm_external_resource_provider")," to insert yarn data information, for details, please refer to ","[Check whether the yarn address is configured correctly]"," (#811-Check whether the yarn address is configured correctly)"),(0,i.kt)("h4",{id:"basic-component-environment-information"},"Basic component environment information"),(0,i.kt)("admonition",{title:"Caution",type:"caution"},(0,i.kt)("p",{parentName:"admonition"},"It can be configured through the user's system environment variables. If it is configured through the system environment variables, it can be commented out directly without configuration in the deploy-config/linkis-env.sh configuration file.")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"##If you do not use Hive, Spark and other engines and do not rely on Hadoop, you do not need to configure the following environment variables\n\n#HADOOP  \nHADOOP_HOME=/appcom/Install/hadoop\nHADOOP_CONF_DIR=/appcom/config/hadoop-config\n\n#Hive\nHIVE_HOME=/appcom/Install/hive\nHIVE_CONF_DIR=/appcom/config/hive-config\n\n#Spark\nSPARK_HOME=/appcom/Install/spark\nSPARK_CONF_DIR=/appcom/config/spark-config\n")),(0,i.kt)("h4",{id:"ldap-login-configuration-optional"},"LDAP login configuration (optional)"),(0,i.kt)("admonition",{title:"Caution",type:"caution"},(0,i.kt)("p",{parentName:"admonition"},"The default is to use a static user and password. The static user is the deployment user. The static password will randomly generate a password string during deployment and store it in ",(0,i.kt)("inlineCode",{parentName:"p"},"${LINKIS_HOME}/conf/linkis-mg-gateway.properties"),"(>=1.0. 3 version).")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"#LDAP configuration, by default Linkis only supports deployment user login, if you need to support multi-user login, you can use LDAP, you need to configure the following parameters:\n#LDAP_URL=ldap://localhost:1389/\n#LDAP_BASEDN=dc=webank,dc=com\n")),(0,i.kt)("h4",{id:"jvm-memory-configuration-optional"},"JVM memory configuration (optional)"),(0,i.kt)("blockquote",null,(0,i.kt)("p",{parentName:"blockquote"},"Microservice starts jvm memory configuration, which can be adjusted according to the actual situation of the machine. If the machine has less memory resources, you can try to reduce it to 256/128M"),(0,i.kt)("pre",{parentName:"blockquote"},(0,i.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},'## java application default jvm memory\nexport SERVER_HEAP_SIZE="512M"\n'))),(0,i.kt)("h4",{id:"installation-directory-configuration-optional"},"Installation directory configuration (optional)"),(0,i.kt)("blockquote",null,(0,i.kt)("p",{parentName:"blockquote"},"Linkis will eventually be installed in this directory, if not configured, it will be in the same directory as the current installation package by default")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"##The decompression directory and the installation directory need to be inconsistent\nLINKIS_HOME=/appcom/Install/LinkisInstall\n")),(0,i.kt)("h4",{id:"no-hdfs-mode-deployment-optional-112-version-support"},"No HDFS mode deployment (optional >1.1.2 version support)"),(0,i.kt)("blockquote",null,(0,i.kt)("p",{parentName:"blockquote"},"Deploy the Linkis service in an environment without HDFS to facilitate lighter learning, use and debugging. Deploying in HDFS mode does not support tasks such as hive/spark/flink engines")),(0,i.kt)("p",null,"Modify ",(0,i.kt)("inlineCode",{parentName:"p"},"linkis-env.sh")," file, modify the following content"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"#Use [file://] path pattern instead of [hdfs://] pattern\nWORKSPACE_USER_ROOT_PATH=file:///tmp/linkis/\nHDFS_USER_ROOT_PATH=file:///tmp/linkis\nRESULT_SET_ROOT_PATH=file:///tmp/linkis\n\nexport ENABLE_HDFS=false\nexport ENABLE_HIVE=false\nexport ENABLE_SPARK=false\n")),(0,i.kt)("h4",{id:"kerberos-authentication-optional"},"kerberos authentication (optional)"),(0,i.kt)("blockquote",null,(0,i.kt)("p",{parentName:"blockquote"},"Linkis does not enable kerberos authentication by default. If the hive cluster used enables kerberos authentication, the following parameters need to be configured.")),(0,i.kt)("p",null,"Modify the ",(0,i.kt)("inlineCode",{parentName:"p"},"linkis-env.sh")," file, the modified content is as follows"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"#HADOOP\nHADOOP_KERBEROS_ENABLE=true\nHADOOP_KEYTAB_PATH=/appcom/keytab/\n")),(0,i.kt)("h3",{id:"24-configure-token"},"2.4 Configure Token"),(0,i.kt)("p",null,"The file is located in ",(0,i.kt)("inlineCode",{parentName:"p"},"bin/install.sh")),(0,i.kt)("p",null,"Linkis 1.3.2 version has changed the Token value to 32-bit random generation to ensure system security. For details, please refer to ","[Token Change Description]","(",(0,i.kt)("a",{parentName:"p",href:"https://linkis.apache.org/zh-CN/docs/1.3.2/"},"https://linkis.apache.org/zh-CN/docs/1.3.2/")," feature/update-token/)."),(0,i.kt)("p",null,"Using randomly generated Token, you will encounter a lot of Token verification failure problems when connecting with ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/WeDataSphere/DataSphereStudio/blob/master/README-ZH.md"},"WDS other components")," for the first time. It is recommended to install it for the first time When not using random generated Token, modify the following configuration to true."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"DEBUG_MODE=true\n")),(0,i.kt)("h3",{id:"25-precautions"},"2.5 Precautions"),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Full installation")),(0,i.kt)("p",null,"For the full installation of the new version of Linkis, the install.sh script will automatically process the configuration file and keep the database Token consistent. Therefore, the Token of the Linkis service itself does not need to be modified. Each application can query and use the new token through the management console."),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"version upgrade")),(0,i.kt)("p",null,"When the version is upgraded, the database Token is not modified, so there is no need to modify the configuration file and application Token."),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Token expiration issue")),(0,i.kt)("p",null,"When the Token token is invalid or has expired, you can check whether the Token is configured correctly. You can query the Token through the management console ==> Basic Data Management ==> Token Management."),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Python version issue"),"\nAfter Linkis is upgraded to 1.4.0, the default Spark version is upgraded to 3.x, which is not compatible with python2. Therefore, if you need to use the pyspark function, you need to make the following modifications."),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"Map python2 commands to python3")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"sudo ln -snf /usr/bin/python3 /usr/bin/python2\n")),(0,i.kt)("ol",{start:2},(0,i.kt)("li",{parentName:"ol"},"Spark engine connector configuration $LINKIS_HOME/lib/linkis-engineconn-plugins/spark/dist/3.2.1/conf/linkis-engineconn.properties Add the following configuration to specify the python installation path")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"pyspark.python3.path=/usr/bin/python3\n")),(0,i.kt)("h2",{id:"3-install-and-start"},"3. Install and start"),(0,i.kt)("h3",{id:"31-execute-the-installation-script"},"3.1 Execute the installation script:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"    sh bin/install.sh\n")),(0,i.kt)("p",null,"The install.sh script will ask you if you want to initialize the database and import metadata. If you choose to initialize, the table data in the database will be cleared and reinitialized."),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},(0,i.kt)("font",{color:"red"},"You must choose to clear the database for the first installation"))),(0,i.kt)("admonition",{title:"note",type:"tip"},(0,i.kt)("ul",{parentName:"admonition"},(0,i.kt)("li",{parentName:"ul"},"If an error occurs, and it is not clear what command to execute to report the error, you can add the -x parameter ",(0,i.kt)("inlineCode",{parentName:"li"},"sh -x bin/install.sh")," to print out the log of the shell script execution process, which is convenient for locating the problem."),(0,i.kt)("li",{parentName:"ul"},"Permission problem: ",(0,i.kt)("inlineCode",{parentName:"li"},"mkdir: cannot create directory 'xxxx': Permission denied"),", please confirm whether the deployment user has read and write permissions for this path."))),(0,i.kt)("p",null,"The prompt for successful execution is as follows:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"`Congratulations! You have installed Linkis xxx successfully, please use sh /data/Install/linkis/sbin/linkis-start-all.sh to start it!  \nYour default account password is [hadoop/5e8e312b4]`\n")),(0,i.kt)("h3",{id:"32-add-mysql-driver-package"},(0,i.kt)("font",{color:"red"},"3.2 Add mysql driver package")),(0,i.kt)("admonition",{title:"Caution",type:"caution"},(0,i.kt)("p",{parentName:"admonition"},"Because the mysql-connector-java driver is under the GPL2.0 agreement, it does not meet the license policy of the Apache open source agreement. Therefore, starting from version 1.0.3, the official deployment package of the Apache version provided does not have mysql-connector-java-xxxjar by default. Dependency package (",(0,i.kt)("strong",{parentName:"p"},"If you install it through the integrated family bucket material package, you don\u2019t need to add it manually"),"), you need to add dependencies to the corresponding lib package yourself when installing and deploying. You can check whether it exists in the corresponding directory. If it does not exist, you need to add it.")),(0,i.kt)("p",null,"Download mysql driver Take version 8.0.28 as an example: ","[Download link]","(",(0,i.kt)("a",{parentName:"p",href:"https://repo1.maven.org/maven2/mysql/mysql-connector-java/8.0.28/mysql-connector-java-8.0.28"},"https://repo1.maven.org/maven2/mysql/mysql-connector-java/8.0.28/mysql-connector-java-8.0.28"),". jar)"),(0,i.kt)("p",null,"Copy the mysql driver package to the lib package"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"cp mysql-connector-java-8.0.28.jar ${LINKIS_HOME}/lib/linkis-spring-cloud-services/linkis-mg-gateway/\ncp mysql-connector-java-8.0.28.jar ${LINKIS_HOME}/lib/linkis-commons/public-module/\n")),(0,i.kt)("h3",{id:"33-add-postgresql-driver-package-optional"},"3.3 Add postgresql driver package (optional)"),(0,i.kt)("p",null,"If you choose to use postgresql as the business database, you need to manually add the postgresql driver\nDownload postgresql driver Take version 42.5.4 as an example: ",(0,i.kt)("a",{parentName:"p",href:"https://repo1.maven.org/maven2/org/postgresql/postgresql/42.5.4/postgresql-42.5.4.jar"},"Download link"),"\nCopy the postgresql driver package to the lib package"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"cp postgresql-42.5.4.jar ${LINKIS_HOME}/lib/linkis-spring-cloud-services/linkis-mg-gateway/\ncp postgresql-42.5.4.jar ${LINKIS_HOME}/lib/linkis-commons/public-module/\n")),(0,i.kt)("h3",{id:"34-configuration-adjustment-optional"},"3.4 Configuration adjustment (optional)"),(0,i.kt)("blockquote",null,(0,i.kt)("p",{parentName:"blockquote"},"The following operations are related to the dependent environment. According to the actual situation, determine whether the operation is required")),(0,i.kt)("h4",{id:"341-yarn-authentication"},"3.4.1 Yarn authentication"),(0,i.kt)("p",null,"When executing spark tasks, you need to use the ResourceManager of yarn, which is controlled by the configuration item ",(0,i.kt)("inlineCode",{parentName:"p"},"YARN_RESTFUL_URL=http://xx.xx.xx.xx:8088"),".\nWhen performing installation and deployment, the ",(0,i.kt)("inlineCode",{parentName:"p"},"YARN_RESTFUL_URL=http://xx.xx.xx.xx:8088")," information will be updated to ",(0,i.kt)("inlineCode",{parentName:"p"},"linkis_cg_rm_external_resource_provider")," in the database table. By default, access to yarn resources does not require authorization verification.\nIf the resourcemanager of yarn has enabled the password authentication, please modify the yarn data information generated in the database table ",(0,i.kt)("inlineCode",{parentName:"p"},"linkis_cg_rm_external_resource_provider")," after installation and deployment,\nFor details, please refer to ","[Check whether the yarn address is configured correctly]"," (#811-Check whether the yarn address is configured correctly)."),(0,i.kt)("h4",{id:"342-session"},"3.4.2 session"),(0,i.kt)("p",null,"If you are an upgrade to Linkis. Deploy DSS or other projects at the same time, but the version of linkis introduced in other software is <1.1.1 (mainly in the lib package, the linkis-module-xxxjar package of Linkis that depends on it <1.1.1), you need to modify the ",(0,i.kt)("inlineCode",{parentName:"p"},"$ {LINKIS_HOME}/conf/linkis.properties")," file."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell"},'echo "wds.linkis.session.ticket.key=bdp-user-ticket-id" >> linkis.properties\n')),(0,i.kt)("h4",{id:"343-s3-mode"},"3.4.3 S3 mode"),(0,i.kt)("blockquote",null,(0,i.kt)("p",{parentName:"blockquote"},"Currently supports storing engine execution logs and results to the S3 file system"),(0,i.kt)("p",{parentName:"blockquote"},"Note: linkis does not adapt permissions to S3, so it cannot perform authorization operations on it")),(0,i.kt)("p",null,(0,i.kt)("inlineCode",{parentName:"p"},"vim $LINKIS_HOME/conf/linkis.properties")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"# s3 file system\nlinkis.storage.s3.access.key=xxx\nlinkis.storage.s3.secret.key=xxx\nlinkis.storage.s3.endpoint=http://xxx.xxx.xxx.xxx:xxx\nlinkis.storage.s3.region=xxx\nlinkis.storage.s3.bucket=xxx\n")),(0,i.kt)("p",null,(0,i.kt)("inlineCode",{parentName:"p"},"vim $LINKIS_HOME/conf/linkis-cg-entrance.properties")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"wds.linkis.entrance.config.log.path=s3:///linkis/logs\nwds.linkis.resultSet.store.path=s3:///linkis/results\n")),(0,i.kt)("h3",{id:"35-start-the-service"},"3.5 Start the service"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"sh sbin/linkis-start-all.sh\n")),(0,i.kt)("h3",{id:"36-modification-of-configuration-after-installation"},"3.6 Modification of configuration after installation"),(0,i.kt)("p",null,"After the installation is complete, if you need to modify the configuration (the configuration needs to be adjusted due to port conflicts or some configuration problems), you can re-execute the installation, or modify the configuration ",(0,i.kt)("inlineCode",{parentName:"p"},"${LINKIS_HOME}/conf/*properties")," file of the corresponding service, Restart the corresponding service, such as: ",(0,i.kt)("inlineCode",{parentName:"p"},"sh sbin/linkis-daemon.sh start ps-publicservice"),"."),(0,i.kt)("h3",{id:"37-check-whether-the-service-starts-normally"},"3.7 Check whether the service starts normally"),(0,i.kt)("p",null,"Visit the eureka service page (http://eurekaip:20303),\nBy default, 6 Linkis microservices will be started, and the linkis-cg-engineconn service in the figure below will only be started for running tasks.\n",(0,i.kt)("img",{alt:"Linkis1.0_Eureka",src:n(11940).Z,width:"1589",height:"374"})),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"LINKIS-CG-ENGINECONNMANAGER Engine Management Service\nLINKIS-CG-ENTRANCE computing governance entry service\nLINKIS-CG-LINKISMANAGER Computing Governance Management Service \nLINKIS-MG-EUREKA Microservice Registry Service   \nLINKIS-MG-GATEWAY Gateway Service\nLINKIS-PS-PUBLICSERVICE Public Service\n")),(0,i.kt)("p",null,"Note: In Linkis 1.3.1, LINKIS-PS-CS, LINKIS-PS-DATA-SOURCE-MANAGER, LINKIS-PS-METADATAMANAGER services have been merged into LINKIS-PS-PUBLICSERVICE, and LINKIS-CG-ENGINEPLUGIN services have been merged into LINKIS -CG-LINKISMANAGER."),(0,i.kt)("p",null,"If any service is not started, you can check the detailed exception log in the corresponding log/${service name}.log file."),(0,i.kt)("h3",{id:"38-configure-token"},"3.8 Configure Token"),(0,i.kt)("p",null,"Linkis's original default Token is fixed and the length is too short, posing security risks. Therefore, Linkis 1.3.2 changes the original fixed Token to random generation, and increases the length of the Token."),(0,i.kt)("p",null,"New Token format: application abbreviation - 32-bit random number, such as BML-928a721518014ba4a28735ec2a0da799."),(0,i.kt)("p",null,"Token may be used in the Linkis service itself, such as executing tasks through Shell, uploading BML, etc., or it may be used in other applications, such as DSS, Qualitis and other applications to access Linkis."),(0,i.kt)("h4",{id:"view-token"},"View Token"),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"View via SQL statement")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"select * from linkis_mg_gateway_auth_token;\n")),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"View via Admin Console")),(0,i.kt)("p",null,"Log in to the management console -> basic data management -> token management\n",(0,i.kt)("img",{src:n(61808).Z,width:"1898",height:"616"})),(0,i.kt)("h4",{id:"check-token-configuration"},"Check Token configuration"),(0,i.kt)("p",null,"When the Linkis service itself uses Token, the Token in the configuration file must be consistent with the Token in the database. Match by applying the short name prefix."),(0,i.kt)("p",null,"$LINKIS_HOME/conf/linkis.properties file Token configuration"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"linkis.configuration.linkisclient.auth.token.value=BML-928a721518014ba4a28735ec2a0da799\nwds.linkis.client.common.tokenValue=BML-928a721518014ba4a28735ec2a0da799\nwds.linkis.bml.auth.token.value=BML-928a721518014ba4a28735ec2a0da799\nwds.linkis.context.client.auth.value=BML-928a721518014ba4a28735ec2a0da799\nwds.linkis.errorcode.auth.token=BML-928a721518014ba4a28735ec2a0da799\n\nwds.linkis.client.test.common.tokenValue=LINKIS_CLI-215af9e265ae437ca1f070b17d6a540d\n\nwds.linkis.filesystem.token.value=WS-52bce72ed51741c7a2a9544812b45725\nwds.linkis.gateway.access.token=WS-52bce72ed51741c7a2a9544812b45725\n\nwds.linkis.server.dsm.auth.token.value=DSM-65169e8e1b564c0d8a04ee861ca7df6e\n")),(0,i.kt)("p",null,"$LINKIS_HOME/conf/linkis-cli/linkis-cli.properties file Token configuration"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"wds.linkis.client.common.tokenValue=BML-928a721518014ba4a28735ec2a0da799\n")),(0,i.kt)("p",null,"When other applications use Token, they need to modify their Token configuration to be consistent with the Token in the database."),(0,i.kt)("h2",{id:"4-install-the-web-front-end"},"4. Install the web front end"),(0,i.kt)("p",null,"The web side uses nginx as the static resource server, and the access request process is:\n",(0,i.kt)("inlineCode",{parentName:"p"},"Linkis management console request->nginx ip:port->linkis-gateway ip:port->other services")),(0,i.kt)("h3",{id:"41-download-the-front-end-installation-package-and-decompress-it"},"4.1 Download the front-end installation package and decompress it"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"tar -xvf apache-linkis-xxx-web-bin.tar.gz\n")),(0,i.kt)("h3",{id:"42-modify-configuration-configsh"},"4.2 Modify configuration config.sh"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},'#Access the port of the management console\nlinkis_port="8188"\n\n#linkis-mg-gateway service address\nlinkis_url="http://localhost:9020"\n')),(0,i.kt)("h3",{id:"43-execute-the-deployment-script"},"4.3 Execute the deployment script"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"# nginx needs sudo permission to install\nsudo sh install.sh\n")),(0,i.kt)("p",null,"After installation, the nginx configuration file of linkis is in ",(0,i.kt)("inlineCode",{parentName:"p"},"/etc/nginx/conf.d/linkis.conf")," by default\nThe log files of nginx are in ",(0,i.kt)("inlineCode",{parentName:"p"},"/var/log/nginx/access.log")," and ",(0,i.kt)("inlineCode",{parentName:"p"},"/var/log/nginx/error.log"),"\nAn example of the generated nginx configuration file of the linkis management console is as follows:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-nginx"},"\n        server {\n            listen 8188;# If the access port is occupied, it needs to be modified\n            server_name localhost;\n            #charset koi8-r;\n            #access_log /var/log/nginx/host.access.log main;\n            location / {\n            root /appcom/Install/linkis-web/dist; # static file directory\n            index index.html index.html;\n            }\n            location /ws {\n            proxy_pass http://localhost:9020;#The address of the backend Linkis\n            proxy_http_version 1.1;\n            proxy_set_header Upgrade $http_upgrade;\n            proxy_set_header Connection upgrade;\n            }\n\n            location /api {\n            proxy_pass http://localhost:9020; #The address of the backend Linkis\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header x_real_ipP $remote_addr;\n            proxy_set_header remote_addr $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_http_version 1.1;\n            proxy_connect_timeout 4s;\n            proxy_read_timeout 600s;\n            proxy_send_timeout 12s;\n            proxy_set_header Upgrade $http_upgrade;\n            proxy_set_header Connection upgrade;\n            }\n\n            #error_page 404 /404.html;\n            # redirect server error pages to the static page /50x.html\n            #\n            error_page 500 502 503 504 /50x.html;\n            location = /50x.html {\n            root /usr/share/nginx/html;\n            }\n        }\n")),(0,i.kt)("p",null,"If you need to modify the port or static resource directory, etc., please modify the ",(0,i.kt)("inlineCode",{parentName:"p"},"/etc/nginx/conf.d/linkis.conf")," file and execute the ",(0,i.kt)("inlineCode",{parentName:"p"},"sudo nginx -s reload")," command"),(0,i.kt)("admonition",{title:"Caution",type:"caution"},(0,i.kt)("ul",{parentName:"admonition"},(0,i.kt)("li",{parentName:"ul"},"At present, the visualis function is not integrated. During the installation process, if you are prompted to fail to install linkis/visualis, you can ignore it."),(0,i.kt)("li",{parentName:"ul"},"Check whether nginx starts normally: check whether the nginx process exists ",(0,i.kt)("inlineCode",{parentName:"li"},"ps -ef |grep nginx"),"."),(0,i.kt)("li",{parentName:"ul"},"Check whether the configuration of nginx is correct ",(0,i.kt)("inlineCode",{parentName:"li"},"sudo nginx -T"),"."),(0,i.kt)("li",{parentName:"ul"},"If the port is occupied, you can modify the service port ",(0,i.kt)("inlineCode",{parentName:"li"},"/etc/nginx/conf.d/linkis.conf"),"listen port value started by nginx, save and restart."),(0,i.kt)("li",{parentName:"ul"},"If there is an interface 502 when accessing the management console, or ",(0,i.kt)("inlineCode",{parentName:"li"},"Unexpected token < in JSON at position 0")," is abnormal, please confirm whether the linkis-mg-gateway is started normally. If it is started normally, check the linkis-mg-gateway configured in the nginx configuration file Whether the service address is correct."))),(0,i.kt)("h3",{id:"44-log-in-to-the-management-console"},"4.4 Log in to the management console"),(0,i.kt)("p",null,"Browser login ",(0,i.kt)("inlineCode",{parentName:"p"},"http://xx.xx.xx.xx:8188/#/login"),"\nUsername/password can be checked in ",(0,i.kt)("inlineCode",{parentName:"p"},"{LINKIS_HOME}/conf/linkis-mg-gateway.properties"),"."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"wds.linkis.admin.user= #user\nwds.linkis.admin.password= #password\n\n")),(0,i.kt)("h2",{id:"5-verify-basic-functions"},"5. Verify basic functions"),(0,i.kt)("blockquote",null,(0,i.kt)("p",{parentName:"blockquote"},"Verify the corresponding engine tasks according to actual needs")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},'#The version number of the engineType stitching of the engine must match the actual one. The following example is the default version number\n#shell engine tasks\nsh bin/linkis-cli -submitUser hadoop -engineType shell-1 -codeType shell -code "whoami"\n\n#hive engine tasks\nsh bin/linkis-cli -submitUser hadoop -engineType hive-3.1.3 -codeType hql -code "show tables"\n\n#spark engine tasks\nsh bin/linkis-cli -submitUser hadoop -engineType spark-3.2.1 -codeType sql -code "show tables"\n\n#python engine tasks\nsh bin/linkis-cli -submitUser hadoop -engineType python-python2 -codeType python -code \'print("hello, world!")\'\n')),(0,i.kt)("p",null,"If the verification fails, please refer to ","[Step 8]"," for troubleshooting."),(0,i.kt)("h2",{id:"6-installation-of-development-tool-ide-scriptis-optional"},"6. Installation of development tool IDE (Scriptis) (optional)"),(0,i.kt)("p",null,"After installing the Scripti tool, you can write SQL, Pyspark, HiveQL and other scripts online on the web page. For detailed instructions, see ","[Tool Scriptis Installation and Deployment]"," (integrated/install-scriptis)."),(0,i.kt)("h2",{id:"7-supported-engines"},"7. Supported engines"),(0,i.kt)("h3",{id:"71-engine-adaptation-list"},"7.1 Engine adaptation list"),(0,i.kt)("p",null,"Please note: the separate installation package of Linkis only includes Python, Shell, Hive, and Spark by default. If there are other engine usage scenarios (such as jdbc/flink/sqoop, etc.), you can install them manually. For details, please refer to ",(0,i.kt)("a",{parentName:"p",href:"install-engineconn"},"EngineConnPlugin Engine Plugin installation documentation"),"."),(0,i.kt)("p",null,"The list of supported engines adapted to this version is as follows:"),(0,i.kt)("table",null,(0,i.kt)("thead",{parentName:"table"},(0,i.kt)("tr",{parentName:"thead"},(0,i.kt)("th",{parentName:"tr",align:null},"Engine type"),(0,i.kt)("th",{parentName:"tr",align:null},"Adaptation situation"),(0,i.kt)("th",{parentName:"tr",align:null},"Whether the official installation package contains"))),(0,i.kt)("tbody",{parentName:"table"},(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"Python"),(0,i.kt)("td",{parentName:"tr",align:null},">=1.0.0 Adapted"),(0,i.kt)("td",{parentName:"tr",align:null},"Contains")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"Shell"),(0,i.kt)("td",{parentName:"tr",align:null},">=1.0.0 adapted"),(0,i.kt)("td",{parentName:"tr",align:null},"contains")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"Hive"),(0,i.kt)("td",{parentName:"tr",align:null},">=1.0.0 adapted"),(0,i.kt)("td",{parentName:"tr",align:null},"contains")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"Spark"),(0,i.kt)("td",{parentName:"tr",align:null},">=1.0.0 adapted"),(0,i.kt)("td",{parentName:"tr",align:null},"contains")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"Pipeline"),(0,i.kt)("td",{parentName:"tr",align:null},">=1.0.0 Adapted"),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("strong",{parentName:"td"},"Not Included"))),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"JDBC"),(0,i.kt)("td",{parentName:"tr",align:null},">=1.0.0 Adapted"),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("strong",{parentName:"td"},"Not Included"))),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"Flink"),(0,i.kt)("td",{parentName:"tr",align:null},">=1.0.0 Adapted"),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("strong",{parentName:"td"},"Excludes"))),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"openLooKeng"),(0,i.kt)("td",{parentName:"tr",align:null},">=1.1.1 Adapted"),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("strong",{parentName:"td"},"Not Included"))),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"Sqoop"),(0,i.kt)("td",{parentName:"tr",align:null},">=1.1.2 Adapted"),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("strong",{parentName:"td"},"Not Included"))),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"Trino"),(0,i.kt)("td",{parentName:"tr",align:null},">=1.3.2 Adapted"),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("strong",{parentName:"td"},"Excluded"))),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"Presto"),(0,i.kt)("td",{parentName:"tr",align:null},">=1.3.2 Adapted"),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("strong",{parentName:"td"},"Excluded"))),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"Elasticsearch"),(0,i.kt)("td",{parentName:"tr",align:null},">=1.3.2 Adapted"),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("strong",{parentName:"td"},"Excludes"))),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"Seatunnel"),(0,i.kt)("td",{parentName:"tr",align:null},">=1.3.2 Adapted"),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("strong",{parentName:"td"},"Not Included"))),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"Impala"),(0,i.kt)("td",{parentName:"tr",align:null},">=1.4.0 Adapted"),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("strong",{parentName:"td"},"Excludes"))))),(0,i.kt)("h3",{id:"72-view-deployed-engines"},"7.2 View deployed engines"),(0,i.kt)("h4",{id:"method-1-view-the-engine-lib-package-directory"},"Method 1: View the engine lib package directory"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"$ tree linkis-package/lib/linkis-engineconn-plugins/ -L 3\nlinkis-package/lib/linkis-engineconn-plugins/\n\u251c\u2500\u2500hive\n\u2502 \u251c\u2500\u2500 dist\n\u2502 \u2502 \u2514\u2500\u2500 3.1.3 #version is 3.1.3 engineType is hive-3.1.3\n\u2502 \u2514\u2500\u2500 plugin\n\u2502 \u2514\u2500\u2500 3.1.3\n\u251c\u2500\u2500 python\n\u2502 \u251c\u2500\u2500 dist\n\u2502 \u2502 \u2514\u2500\u2500 python2\n\u2502 \u2514\u2500\u2500 plugin\n\u2502 \u2514\u2500\u2500 python2 #version is python2 engineType is python-python2\n\u251c\u2500\u2500 shell\n\u2502 \u251c\u2500\u2500 dist\n\u2502 \u2502 \u2514\u2500\u2500 1\n\u2502 \u2514\u2500\u2500 plugin\n\u2502 \u2514\u2500\u2500 1\n\u2514\u2500\u2500 spark\n    \u251c\u2500\u2500 dist\n    \u2502 \u2514\u2500\u2500 3.2.1\n    \u2514\u2500\u2500 plugin\n        \u2514\u2500\u2500 3.2.1\n")),(0,i.kt)("h4",{id:"method-2-view-the-database-table-of-linkis"},"Method 2: View the database table of linkis"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"select * from linkis_cg_engine_conn_plugin_bml_resources\n")),(0,i.kt)("h2",{id:"8-troubleshooting-guidelines-for-common-abnormal-problems"},"8. Troubleshooting guidelines for common abnormal problems"),(0,i.kt)("h3",{id:"81-yarn-queue-check"},"8.1. Yarn queue check"),(0,i.kt)("blockquote",null,(0,i.kt)("p",{parentName:"blockquote"},"If you need to use the spark/hive/flink engine")),(0,i.kt)("p",null,"After logging in, check whether the yarn queue resources can be displayed normally (click the button in the lower right corner of the page) (you need to install the front end first)."),(0,i.kt)("p",null,"Normal as shown in the figure below:",(0,i.kt)("br",{parentName:"p"}),"\n",(0,i.kt)("img",{alt:"yarn-normal",src:n(71770).Z,width:"1669",height:"784"})),(0,i.kt)("p",null,"If it cannot be displayed: You can adjust it according to the following guidelines"),(0,i.kt)("h4",{id:"811-check-whether-the-yarn-address-is-configured-correctly"},"8.1.1 Check whether the yarn address is configured correctly"),(0,i.kt)("p",null,"Database table `linkis_cg_rm_external_resource_provider``\nInsert yarn data information"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},'INSERT INTO `linkis_cg_rm_external_resource_provider`\n(`resource_type`, `name`, `labels`, `config`) VALUES\n(\'Yarn\', \'sit\', NULL,\n\'{\\r\\n"rmWebAddress": "http://xx.xx.xx.xx:8088",\\r\\n"hadoopVersion": "3.3.4",\\r\\n"authorEnable":false, \\r\\n"user":"hadoop",\\r\\n"pwd":"123456"\\r\\n}\'\n);\n\nconfig field attribute\n\n"rmWebAddress": "http://xx.xx.xx.xx:8088", #Need to bring http and port\n"hadoopVersion": "3.3.4",\n"authorEnable":true, //Whether authentication is required You can verify the username and password by visiting http://xx.xx.xx.xx:8088 in the browser\n"user": "user", //username\n"pwd": "pwd"//password\n\n')),(0,i.kt)("p",null,"After the update, because the cache is used in the program, if you want to take effect immediately, you need to restart the linkis-cg-linkismanager service."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"sh sbin/linkis-daemon.sh restart cg-linkismanager\n")),(0,i.kt)("h4",{id:"812-check-whether-the-yarn-queue-exists"},"8.1.2 Check whether the yarn queue exists"),(0,i.kt)("p",null,"Exception information: ",(0,i.kt)("inlineCode",{parentName:"p"},"desc: queue ide is not exists in YARN.")," indicates that the configured yarn queue does not exist and needs to be adjusted."),(0,i.kt)("p",null,"Modification method: ",(0,i.kt)("inlineCode",{parentName:"p"},"linkis management console/parameter configuration>global settings>yarn queue name [wds.linkis.rm.yarnqueue]"),", modify a yarn queue that can be used, and the yarn queue to be used can be found at ",(0,i.kt)("inlineCode",{parentName:"p"},"rmWebAddress:http:// xx.xx.xx.xx:8088/cluster/scheduler"),"."),(0,i.kt)("p",null,"View available yarn queues"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"View yarn queue address: http://ip:8888/cluster/scheduler")),(0,i.kt)("h3",{id:"82-check-whether-the-engine-material-resources-are-uploaded-successfully"},"8.2 Check whether the engine material resources are uploaded successfully"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"#Log in to the linkis database\nselect * from linkis_cg_engine_conn_plugin_bml_resources\n")),(0,i.kt)("p",null,"Normally as follows:\n",(0,i.kt)("img",{alt:"bml",src:n(24006).Z,width:"1375",height:"223"})),(0,i.kt)("p",null,"Check whether the material record of the engine exists (if there is an update, check whether the update time is correct)"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"If it does not exist or is not updated, first try to manually refresh the material resource (see ","[Engine Material Resource Refresh]","(install-engineconn#23-engine refresh) for details)."),(0,i.kt)("li",{parentName:"ul"},"Use ",(0,i.kt)("inlineCode",{parentName:"li"},"log/linkis-cg-linkismanager.log")," to check the specific reason for the failure of the material. In many cases, it may be caused by the lack of permission in the hdfs directory."),(0,i.kt)("li",{parentName:"ul"},"Check whether the gateway address configuration is correct. The configuration item ",(0,i.kt)("inlineCode",{parentName:"li"},"wds.linkis.gateway.url")," in ",(0,i.kt)("inlineCode",{parentName:"li"},"conf/linkis.properties"),".")),(0,i.kt)("p",null,"The material resources of the engine are uploaded to the hdfs directory by default as ",(0,i.kt)("inlineCode",{parentName:"p"},"/apps-data/${deployUser}/bml"),"."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"hdfs dfs -ls /apps-data/hadoop/bml\n#If there is no such directory, please manually create the directory and grant ${deployUser} read and write permissions\nhdfs dfs -mkdir /apps-data\nhdfs dfs -chown hadoop:hadoop /apps-data\n")),(0,i.kt)("h3",{id:"83-login-password-problem"},"8.3 Login password problem"),(0,i.kt)("p",null,"Linkis uses static users and passwords by default. Static users are deployment users. Static passwords will randomly generate a password string during deployment and store it in"),(0,i.kt)("p",null,(0,i.kt)("inlineCode",{parentName:"p"},"${LINKIS_HOME}/conf/linkis-mg-gateway.properties")," (>=version 1.0.3)."),(0,i.kt)("h3",{id:"84-version-compatibility-issues"},"8.4 version compatibility issues"),(0,i.kt)("p",null,"The engine supported by linkis by default, and the compatibility relationship with dss can be viewed in ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/apache/linkis/blob/master/README.md"},"this document"),"."),(0,i.kt)("h3",{id:"85-how-to-locate-server-side-exception-logs"},"8.5 How to locate server-side exception logs"),(0,i.kt)("p",null,"Linkis has many microservices. If you are not familiar with the system, sometimes you cannot locate the specific module that has an exception. You can search through the global log."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"tail -f log/* |grep -5n exception (or tail -f log/* |grep -5n ERROR)  \nless log/* |grep -5n exception (or less log/* |grep -5n ERROR)  \n")),(0,i.kt)("h3",{id:"86-execution-engine-task-exception-troubleshooting"},"8.6 Execution engine task exception troubleshooting"),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"}," step1: Find the startup deployment directory of the engine"),"  "),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Method 1: If it is displayed in the execution log, you can view it on the management console as shown below:",(0,i.kt)("br",{parentName:"li"}),(0,i.kt)("img",{alt:"engine-log",src:n(80383).Z,width:"1889",height:"731"})),(0,i.kt)("li",{parentName:"ul"},"Method 2: If not found in method 1, you can find the ",(0,i.kt)("inlineCode",{parentName:"li"},"wds.linkis.engineconn.root.dir")," parameter configured in ",(0,i.kt)("inlineCode",{parentName:"li"},"conf/linkis-cg-engineconnmanager.properties"),", and this value is the directory where the engine starts and deploys. Subdirectories are segregated by user of the execution engine")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"# If you don't know the taskid, you can sort by time and choose ll -rt /appcom/tmp/${executed user}/${date}/${engine}/  \ncd /appcom/tmp/${user executed}/${date}/${engine}/${taskId}  \n")),(0,i.kt)("p",null,"The directory is roughly as follows"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"conf -> /appcom/tmp/engineConnPublicDir/6a09d5fb-81dd-41af-a58b-9cb5d5d81b5a/v000002/conf #engine configuration file  \nengineConnExec.sh #generated engine startup script  \nlib -> /appcom/tmp/engineConnPublicDir/45bf0e6b-0fa5-47da-9532-c2a9f3ec764d/v000003/lib #engine-dependent packages  \nlogs #Related logs of engine startup execution  \n")),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"step2: Check the log of the engine")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"less logs/stdout  \n")),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"step3: Try to execute the script manually (if needed)"),(0,i.kt)("br",{parentName:"p"}),"\n","You can debug by trying to execute the script manually"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"sh -x engineConnExec.sh  \n")),(0,i.kt)("h3",{id:"87-how-to-modify-the-port-of-the-registration-center-eureka"},"8.7 How to modify the port of the registration center eureka"),(0,i.kt)("p",null,"Sometimes when the eureka port is occupied by other services and the default eureka port cannot be used, it is necessary to modify the eureka port. Here, the modification of the eureka port is divided into two cases: before the installation and after the installation."),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"Modify the eureka port of the registration center before performing the installation")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"1. Enter the decompression directory of apache-linkis-xxx-bin.tar.gz\n2. Execute vi deploy-config/linkis-env.sh\n3. Modify EUREKA_PORT=20303 to EUREKA_PORT=port number\n")),(0,i.kt)("ol",{start:2},(0,i.kt)("li",{parentName:"ol"},"Modify the registry eureka port after installation  ")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"1. Enter the ${LINKIS_HOME}/conf directory\n\n2. Execute grep -r 20303 ./* , the query results are as follows:\n      ./application-eureka.yml: port: 20303\n      ./application-eureka.yml: defaultZone: http://ip:20303/eureka/\n      ./application-linkis.yml: defaultZone: http://ip:20303/eureka/\n      ./linkis-env.sh:EUREKA_PORT=20303\n      ./linkis.properties:wds.linkis.eureka.defaultZone=http://ip:20303/eureka/\n\n3. Change the port at the corresponding location to a new port, and restart all services sh restart sbin/linkis-start-all.sh\n")),(0,i.kt)("h3",{id:"88-notes-for-cdh-adaptation-version"},"8.8 Notes for CDH adaptation version"),(0,i.kt)("p",null,"CDH itself is not an official standard hive/spark package. When adapting, it is best to modify the hive/spark version dependencies in the linkis source code and recompile and deploy.",(0,i.kt)("br",{parentName:"p"}),"\n","For details, please refer to the CDH adaptation blog post",(0,i.kt)("br",{parentName:"p"}),"\n",(0,i.kt)("a",{parentName:"p",href:"https://mp.weixin.qq.com/s/__QxC1NoLQFwme1yljy-Nw"},"[Linkis1.0\u2014\u2014Installation and stepping in the CDH5 environment]"),(0,i.kt)("br",{parentName:"p"}),"\n",(0,i.kt)("a",{parentName:"p",href:"https://mp.weixin.qq.com/s/9Pl9P0hizDWbbTBf1yzGJA"},"[DSS1.0.0+Linkis1.0.2\u2014\u2014Trial record in CDH5 environment]"),(0,i.kt)("br",{parentName:"p"}),"\n",(0,i.kt)("a",{parentName:"p",href:"https://mp.weixin.qq.com/s/vcFge4BNiEuW-7OC3P-yaw"},"[DSS1.0.0 and Linkis1.0.2 - Summary of JDBC engine-related issues]"),(0,i.kt)("br",{parentName:"p"}),"\n",(0,i.kt)("a",{parentName:"p",href:"https://mp.weixin.qq.com/s/VxZ16IPMd1CvcrvHFuU4RQ"},"[DSS1.0.0 and Linkis1.0.2\u2014\u2014Summary of issues related to Flink engine]")),(0,i.kt)("h3",{id:"89-debugging-of-http-interface"},"8.9 Debugging of Http interface"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Method 1 can enable ","[Guide to Free Login Mode]","(/docs/latest/api/login-api/#2 Login-free configuration)"),(0,i.kt)("li",{parentName:"ul"},"In method 2 postman, the cookie value of successful login on the request header\nThe cookie value can be obtained after successful login on the browser side\n",(0,i.kt)("img",{alt:"bml",src:n(19798).Z,width:"1912",height:"820"}))),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"Cookie: bdp-user-ticket-id=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Method 3 http request header to add a static Token token",(0,i.kt)("br",{parentName:"li"}),"Token is configured in conf/linkis.properties\nSuch as: TEST-AUTH=hadoop,root,user01")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"Token-Code: TEST-AUTH\nToken-User: hadoop\n")),(0,i.kt)("h3",{id:"810-troubleshooting-process-for-abnormal-problems"},"8.10 Troubleshooting process for abnormal problems"),(0,i.kt)("p",null,"First, check whether the service/environment is started normally according to the above steps, and then check the basic problems according to some scenarios listed above."),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://docs.qq.com/doc/DSGZhdnpMV3lTUUxq"},"QA document")," Find out if there is a solution, link: ",(0,i.kt)("a",{parentName:"p",href:"https://docs.qq.com/doc/DSGZhdnpMV3lTUUxq"},"https://docs.qq.com/doc/DSGZhdnpMV3lTUUxq"),(0,i.kt)("br",{parentName:"p"}),"\n","See if you can find a solution by searching the contents of the issue.",(0,i.kt)("br",{parentName:"p"}),"\n",(0,i.kt)("img",{alt:"issues",src:n(47879).Z,width:"1591",height:"803"}),(0,i.kt)("br",{parentName:"p"}),"\n",'Through the official website document search, for some questions, you can search keywords on the official website, such as searching for "deployment". (If 404 appears, please refresh the browser)',(0,i.kt)("br",{parentName:"p"}),"\n",(0,i.kt)("img",{alt:"search",src:n(48284).Z,width:"1790",height:"749"})),(0,i.kt)("h2",{id:"9-how-to-obtain-relevant-information"},"9. How to obtain relevant information"),(0,i.kt)("p",null,"Linkis official website documents are constantly being improved, and you can view related documents on this official website."),(0,i.kt)("p",null,"Related blog posts are linked below."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Linkis' technical blog collection ",(0,i.kt)("a",{parentName:"li",href:"https://github.com/apache/linkis/issues/1233"},"https://github.com/apache/linkis/issues/1233")),(0,i.kt)("li",{parentName:"ul"},"Public account technical blog post ",(0,i.kt)("a",{parentName:"li",href:"https://mp.weixin.qq.com/mp/homepage?__biz=MzI4MDkxNzUxMg==&hid=1&sn=088cbf2bbed1c80d003c5865bc92ace8&scene=18"},"https://mp.weixin.qq.com/mp/homepage?__biz=MzI4MDkxNzUxMg==&hid=1&sn=088cbf2bbed1c80d003c5865bc92ace8&scene=18")),(0,i.kt)("li",{parentName:"ul"},"Official website documentation ",(0,i.kt)("a",{parentName:"li",href:"https://linkis.apache.org/zh-CN/docs/latest/about/introduction"},"https://linkis.apache.org/zh-CN/docs/latest/about/introduction")),(0,i.kt)("li",{parentName:"ul"},"bili technology sharing video ",(0,i.kt)("a",{parentName:"li",href:"https://space.bilibili.com/598542776?spm_id_from=333.788.b_765f7570696e666f.2"},"https://space.bilibili.com/598542776?spm_id_from=333.788.b_765f7570696e666f.2"))))}u.isMDXComponent=!0},19798:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/bml-cookie-55d9c73cf98991ff4fdc55bf7b0ffdfa.png"},24006:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/bml-d0ca8015ccab374cf4361949ca940f65.png"},80383:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/engine-log-ea301d1f5c9da11de32fdb8408b14b56.png"},11940:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/eureka-82da8945433f3f45507327bf902f17b1.png"},47879:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/issues-016acec5dab8f24e2cdc9f6dc5651b8c.png"},48284:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/search-227e7f82f47dbcbf64dfa0dda1017a3a.png"},71770:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/yarn-normal-8723b62735d0da4ad3599871eef8c0d1.png"},61808:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/token-list-436c80c4a93e0a8c542304e7aa1e1ea8.png"}}]);