"use strict";(self.webpackChunklinkis_web_apache=self.webpackChunklinkis_web_apache||[]).push([[70886],{3905:(e,a,t)=>{t.d(a,{Zo:()=>p,kt:()=>_});var n=t(67294);function r(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function s(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);a&&(n=n.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,n)}return t}function o(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?s(Object(t),!0).forEach((function(a){r(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):s(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function i(e,a){if(null==e)return{};var t,n,r=function(e,a){if(null==e)return{};var t,n,r={},s=Object.keys(e);for(n=0;n<s.length;n++)t=s[n],a.indexOf(t)>=0||(r[t]=e[t]);return r}(e,a);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(n=0;n<s.length;n++)t=s[n],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var l=n.createContext({}),d=function(e){var a=n.useContext(l),t=a;return e&&(t="function"==typeof e?e(a):o(o({},a),e)),t},p=function(e){var a=d(e.components);return n.createElement(l.Provider,{value:a},e.children)},c="mdxType",u={inlineCode:"code",wrapper:function(e){var a=e.children;return n.createElement(n.Fragment,{},a)}},L=n.forwardRef((function(e,a){var t=e.components,r=e.mdxType,s=e.originalType,l=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),c=d(t),L=r,_=c["".concat(l,".").concat(L)]||c[L]||u[L]||s;return t?n.createElement(_,o(o({ref:a},p),{},{components:t})):n.createElement(_,o({ref:a},p))}));function _(e,a){var t=arguments,r=a&&a.mdxType;if("string"==typeof e||r){var s=t.length,o=new Array(s);o[0]=L;var i={};for(var l in a)hasOwnProperty.call(a,l)&&(i[l]=a[l]);i.originalType=e,i[c]="string"==typeof e?e:r,o[1]=i;for(var d=2;d<s;d++)o[d]=t[d];return n.createElement.apply(null,o)}return n.createElement.apply(null,t)}L.displayName="MDXCreateElement"},80037:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>l,contentTitle:()=>o,default:()=>u,frontMatter:()=>s,metadata:()=>i,toc:()=>d});var n=t(87462),r=(t(67294),t(3905));const s={title:"Upgrade Guide for 1.4.0",sidebar_position:3},o=void 0,i={unversionedId:"upgrade/upgrade-to-1.4.0-guide",id:"upgrade/upgrade-to-1.4.0-guide",title:"Upgrade Guide for 1.4.0",description:"Linkis1.4.0 has made many adjustments to Linkis services and codes. This article introduces the relevant precautions for upgrading to Linkis 1.4.0.",source:"@site/docs/upgrade/upgrade-to-1.4.0-guide.md",sourceDirName:"upgrade",slug:"/upgrade/upgrade-to-1.4.0-guide",permalink:"/docs/1.4.0/upgrade/upgrade-to-1.4.0-guide",draft:!1,editUrl:"https://github.com/apache/linkis-website/edit/dev/docs/upgrade/upgrade-to-1.4.0-guide.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{title:"Upgrade Guide for 1.4.0",sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"Version Upgrades above 1.0.3",permalink:"/docs/1.4.0/upgrade/upgrade-guide"}},l={},d=[{value:"1. Precautions",id:"1-precautions",level:2},{value:"2. Environment upgrade",id:"2-environment-upgrade",level:2},{value:"3. Service upgrade installation",id:"3-service-upgrade-installation",level:2},{value:"4. Database upgrade",id:"4-database-upgrade",level:2},{value:"4.1 Table structure modification part:",id:"41-table-structure-modification-part",level:3},{value:"4.2 Newly executed sql is required:",id:"42-newly-executed-sql-is-required",level:3},{value:"4. Add mysql driver package",id:"4-add-mysql-driver-package",level:2},{value:"5. Start the service",id:"5-start-the-service",level:2},{value:"6. Precautions",id:"6-precautions",level:2}],p={toc:d},c="wrapper";function u(e){let{components:a,...t}=e;return(0,r.kt)(c,(0,n.Z)({},p,t,{components:a,mdxType:"MDXLayout"}),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"Linkis1.4.0 has made many adjustments to Linkis services and codes. This article introduces the relevant precautions for upgrading to Linkis 1.4.0.")),(0,r.kt)("h2",{id:"1-precautions"},"1. Precautions"),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"1) If you are using Linkis for the first time, you can ignore this chapter and refer to the ",(0,r.kt)("a",{parentName:"strong",href:"/docs/1.4.0/deployment/deploy-quick"},"Single-machine deployment")," guide to deploy Linkis. ")),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"2) If you have installed a version before Likis 1.4.0 but do not want to keep the original data, you can also refer to the ",(0,r.kt)("a",{parentName:"strong",href:"/docs/1.4.0/deployment/deploy-quick"},"Stand-alone Deployment")," guide to redeploy, and select 2 to clean up during installation All the data and rebuild the table (see the code below). ")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"Do you want to clear Linkis table information in the database?\n 1: Do not execute table-building statements\n 2: Dangerous! Clear all data and rebuild the tables\n other: exit\n\nPlease input the choice: ## choice 2\n")),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"3) If you have installed a version of Likis earlier than 1.4.0 but need to keep the original version data, you can refer to this document to upgrade. ")),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"2-environment-upgrade"},"2. Environment upgrade"),(0,r.kt)("p",null,"Linkis 1.4.0 upgrades the default dependent environments Hadoop, Hive, and Spark to 3.x. Hadoop was upgraded to 3.3.4, Hive was upgraded to 3.1.3, and Spark was upgraded to 3.2.1. Please upgrade these environments before performing subsequent operations."),(0,r.kt)("p",null,"Verify the upgraded version by the following command"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"echo $HADOOP_HOME\n/data/hadoop-3.3.4\necho $HIVE_HOME\n/data/apache-hive-3.1.3-bin\necho $SPARK_HOME\n/data/spark-3.2.1-bin-hadoop3.2\n")),(0,r.kt)("p",null,"Before installation, please modify the relevant configurations of Hadoop, Hive, and Spark in the deploy-config/linkis-env.sh file to the upgraded directory. The specific modification items are as follows:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'#HADOOP\nHADOOP_HOME=${HADOOP_HOME:-"/appcom/Install/hadoop"}\nHADOOP_CONF_DIR=${HADOOP_CONF_DIR:-"/appcom/config/hadoop-config"}\n\n## Hadoop env version\nHADOOP_VERSION=${HADOOP_VERSION:-"3.3.4"}\n\n#Hive\nHIVE_HOME=/appcom/Install/hive\nHIVE_CONF_DIR=/appcom/config/hive-config\n\n#Spark\nSPARK_HOME=/appcom/Install/spark\nSPARK_CONF_DIR=/appcom/config/spark-config\n\n')),(0,r.kt)("h2",{id:"3-service-upgrade-installation"},"3. Service upgrade installation"),(0,r.kt)("p",null,"Because the 1.4.0 version has changed a lot, the service needs to be reinstalled when the old version is upgraded to 1.4.0."),(0,r.kt)("p",null,"If you need to keep the old version of data during installation, be sure to choose 1 to skip the table creation statement (see the code below)."),(0,r.kt)("p",null,"Linkis 1.4.0 installation can refer to ",(0,r.kt)("a",{parentName:"p",href:"/docs/1.4.0/deployment/deploy-quick"},"How to install quickly")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"Do you want to clear Linkis table information in the database?\n 1: Do not execute table-building statements\n 2: Dangerous! Clear all data and rebuild the tables\n other: exit\n\nPlease input the choice: ## choice 1\n")),(0,r.kt)("h2",{id:"4-database-upgrade"},"4. Database upgrade"),(0,r.kt)("p",null,"  After the service installation is complete, the data tables of the database need to be modified, including table structure changes and table data updates. Execute the DDL and DML scripts corresponding to the upgraded version."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"# table structure changes\nlinkis-dist\\package\\db\\upgrade\\${version}_schema\\mysql\\linkis_ddl.sql\n# table data changes\nlinkis-dist\\package\\db\\upgrade\\${version}_schema\\mysql\\linkis_dml.sql\n")),(0,r.kt)("p",null,"Note that when upgrading, please execute the upgrade script in sequence, such as upgrading from the current version 1.3.1 to version 1.4.0. You need to execute the DDL and DML scripts of 1.3.2 upgrade first, and then execute the DDL and DML scripts of 1.4.0 upgrade. This article takes the upgrade from 1.3.2 to 1.4.0 as an example to illustrate"),(0,r.kt)("h3",{id:"41-table-structure-modification-part"},"4.1 Table structure modification part:"),(0,r.kt)("p",null,"Connect to the mysql database and execute the linkis-dist\\package\\db\\upgrade\\1.3.2_schema\\mysql\\linkis_ddl.sql script content, the specific content is as follows:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-mysql-sql"},"ALTER TABLE `linkis_cg_manager_service_instance` ADD COLUMN `identifier` varchar(32) COLLATE utf8_bin DEFAULT NULL;\nALTER TABLE `linkis_cg_manager_service_instance` ADD COLUMN `ticketId` varchar(255) COLLATE utf8_bin DEFAULT NULL;\nALTER TABLE `linkis_cg_ec_resource_info_record` MODIFY COLUMN metrics TEXT DEFAULT NULL COMMENT 'ec metrics';\n")),(0,r.kt)("h3",{id:"42-newly-executed-sql-is-required"},"4.2 Newly executed sql is required:"),(0,r.kt)("p",null,"Connect to the mysql database and execute the linkis-dist\\package\\db\\upgrade\\1.3.2_schema\\mysql\\linkis_dml.sql script content, the specific content is as follows:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"-- Default version upgrade\nUPDATE linkis_ps_configuration_config_key SET default_value = 'python3' WHERE `key` = 'spark.python.version';\nUPDATE linkis_cg_manager_label SET label_value = '*-*,hive-3.1.3' WHERE label_value = '*-*,hive-2.3.3';\nUPDATE linkis_cg_manager_label SET label_value = '*-IDE,hive-3.1.3' WHERE label_value = '*-IDE,hive-2.3.3';\nUPDATE linkis_cg_manager_label SET label_value = '*-nodeexecution,hive-3.1.3' WHERE label_value = '*-nodeexecution,hive-2.3.3';\nUPDATE linkis_cg_manager_label SET label_value = '*-*,spark-3.2.1' WHERE label_value = '*-*,spark-2.4.3';\nUPDATE linkis_cg_manager_label SET label_value = '*-IDE,spark-3.2.1' WHERE label_value = '*-IDE,spark-2.4.3';\nUPDATE linkis_cg_manager_label SET label_value = '*-Visualis,spark-3.2.1' WHERE label_value = '*-Visualis,spark-2.4.3';\nUPDATE linkis_cg_manager_label SET label_value = '*-nodeexecution,spark-3.2.1' WHERE label_value = '*-nodeexecution,spark-2.4.3';\n\n-- Support for different data sources\nINSERT INTO `linkis_ps_dm_datasource_type` (`name`, `description`, `option`, `classifier`, `icon`, `layers`, `description_en`, `option_en`, `classifier_en`) VALUES ('tidb', 'tidb Database', 'tidb', 'Relational Database', '', 3, 'TiDB Database', 'TiDB', 'Relational Database');\n\nselect @data_source_type_id := id from `linkis_ps_dm_datasource_type` where `name` = 'tidb';\nINSERT INTO `linkis_ps_dm_datasource_type_key`\n(`data_source_type_id`, `key`, `name`, `name_en`, `default_value`, `value_type`, `scope`, `require`, `description`, `description_en`, `value_regex`, `ref_id`, ` ref_value`, `data_source`, `update_time`, `create_time`)\nVALUES (@data_source_type_id, 'address', 'Address', 'Address', NULL, 'TEXT', NULL, 0, 'Address(host1:port1,host2:port2...)', 'Address(host1:port1, host2:port2...)', NULL, NULL, NULL, NULL, now(), now()),\n       (@data_source_type_id, 'host', 'Host', 'Host', NULL, 'TEXT', NULL, 1, 'Host', 'Host', NULL, NULL, NULL, NULL, now(), now()),\n       (@data_source_type_id, 'port', 'Port', 'Port', NULL, 'TEXT', NULL, 1, 'Port', 'Port', NULL, NULL, NULL, NULL, now(), now()),\n       (@data_source_type_id, 'driverClassName', 'Driver class name', 'Driver class name', 'com.mysql.jdbc.Driver', 'TEXT', NULL, 1, 'Driver class name (Driver class name)', 'Driver class name', NULL, NULL, NULL, NULL, now(), now()),\n       (@data_source_type_id, 'params', 'Connection params', 'Connection params', NULL, 'TEXT', NULL, 0, 'Input JSON format): {\"param\":\"value\" }', 'Input JSON format: {\"param\":\"value\"}', NULL, NULL, NULL, NULL, now(), now()),\n       (@data_source_type_id, 'username', 'Username', 'Username', NULL, 'TEXT', NULL, 1, 'Username', 'Username', '^[0-9A-Za -z_-]+$', NULL, NULL, NULL, now(), now()),\n       (@data_source_type_id, 'password', 'Password', 'Password', NULL, 'PASSWORD', NULL, 0, 'Password', 'Password', '', NULL, NULL, NULL, now (), now()),\n       (@data_source_type_id, 'instance', 'Instance name (instance)', 'Instance', NULL, 'TEXT', NULL, 1, 'Instance name (instance)', 'Instance', NULL, NULL, NULL, NULL, now(), now());\n\nINSERT INTO `linkis_ps_dm_datasource_type` (`name`, `description`, `option`, `classifier`, `icon`, `layers`, `description_en`, `option_en`, `classifier_en`) VALUES ('starrocks', 'starrocks` Database', 'starrocks', 'olap', '', 4, 'StarRocks Database', 'StarRocks', 'Olap');\n\nselect @data_source_type_id := id from `linkis_ps_dm_datasource_type` where `name` = 'starrocks';\nINSERT INTO `linkis_ps_dm_datasource_type_key`\n(`data_source_type_id`, `key`, `name`, `name_en`, `default_value`, `value_type`, `scope`, `require`, `description`, `description_en`, `value_regex`, `ref_id`, ` ref_value`, `data_source`, `update_time`, `create_time`)\nVALUES (@data_source_type_id, 'address', 'Address', 'Address', NULL, 'TEXT', NULL, 0, 'Address(host1:port1,host2:port2...)', 'Address(host1:port1, host2:port2...)', NULL, NULL, NULL, NULL, now(), now()),\n       (@data_source_type_id, 'host', 'Host', 'Host', NULL, 'TEXT', NULL, 1, 'Host', 'Host', NULL, NULL, NULL, NULL, now(), now()),\n       (@data_source_type_id, 'port', 'Port', 'Port', NULL, 'TEXT', NULL, 1, 'Port', 'Port', NULL, NULL, NULL, NULL, now(), now()),\n       (@data_source_type_id, 'driverClassName', 'Driver class name', 'Driver class name', 'com.mysql.jdbc.Driver', 'TEXT', NULL, 1, 'Driver class name (Driver class name)', 'Driver class name', NULL, NULL, NULL, NULL, now(), now()),\n       (@data_source_type_id, 'params', 'Connection params', 'Connection params', NULL, 'TEXT', NULL, 0, 'Input JSON format): {\"param\":\"value\" }', 'Input JSON format: {\"param\":\"value\"}', NULL, NULL, NULL, NULL, now(), now()),\n       (@data_source_type_id, 'username', 'Username', 'Username', NULL, 'TEXT', NULL, 1, 'Username', 'Username', '^[0-9A-Za -z_-]+$', NULL, NULL, NULL, now(), now()),\n       (@data_source_type_id, 'password', 'Password', 'Password', NULL, 'PASSWORD', NULL, 0, 'Password', 'Password', '', NULL, NULL, NULL, now (), now()),\n       (@data_source_type_id, 'instance', 'Instance name (instance)', 'Instance', NULL, 'TEXT', NULL, 1, 'Instance name (instance)', 'Instance', NULL, NULL, NULL, NULL, now(), now());\n\nINSERT INTO `linkis_ps_dm_datasource_type` (`name`, `description`, `option`, `classifier`, `icon`, `layers`, `description_en`, `option_en`, `classifier_en`) VALUES ('gaussdb', 'gaussdb Database', 'gaussdb', 'Relational Database', '', 3, 'GaussDB Database', 'GaussDB', 'Relational Database');\n\nselect @data_source_type_id := id from `linkis_ps_dm_datasource_type` where `name` = 'gaussdb';\nINSERT INTO `linkis_ps_dm_datasource_type_key`\n(`data_source_type_id`, `key`, `name`, `name_en`, `default_value`, `value_type`, `scope`, `require`, `description`, `description_en`, `value_regex`, `ref_id`, ` ref_value`, `data_source`, `update_time`, `create_time`)\nVALUES (@data_source_type_id, 'address', 'Address', 'Address', NULL, 'TEXT', NULL, 0, 'Address(host1:port1,host2:port2...)', 'Address(host1:port1, host2:port2...)', NULL, NULL, NULL, NULL, now(), now()),\n       (@data_source_type_id, 'host', 'Host', 'Host', NULL, 'TEXT', NULL, 1, 'Host', 'Host', NULL, NULL, NULL, NULL, now(), now()),\n       (@data_source_type_id, 'port', 'Port', 'Port', NULL, 'TEXT', NULL, 1, 'Port', 'Port', NULL, NULL, NULL, NULL, now(), now()),\n       (@data_source_type_id, 'driverClassName', 'Driver class name', 'Driver class name', 'org.postgresql.Driver', 'TEXT', NULL, 1, 'Driver class name) ', 'Driver class name', NULL, NULL, NULL, NULL, now(), now()),\n       (@data_source_type_id, 'params', 'Connection params', 'Connection params', NULL, 'TEXT', NULL, 0, 'Input JSON format): {\"param\":\"value\" }', 'Input JSON format: {\"param\":\"value\"}', NULL, NULL, NULL, NULL, now(), now()),\n       (@data_source_type_id, 'username', 'Username', 'Username', NULL, 'TEXT', NULL, 1, 'Username', 'Username', '^[0-9A-Za -z_-]+$', NULL, NULL, NULL, now(), now()),\n       (@data_source_type_id, 'password', 'Password', 'Password', NULL, 'PASSWORD', NULL, 1, 'Password', 'Password', '', NULL, NULL, NULL, now (), now()),\n       (@data_source_type_id, 'instance', 'Instance name (instance)', 'Instance', NULL, 'TEXT', NULL, 1, 'Instance name (instance)', 'Instance', NULL, NULL, NULL, NULL, now(), now());\n\nINSERT INTO `linkis_ps_dm_datasource_type` (`name`, `description`, `option`, `classifier`, `icon`, `layers`, `description_en`, `option_en`, `classifier_en`) VALUES ('oceanbase', 'oceanbase` Database', 'oceanbase', 'olap', '', 4, 'oceanbase Database', 'oceanbase', 'Olap');\n\nselect @data_source_type_id := id from `linkis_ps_dm_datasource_type` where `name` = 'oceanbase';\nINSERT INTO `linkis_ps_dm_datasource_type_key`\n(`data_source_type_id`, `key`, `name`, `name_en`, `default_value`, `value_type`, `scope`, `require`, `description`, `description_en`, `value_regex`, `ref_id`, ` ref_value`, `data_source`, `update_time`, `create_time`)\nVALUES (@data_source_type_id, 'address', 'Address', 'Address', NULL, 'TEXT', NULL, 0, 'Address(host1:port1,host2:port2...)', 'Address(host1:port1, host2:port2...)', NULL, NULL, NULL, NULL, now(), now()),\n       (@data_source_type_id, 'host', 'Host', 'Host', NULL, 'TEXT', NULL, 1, 'Host', 'Host', NULL, NULL, NULL, NULL, now(), now()),\n       (@data_source_type_id, 'port', 'Port', 'Port', NULL, 'TEXT', NULL, 1, 'Port', 'Port', NULL, NULL, NULL, NULL, now(), now()),\n       (@data_source_type_id, 'driverClassName', 'Driver class name', 'Driver class name', 'com.mysql.jdbc.Driver', 'TEXT', NULL, 1, 'Driver class name (Driver class name)', 'Driver class name', NULL, NULL, NULL, NULL, now(), now()),\n       (@data_source_type_id, 'params', 'Connection params', 'Connection params', NULL, 'TEXT', NULL, 0, 'Input JSON format): {\"param\":\"value\" }', 'Input JSON format: {\"param\":\"value\"}', NULL, NULL, NULL, NULL, now(), now()),\n       (@data_source_type_id, 'username', 'Username', 'Username', NULL, 'TEXT', NULL, 1, 'Username', 'Username', '^[0-9A-Za -z_-]+$', NULL, NULL, NULL, now(), now()),\n       (@data_source_type_id, 'password', 'Password', 'Password', NULL, 'PASSWORD', NULL, 1, 'Password', 'Password', '', NULL, NULL, NULL, now (), now()),\n       (@data_source_type_id, 'instance', 'Instance name (instance)', 'Instance', NULL, 'TEXT', NULL, 1, 'Instance name (instance)', 'Instance', NULL, NULL, NULL, NULL, now(), now());\n")),(0,r.kt)("h2",{id:"4-add-mysql-driver-package"},"4. Add mysql driver package"),(0,r.kt)("p",null,"When linkis is upgraded to version 1.4.0, the mysql driver package needs to use version 8.x. Take version 8.0.28 as an example: ","[Download link]","(",(0,r.kt)("a",{parentName:"p",href:"https://repo1.maven.org/maven2/mysql/mysql-connector-java"},"https://repo1.maven.org/maven2/mysql/mysql-connector-java")," /8.0.28/mysql-connector-java-8.0.28.jar) copy the driver package to the lib package"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"cp mysql-connector-java-8.0.28.jar ${LINKIS_HOME}/lib/linkis-spring-cloud-services/linkis-mg-gateway/\ncp mysql-connector-java-8.0.28.jar ${LINKIS_HOME}/lib/linkis-commons/public-module/\n")),(0,r.kt)("h2",{id:"5-start-the-service"},"5. Start the service"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"sh linkis-start-all.sh\n")),(0,r.kt)("h2",{id:"6-precautions"},"6. Precautions"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"After Spark is upgraded to 3.x, it is not compatible with python2, so you need to install python3 when executing pyspark tasks, and perform the following operations")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"sudo ln -snf /usr/bin/python3 /usr/bin/python2\n")),(0,r.kt)("p",null,"And add the following configuration in the spark engine configuration $LINKIS_HOME/lib/linkis-engineconn-plugins/spark/dist/3.2.1/conf/linkis-engineconn.properties, specify the python installation path"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"pyspark.python3.path=/usr/bin/python3\n")),(0,r.kt)("ol",{start:2},(0,r.kt)("li",{parentName:"ol"},"The Token value in the configuration file cannot be automatically unified with the original database Token value during upgrade. You need to manually modify the Token value in the ",(0,r.kt)("inlineCode",{parentName:"li"},"linkis.properties")," and ",(0,r.kt)("inlineCode",{parentName:"li"},"linkis-cli/linkis-cli.properties")," files to the Token value corresponding to the data table ",(0,r.kt)("inlineCode",{parentName:"li"},"linkis_mg_gateway_auth_token"),"."),(0,r.kt)("li",{parentName:"ol"},"When upgrading from a lower version to a higher version, execute the database upgrade script step by step.")))}u.isMDXComponent=!0}}]);