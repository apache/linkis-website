"use strict";(self.webpackChunklinkis_web_apache=self.webpackChunklinkis_web_apache||[]).push([[17276],{3905:(e,t,a)=>{a.d(t,{Zo:()=>d,kt:()=>k});var n=a(67294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function l(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?l(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):l(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},l=Object.keys(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var o=n.createContext({}),p=function(e){var t=n.useContext(o),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},d=function(e){var t=p(e.components);return n.createElement(o.Provider,{value:t},e.children)},u="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},c=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,l=e.originalType,o=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),u=p(a),c=r,k=u["".concat(o,".").concat(c)]||u[c]||m[c]||l;return a?n.createElement(k,i(i({ref:t},d),{},{components:a})):n.createElement(k,i({ref:t},d))}));function k(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var l=a.length,i=new Array(l);i[0]=c;var s={};for(var o in t)hasOwnProperty.call(t,o)&&(s[o]=t[o]);s.originalType=e,s[u]="string"==typeof e?e:r,i[1]=s;for(var p=2;p<l;p++)i[p]=a[p];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}c.displayName="MDXCreateElement"},52397:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>o,contentTitle:()=>i,default:()=>m,frontMatter:()=>l,metadata:()=>s,toc:()=>p});var n=a(87462),r=(a(67294),a(3905));const l={title:"Generate SQL from the data source",sidebar_position:.2},i=void 0,s={unversionedId:"feature/datasource-generate-sql",id:"feature/datasource-generate-sql",title:"Generate SQL from the data source",description:"1. Background",source:"@site/docs/feature/datasource-generate-sql.md",sourceDirName:"feature",slug:"/feature/datasource-generate-sql",permalink:"/docs/1.4.0/feature/datasource-generate-sql",draft:!1,editUrl:"https://github.com/apache/linkis-website/edit/dev/docs/feature/datasource-generate-sql.md",tags:[],version:"current",sidebarPosition:.2,frontMatter:{title:"Generate SQL from the data source",sidebar_position:.2},sidebar:"tutorialSidebar",previous:{title:"reduce base engine compatibility issues",permalink:"/docs/1.4.0/feature/base-engine-compatibilty"},next:{title:"Eureka reports version metadata",permalink:"/docs/1.4.0/feature/eureka-version-metadata"}},o={},p=[{value:"1. Background",id:"1-background",level:2},{value:"2. Instructions for use",id:"2-instructions-for-use",level:2},{value:"Generate SparkSQL",id:"generate-sparksql",level:3},{value:"Generate JdbcSQL",id:"generate-jdbcsql",level:3},{value:"3. Precautions",id:"3-precautions",level:2},{value:"4. Implementation principle",id:"4-implementation-principle",level:2},{value:"Generate SparkSQL implementation principles",id:"generate-sparksql-implementation-principles",level:3},{value:"Generate JdbcSQL implementation principles",id:"generate-jdbcsql-implementation-principles",level:3}],d={toc:p},u="wrapper";function m(e){let{components:t,...a}=e;return(0,r.kt)(u,(0,n.Z)({},d,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"1-background"},"1. Background"),(0,r.kt)("p",null,"SparkSQL and JdbcSQL are generated based on data source information, including DDL, DML, and DQL"),(0,r.kt)("h2",{id:"2-instructions-for-use"},"2. Instructions for use"),(0,r.kt)("h3",{id:"generate-sparksql"},"Generate SparkSQL"),(0,r.kt)("p",null,"Parameter Description:"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"parameter name"),(0,r.kt)("th",{parentName:"tr",align:null},"description"),(0,r.kt)("th",{parentName:"tr",align:null},"default value"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"dataSourceName")),(0,r.kt)("td",{parentName:"tr",align:null},"Data source name"),(0,r.kt)("td",{parentName:"tr",align:null},"-")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"system")),(0,r.kt)("td",{parentName:"tr",align:null},"System name"),(0,r.kt)("td",{parentName:"tr",align:null},"-")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"database")),(0,r.kt)("td",{parentName:"tr",align:null},"Database name"),(0,r.kt)("td",{parentName:"tr",align:null},"-")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"table")),(0,r.kt)("td",{parentName:"tr",align:null},"Table name"),(0,r.kt)("td",{parentName:"tr",align:null},"-")))),(0,r.kt)("p",null,"Submit the task through RestFul, the request example is as follows."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-json"},"GET /api/rest_j/v1/metadataQuery/getSparkSql?dataSourceName=mysql&system=system&database=test&table=test\n")),(0,r.kt)("p",null,"The following is an example of the response."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-json"},'{\n    "method": null,\n    "status": 0,\n    "message": "OK",\n    "data": {\n        "sparkSql": {\n            "ddl": "CREATE TEMPORARY TABLE test USING org.apache.spark.sql.jdbc OPTIONS (  url \'jdbc:mysql://localhost:3306/test\',  dbtable \'test\',  user \'root\',  password \'password\')",\n            "dml": "INSERT INTO test SELECT * FROM ${resultTable}",\n            "dql": "SELECT id,name FROM test"\n        }\n    }\n}\n')),(0,r.kt)("p",null,"Currently, jdbc, kafka, elasticsearch, and mongo data sources are supported. You can register spark table based on SparkSQLDdl for query"),(0,r.kt)("h3",{id:"generate-jdbcsql"},"Generate JdbcSQL"),(0,r.kt)("p",null,"Parameter Description:"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"parameter name"),(0,r.kt)("th",{parentName:"tr",align:null},"description"),(0,r.kt)("th",{parentName:"tr",align:null},"default value"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"dataSourceName")),(0,r.kt)("td",{parentName:"tr",align:null},"Data source name"),(0,r.kt)("td",{parentName:"tr",align:null},"-")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"system")),(0,r.kt)("td",{parentName:"tr",align:null},"System name"),(0,r.kt)("td",{parentName:"tr",align:null},"-")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"database")),(0,r.kt)("td",{parentName:"tr",align:null},"Database name"),(0,r.kt)("td",{parentName:"tr",align:null},"-")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("inlineCode",{parentName:"td"},"table")),(0,r.kt)("td",{parentName:"tr",align:null},"Table name"),(0,r.kt)("td",{parentName:"tr",align:null},"-")))),(0,r.kt)("p",null,"Submit the task through RestFul, the request example is as follows."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-json"},"GET /api/rest_j/v1/metadataQuery/getJdbcSql?dataSourceName=mysql&system=system&database=test&table=test\n")),(0,r.kt)("p",null,"The following is an example of the response."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "method": null,\n  "status": 0,\n  "message": "OK",\n  "data": {\n    "jdbcSql": {\n      "ddl": "CREATE TABLE `test` (\\n\\t  `id` varchar(64) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL COMMENT \'\u5217\u540d\u662fid\',\\n\\t  `name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL COMMENT \'\u5217\u540d\u662fname\',\\n\\t  PRIMARY KEY (`id`)\\n\\t) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci",\n      "dml": "INSERT INTO test SELECT * FROM ${resultTable}",\n      "dql": "SELECT id,name FROM test"\n    }\n  }\n}\n')),(0,r.kt)("p",null,"Currently, jdbc data sources are supported, such as mysql, oracle, and postgres. JdbcSQLDdl can be used for front-end display"),(0,r.kt)("h2",{id:"3-precautions"},"3. Precautions"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"You need to register the data source first")),(0,r.kt)("h2",{id:"4-implementation-principle"},"4. Implementation principle"),(0,r.kt)("h3",{id:"generate-sparksql-implementation-principles"},"Generate SparkSQL implementation principles"),(0,r.kt)("p",null,"Define DDL_SQL_TEMPLATE to retrieve data source information for replacement"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-java"},'  public static final String JDBC_DDL_SQL_TEMPLATE =\n        "CREATE TEMPORARY TABLE %s "\n        + "USING org.apache.spark.sql.jdbc "\n        + "OPTIONS ("\n        + "  url \'%s\',"\n        + "  dbtable \'%s\',"\n        + "  user \'%s\',"\n        + "  password \'%s\'"\n        + ")";\n')),(0,r.kt)("h3",{id:"generate-jdbcsql-implementation-principles"},"Generate JdbcSQL implementation principles"),(0,r.kt)("p",null,"Concatenate DDL based on the table schema information"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-java"},'  public String generateJdbcDdlSql(String database, String table) {\n        StringBuilder ddl = new StringBuilder();\n        ddl.append("CREATE TABLE ").append(String.format("%s.%s", database, table)).append(" (");\n\n        try {\n        List<MetaColumnInfo> columns = getColumns(database, table);\n        if (CollectionUtils.isNotEmpty(columns)) {\n        for (MetaColumnInfo column : columns) {\n        ddl.append("\\n\\t").append(column.getName()).append(" ").append(column.getType());\n        if (column.getLength() > 0) {\n        ddl.append("(").append(column.getLength()).append(")");\n        }\n        if (!column.isNullable()) {\n        ddl.append(" NOT NULL");\n        }\n        ddl.append(",");\n        }\n        String primaryKeys =\n        columns.stream()\n        .filter(MetaColumnInfo::isPrimaryKey)\n        .map(MetaColumnInfo::getName)\n        .collect(Collectors.joining(", "));\n        if (StringUtils.isNotBlank(primaryKeys)) {\n        ddl.append(String.format("\\n\\tPRIMARY KEY (%s),", primaryKeys));\n        }\n        ddl.deleteCharAt(ddl.length() - 1);\n        }\n        } catch (Exception e) {\n        LOG.warn("Fail to get Sql columns(\u83b7\u53d6\u5b57\u6bb5\u5217\u8868\u5931\u8d25)");\n        }\n\n        ddl.append("\\n)");\n\n        return ddl.toString();\n        }\n')),(0,r.kt)("p",null,"Some data sources support fetching DDL directly"),(0,r.kt)("p",null,"mysql"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"SHOW CREATE TABLE 'table'\n")),(0,r.kt)("p",null,"oracle"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT DBMS_METADATA.GET_DDL('TABLE', 'table', 'database') AS DDL  FROM DUAL\n")))}m.isMDXComponent=!0}}]);