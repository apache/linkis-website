"use strict";(self.webpackChunklinkis_web_apache=self.webpackChunklinkis_web_apache||[]).push([[938],{3905:(e,r,t)=>{t.d(r,{Zo:()=>l,kt:()=>v});var n=t(67294);function o(e,r,t){return r in e?Object.defineProperty(e,r,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[r]=t,e}function a(e,r){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);r&&(n=n.filter((function(r){return Object.getOwnPropertyDescriptor(e,r).enumerable}))),t.push.apply(t,n)}return t}function i(e){for(var r=1;r<arguments.length;r++){var t=null!=arguments[r]?arguments[r]:{};r%2?a(Object(t),!0).forEach((function(r){o(e,r,t[r])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):a(Object(t)).forEach((function(r){Object.defineProperty(e,r,Object.getOwnPropertyDescriptor(t,r))}))}return e}function s(e,r){if(null==e)return{};var t,n,o=function(e,r){if(null==e)return{};var t,n,o={},a=Object.keys(e);for(n=0;n<a.length;n++)t=a[n],r.indexOf(t)>=0||(o[t]=e[t]);return o}(e,r);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(n=0;n<a.length;n++)t=a[n],r.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(o[t]=e[t])}return o}var u=n.createContext({}),p=function(e){var r=n.useContext(u),t=r;return e&&(t="function"==typeof e?e(r):i(i({},r),e)),t},l=function(e){var r=p(e.components);return n.createElement(u.Provider,{value:r},e.children)},c="mdxType",d={inlineCode:"code",wrapper:function(e){var r=e.children;return n.createElement(n.Fragment,{},r)}},f=n.forwardRef((function(e,r){var t=e.components,o=e.mdxType,a=e.originalType,u=e.parentName,l=s(e,["components","mdxType","originalType","parentName"]),c=p(t),f=o,v=c["".concat(u,".").concat(f)]||c[f]||d[f]||a;return t?n.createElement(v,i(i({ref:r},l),{},{components:t})):n.createElement(v,i({ref:r},l))}));function v(e,r){var t=arguments,o=r&&r.mdxType;if("string"==typeof e||o){var a=t.length,i=new Array(a);i[0]=f;var s={};for(var u in r)hasOwnProperty.call(r,u)&&(s[u]=r[u]);s.originalType=e,s[c]="string"==typeof e?e:o,i[1]=s;for(var p=2;p<a;p++)i[p]=t[p];return n.createElement.apply(null,i)}return n.createElement.apply(null,t)}f.displayName="MDXCreateElement"},13999:(e,r,t)=>{t.r(r),t.d(r,{assets:()=>u,contentTitle:()=>i,default:()=>d,frontMatter:()=>a,metadata:()=>s,toc:()=>p});var n=t(87462),o=(t(67294),t(3905));const a={title:"upgrade hadoopsparkhive default version to 3.x",sidebar_position:.2},i=void 0,s={unversionedId:"feature/upgrade-base-engine-version",id:"feature/upgrade-base-engine-version",title:"upgrade hadoop\\spark\\hive default version to 3.x",description:"1. Requirement Background",source:"@site/docs/feature/upgrade-base-engine-version.md",sourceDirName:"feature",slug:"/feature/upgrade-base-engine-version",permalink:"/docs/1.4.0/feature/upgrade-base-engine-version",draft:!1,editUrl:"https://github.com/apache/linkis-website/edit/dev/docs/feature/upgrade-base-engine-version.md",tags:[],version:"current",sidebarPosition:.2,frontMatter:{title:"upgrade hadoop\\spark\\hive default version to 3.x",sidebar_position:.2},sidebar:"tutorialSidebar",previous:{title:"Extend linkis-storage add support OSS filesystem",permalink:"/docs/1.4.0/feature/storage-add-support-oss"},next:{title:"version number and branch modification instructions",permalink:"/docs/1.4.0/feature/version-and-branch-intro"}},u={},p=[{value:"1. Requirement Background",id:"1-requirement-background",level:2},{value:"2. Instructions for use",id:"2-instructions-for-use",level:2},{value:"3. Precautions",id:"3-precautions",level:2}],l={toc:p},c="wrapper";function d(e){let{components:r,...t}=e;return(0,o.kt)(c,(0,n.Z)({},l,t,{components:r,mdxType:"MDXLayout"}),(0,o.kt)("h2",{id:"1-requirement-background"},"1. Requirement Background"),(0,o.kt)("p",null,"fow now we support different hadoop, hive ,spark version compile, and lower engine version may have potential CVE risk"),(0,o.kt)("h2",{id:"2-instructions-for-use"},"2. Instructions for use"),(0,o.kt)("p",null,"default hadoop version changes from 2.7.2 to 3.3.4\ndefault hive version changes from 2.3.3 to 3.1.3\ndefault spark version changes from 2.4.3 to 3.2.1"),(0,o.kt)("h2",{id:"3-precautions"},"3. Precautions"),(0,o.kt)("p",null,"for the default compilation, versions will be spark3.2.1+hadoop3.3.4+hive3.1.3."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"mvn install package\n")),(0,o.kt)("p",null,"profile spark-3.2 \u3001 hadoop-3.3 \u3001spark-2.4-hadoop-3.3 profiles have been removed and profile hadoop-2.7 and spark-2.4 have been added instead."))}d.isMDXComponent=!0}}]);