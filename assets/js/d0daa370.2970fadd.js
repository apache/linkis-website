"use strict";(self.webpackChunklinkis_web_apache=self.webpackChunklinkis_web_apache||[]).push([[24330],{3905:(e,t,n)=>{n.d(t,{Zo:()=>d,kt:()=>h});var i=n(67294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);t&&(i=i.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,i)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,i,a=function(e,t){if(null==e)return{};var n,i,a={},o=Object.keys(e);for(i=0;i<o.length;i++)n=o[i],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(i=0;i<o.length;i++)n=o[i],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var s=i.createContext({}),p=function(e){var t=i.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},d=function(e){var t=p(e.components);return i.createElement(s.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return i.createElement(i.Fragment,{},t)}},u=i.forwardRef((function(e,t){var n=e.components,a=e.mdxType,o=e.originalType,s=e.parentName,d=l(e,["components","mdxType","originalType","parentName"]),u=p(n),h=a,m=u["".concat(s,".").concat(h)]||u[h]||c[h]||o;return n?i.createElement(m,r(r({ref:t},d),{},{components:n})):i.createElement(m,r({ref:t},d))}));function h(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=n.length,r=new Array(o);r[0]=u;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:a,r[1]=l;for(var p=2;p<o;p++)r[p]=n[p];return i.createElement.apply(null,r)}return i.createElement.apply(null,n)}u.displayName="MDXCreateElement"},51676:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>r,default:()=>c,frontMatter:()=>o,metadata:()=>l,toc:()=>p});var i=n(87462),a=(n(67294),n(3905));const o={title:"Quick Deployment",sidebar_position:1},r=void 0,l={unversionedId:"deployment/quick-deploy",id:"version-1.1.2/deployment/quick-deploy",title:"Quick Deployment",description:"1. Preparing for the first installation",source:"@site/versioned_docs/version-1.1.2/deployment/quick-deploy.md",sourceDirName:"deployment",slug:"/deployment/quick-deploy",permalink:"/docs/1.1.2/deployment/quick-deploy",draft:!1,editUrl:"https://github.com/apache/incubator-linkis-website/edit/dev/versioned_docs/version-1.1.2/deployment/quick-deploy.md",tags:[],version:"1.1.2",sidebarPosition:1,frontMatter:{title:"Quick Deployment",sidebar_position:1},sidebar:"version-1.1.2/tutorialSidebar",previous:{title:"Version Overview",permalink:"/docs/1.1.2/release"},next:{title:"Cluster Deployment",permalink:"/docs/1.1.2/deployment/cluster-deployment"}},s={},p=[{value:"1. Preparing for the first installation",id:"1-preparing-for-the-first-installation",level:2},{value:"1.1 Linux Server",id:"11-linux-server",level:3},{value:"1.2 Add deployment user",id:"12-add-deployment-user",level:3},{value:"2. Configuration modification",id:"2-configuration-modification",level:2},{value:"2.1 Installation package preparation",id:"21-installation-package-preparation",level:3},{value:"2.2 Configure database information",id:"22-configure-database-information",level:3},{value:"2.3 Configure basic variables",id:"23-configure-basic-variables",level:3},{value:"deploy user",id:"deploy-user",level:4},{value:"base directory configuration (optional)",id:"base-directory-configuration-optional",level:4},{value:"Yarn&#39;s ResourceManager address",id:"yarns-resourcemanager-address",level:4},{value:"Basic component environment information",id:"basic-component-environment-information",level:4},{value:"LDAP login configuration (optional)",id:"ldap-login-configuration-optional",level:4},{value:"JVM memory configuration (optional)",id:"jvm-memory-configuration-optional",level:4},{value:"Installation directory configuration (optional)",id:"installation-directory-configuration-optional",level:4},{value:"Data source service is enabled (optional)",id:"data-source-service-is-enabled-optional",level:4},{value:"No HDFS mode deployment (optional &gt;1.1.2 version support hold)",id:"no-hdfs-mode-deployment-optional-112-version-support-hold",level:4},{value:"3. Install and start",id:"3-install-and-start",level:2},{value:"3.1 Execute the installation script:",id:"31-execute-the-installation-script",level:3},{value:'<font color="red">3.2 Add mysql driver package</font>',id:"32-add-mysql-driver-package",level:3},{value:"3.3 Configuration Adjustment (Optional)",id:"33-configuration-adjustment-optional",level:3},{value:"3.3.1 kerberos authentication",id:"331-kerberos-authentication",level:4},{value:"3.3.2 Yarn Authentication",id:"332-yarn-authentication",level:4},{value:"3.3.3 session",id:"333-session",level:4},{value:"3.4 Start the service",id:"34-start-the-service",level:3},{value:"3.5 Modification of post-installation configuration",id:"35-modification-of-post-installation-configuration",level:3},{value:"3.6 Check whether the service starts normally",id:"36-check-whether-the-service-starts-normally",level:3},{value:"4. Install the web frontend",id:"4-install-the-web-frontend",level:2},{value:"4.1 Download the front-end installation package and unzip it",id:"41-download-the-front-end-installation-package-and-unzip-it",level:3},{value:"4.2 Modify the configuration config.sh",id:"42-modify-the-configuration-configsh",level:3},{value:"4.3 Execute the deployment script",id:"43-execute-the-deployment-script",level:3},{value:"4.4 Login to the console",id:"44-login-to-the-console",level:3},{value:"5. Verify basic functionality",id:"5-verify-basic-functionality",level:2},{value:"6 Installation of development tool IDE (Scriptis) (optional)",id:"6-installation-of-development-tool-ide-scriptis-optional",level:2},{value:"7. Supported Engines",id:"7-supported-engines",level:2},{value:"7.1 Engine Adaptation List",id:"71-engine-adaptation-list",level:3},{value:"7.2 View the deployed engine",id:"72-view-the-deployed-engine",level:3},{value:"Method 1: View the engine lib package directory",id:"method-1-view-the-engine-lib-package-directory",level:4},{value:"Method 2: View the database table of linkis",id:"method-2-view-the-database-table-of-linkis",level:4},{value:"8. Troubleshooting Guidelines for Common Abnormal Problems",id:"8-troubleshooting-guidelines-for-common-abnormal-problems",level:2},{value:"8.1. Yarn Queue Check",id:"81-yarn-queue-check",level:3},{value:"8.1.1 Check whether the yarn address is configured correctly",id:"811-check-whether-the-yarn-address-is-configured-correctly",level:4},{value:"8.1.2 Check whether the yarn queue exists",id:"812-check-whether-the-yarn-queue-exists",level:4},{value:"8.2 Check whether the engine material resource is uploaded successfully",id:"82-check-whether-the-engine-material-resource-is-uploaded-successfully",level:3},{value:"8.3 Login password problem",id:"83-login-password-problem",level:3},{value:"8.4 version compatibility issues",id:"84-version-compatibility-issues",level:3},{value:"8.5 How to locate the server exception log",id:"85-how-to-locate-the-server-exception-log",level:3},{value:"8.6 Exception troubleshooting of execution engine tasks",id:"86-exception-troubleshooting-of-execution-engine-tasks",level:3},{value:"8.7 How to modify the port of the registry eureka",id:"87-how-to-modify-the-port-of-the-registry-eureka",level:3},{value:"8.8 Notes on CDH adaptation version",id:"88-notes-on-cdh-adaptation-version",level:3},{value:"8.9 Debugging of Http interface",id:"89-debugging-of-http-interface",level:3},{value:"8.10 Troubleshooting process for abnormal problems",id:"810-troubleshooting-process-for-abnormal-problems",level:3},{value:"9. How to obtain relevant information",id:"9-how-to-obtain-relevant-information",level:2}],d={toc:p};function c(e){let{components:t,...o}=e;return(0,a.kt)("wrapper",(0,i.Z)({},d,o,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h2",{id:"1-preparing-for-the-first-installation"},"1. Preparing for the first installation"),(0,a.kt)("h3",{id:"11-linux-server"},"1.1 Linux Server"),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Hardware requirements"),"\nInstall nearly 10 linkis microservices with at least 3G memory. **The size of the jvm -Xmx memory started by the default configuration of each microservice is 512M (if the memory is not enough, you can try to reduce it to 256/128M, and you can also increase it if the memory is sufficient)"),(0,a.kt)("h3",{id:"12-add-deployment-user"},"1.2 Add deployment user"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Deployment user: the startup user of the linkis core process, and this user will be the administrator privilege by default. ",(0,a.kt)("font",{color:"red"},"The corresponding administrator login password will be generated during the deployment process, located in ",(0,a.kt)("inlineCode",{parentName:"p"},"conf/linkis-mg-gateway .properties")," file"),"\nLinkis supports specifying the user who submits and executes. The linkis main process service will switch to the corresponding user through ",(0,a.kt)("inlineCode",{parentName:"p"},"sudo -u ${linkis-user}"),", and then execute the corresponding engine start command, so the user to which the engine ",(0,a.kt)("inlineCode",{parentName:"p"},"linkis-engine")," process belongs is the executor of the task (so the deployment The user needs to have sudo permissions, and it is password-free)")),(0,a.kt)("p",null,"Take hadoop user as an example:"),(0,a.kt)("p",null,"First check whether there is already a hadoop user in the system. If it already exists, you can directly authorize it; if not, create a user first, and then authorize."),(0,a.kt)("p",null,"Check if a hadoop user already exists"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"$ id hadoop\nuid=2001(hadoop) gid=2001(hadoop) groups=2001(hadoop)\n")),(0,a.kt)("p",null,"If it does not exist, you need to create a hadoop user and join the hadoop user group"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"$ sudo useradd hadoop -g hadoop\n$ vi /etc/sudoers\n#Secret-free configuration\nhadoop ALL=(ALL) NOPASSWD: NOPASSWD: ALL\n")),(0,a.kt)("font",{color:"red"},"The following operations are performed under the hadoop user"),(0,a.kt)("h2",{id:"2-configuration-modification"},"2. Configuration modification"),(0,a.kt)("h3",{id:"21-installation-package-preparation"},"2.1 Installation package preparation"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Method 1: From the official website ",(0,a.kt)("a",{parentName:"li",href:"https://linkis.apache.org/download/main"},"download address"),": ",(0,a.kt)("a",{parentName:"li",href:"https://linkis.apache.org/download/main"},"https://linkis.apache.org/download/main"),", download the corresponding The installation package (project installation package and management console installation package)"),(0,a.kt)("li",{parentName:"ul"},"Method 2: Compile the project installation package and management console according to ",(0,a.kt)("a",{parentName:"li",href:"../development/linkis-compile-and-package"},"Linkis Compile and Package")," and ",(0,a.kt)("a",{parentName:"li",href:"../development/web-build"},"Front-end Management Console Compile")," Installation package")),(0,a.kt)("p",null,"After uploading the installation package ",(0,a.kt)("inlineCode",{parentName:"p"},"apache-linkis-x.x.x-incubating-bin.tar.gz"),", decompress the installation package"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"$ tar -xvf apache-linkis-x.x.x-incubating-bin.tar.gz\n")),(0,a.kt)("p",null,"The unzipped directory structure is as follows"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"-rw-r--r-- 1 hadoop hadoop 531847342 Feb 21 10:10 apache-linkis-1.0.3-incubating-bin.tar.gz\ndrwxrwxr-x 2 hadoop hadoop 4096 Feb 21 10:13 bin //Script to perform environment check and install\ndrwxrwxr-x 2 hadoop hadoop 4096 Feb 21 10:13 deploy-config // Environment configuration information such as DB that depends on deployment\n-rw-r--r-- 1 hadoop hadoop 1707 Jan 22 2020 DISCLAIMER-WIP\n-rw-r--r-- 1 hadoop hadoop 66058 Jan 22 2020 LICENSE\ndrwxrwxr-x 2 hadoop hadoop 16384 Feb 21 10:13 licenses\ndrwxrwxr-x 7 hadoop hadoop 4096 Feb 21 10:13 linkis-package // The actual package, including lib/service startup script tool/db initialization script/microservice configuration file, etc.\n-rw-r--r-- 1 hadoop hadoop 83126 Jan 22 2020 NOTICE\n-rw-r--r-- 1 hadoop hadoop 7900 Jan 22 2020 README_CN.md\n-rw-r--r-- 1 hadoop hadoop 8184 Jan 22 2020 README.md\n\n")),(0,a.kt)("h3",{id:"22-configure-database-information"},"2.2 Configure database information"),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"vim deploy-config/db.sh")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},'# Database information of Linkis\' own business\nMYSQL_HOST=xx.xx.xx.xx\nMYSQL_PORT=3306\nMYSQL_DB=linkis_test\nMYSQL_USER=test\nMYSQL_PASSWORD=xxxxx\n\n# Provide the DB information of the Hive metadata database. If the hive engine is not involved (or just a simple trial), you can not configure it\n#Mainly used with scripts, if not configured, it will try to obtain it through the configuration file in $HIVE_CONF_DIR by default\nHIVE_META_URL="jdbc:mysql://10.10.10.10:3306/hive_meta_demo?useUnicode=true&amp;characterEncoding=UTF-8"\nHIVE_META_USER=demo # User of HiveMeta Metabase\nHIVE_META_PASSWORD=demo123 # HiveMeta metabase password\n')),(0,a.kt)("h3",{id:"23-configure-basic-variables"},"2.3 Configure basic variables"),(0,a.kt)("p",null,"The file is located at ",(0,a.kt)("inlineCode",{parentName:"p"},"deploy-config/linkis-env.sh")),(0,a.kt)("h4",{id:"deploy-user"},"deploy user"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"deployUser=hadoop #The user who executes the deployment is the user created in step 1.2\n")),(0,a.kt)("h4",{id:"base-directory-configuration-optional"},"base directory configuration (optional)"),(0,a.kt)("admonition",{title:"note",type:"caution"},(0,a.kt)("p",{parentName:"admonition"},"Determine whether you need to adjust according to the actual situation, you can choose to use the default value")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"\n# Specify the directory path used by the user, which is generally used to store the user's script files and log files, and is the user's workspace. The corresponding configuration file configuration item is wds.linkis.filesystem.root.path(linkis.properties)\nWORKSPACE_USER_ROOT_PATH=file:///tmp/linkis\n\n# File paths such as result set logs, used to store the result set files of the Job wds.linkis.resultSet.store.path(linkis-cg-entrance.properties) //If not configured, use the configuration of HDFS_USER_ROOT_PATH\nRESULT_SET_ROOT_PATH=file:///tmp/linkis\n\n# File path such as result set log, used to store the result set file of Job wds.linkis.filesystem.hdfs.root.path(linkis.properties)\nHDFS_USER_ROOT_PATH=hdfs:///tmp/linkis\n  \n# Store the working path of the execution engine. You need to deploy a local directory with write permissions for the user wds.linkis.engineconn.root.dir(linkis-cg-engineconnmanager.properties)\nENGINECONN_ROOT_PATH=/appcom/tmp\n")),(0,a.kt)("h4",{id:"yarns-resourcemanager-address"},"Yarn's ResourceManager address"),(0,a.kt)("admonition",{title:"note",type:"caution"},(0,a.kt)("p",{parentName:"admonition"},"If you need to use the Spark engine, you need to configure")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"\n#You can confirm whether it can be accessed normally by visiting the http://xx.xx.xx.xx:8088/ws/v1/cluster/scheduler interface\nYARN_RESTFUL_URL=http://xx.xx.xx.xx:8088\n")),(0,a.kt)("p",null,"When executing spark tasks, you need to use the ResourceManager of yarn. By default, linkis does not enable permission verification. If the ResourceManager has password permission verification enabled, please install and deploy it.\nModify the database table ",(0,a.kt)("inlineCode",{parentName:"p"},"linkis_cg_rm_external_resource_provider")," to insert yarn data information. For details, please refer to ","[Check whether the yarn address is configured correctly]"," (#811-Check whether the yarn address is configured correctly)"),(0,a.kt)("h4",{id:"basic-component-environment-information"},"Basic component environment information"),(0,a.kt)("admonition",{title:"note",type:"caution"},(0,a.kt)("p",{parentName:"admonition"},"It can be configured through the user's system environment variables. If configured through the system environment variables, the deploy-config/linkis-env.sh configuration file can be directly commented out without configuration.")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"##If you do not use Hive, Spark and other engines and do not rely on Hadoop, you do not need to configure the following environment variables\n\n#HADOOP\nHADOOP_HOME=/appcom/Install/hadoop\nHADOOP_CONF_DIR=/appcom/config/hadoop-config\n\n#Hive\nHIVE_HOME=/appcom/Install/hive\nHIVE_CONF_DIR=/appcom/config/hive-config\n\n#Spark\nSPARK_HOME=/appcom/Install/spark\nSPARK_CONF_DIR=/appcom/config/spark-config\n")),(0,a.kt)("h4",{id:"ldap-login-configuration-optional"},"LDAP login configuration (optional)"),(0,a.kt)("admonition",{title:"note",type:"caution"},(0,a.kt)("p",{parentName:"admonition"},"The default is to use a static user and password. The static user is the deployment user. The static password will generate a random password string during deployment and store it in ",(0,a.kt)("inlineCode",{parentName:"p"},"{LINKIS_HOME}/conf/linkis-mg-gateway.properties"),"(>=1.0.3 Version)")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"#LDAP configuration, Linkis only supports deployment user login by default. If you need to support multi-user login, you can use LDAP. You need to configure the following parameters:\n#LDAP_URL=ldap://localhost:1389/\n#LDAP_BASEDN=dc=webank,dc=com\n")),(0,a.kt)("h4",{id:"jvm-memory-configuration-optional"},"JVM memory configuration (optional)"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"The microservice starts the jvm memory configuration, which can be adjusted according to the actual situation of the machine. If the machine memory resources are few, you can try to adjust it to 256/128M"),(0,a.kt)("pre",{parentName:"blockquote"},(0,a.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},'## java application default jvm memory\nexport SERVER_HEAP_SIZE="512M"\n'))),(0,a.kt)("h4",{id:"installation-directory-configuration-optional"},"Installation directory configuration (optional)"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Linkis will eventually be installed in this directory. If it is not configured, it will be in the same level directory as the current installation package by default.")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"##The decompression directory and the installation directory need to be inconsistent\nLINKIS_HOME=/appcom/Install/LinkisInstall\n")),(0,a.kt)("h4",{id:"data-source-service-is-enabled-optional"},"Data source service is enabled (optional)"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"According to the actual situation, if you want to use the data source function, you need to adjust")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"#If you want to start metadata related microservices, you can set this export ENABLE_METADATA_MANAGE=true\nexport ENABLE_METADATA_QUERY=true\n")),(0,a.kt)("h4",{id:"no-hdfs-mode-deployment-optional-112-version-support-hold"},"No HDFS mode deployment (optional >1.1.2 version support hold)"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Deploy Linkis services in an environment without HDFS to facilitate more lightweight learning and debugging. Deploying in HDFS mode does not support tasks such as hive/spark/flink engines")),(0,a.kt)("p",null,"Modify the ",(0,a.kt)("inlineCode",{parentName:"p"},"linkis-env.sh")," file and modify the following"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"#Use the [file://] path pattern instead of the [hdfs://] pattern\nWORKSPACE_USER_ROOT_PATH=file:///tmp/linkis/\nHDFS_USER_ROOT_PATH=file:///tmp/linkis\nRESULT_SET_ROOT_PATH=file:///tmp/linkis\n\nexport ENABLE_HDFS=false\nexport ENABLE_HIVE=false\nexport ENABLE_SPARK=false\n")),(0,a.kt)("h2",{id:"3-install-and-start"},"3. Install and start"),(0,a.kt)("h3",{id:"31-execute-the-installation-script"},"3.1 Execute the installation script:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"    sh bin/install.sh\n")),(0,a.kt)("p",null,"The install.sh script will ask you if you need to initialize the database and import metadata. If you choose to initialize, the table data in the database will be emptied and reinitialized."),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},(0,a.kt)("font",{color:"red"},"Empty database must be selected for the first installation"))),(0,a.kt)("admonition",{title:"Note",type:"tip"},(0,a.kt)("ul",{parentName:"admonition"},(0,a.kt)("li",{parentName:"ul"},"If an error occurs, and it is unclear what command to execute to report the error, you can add the -x parameter ",(0,a.kt)("inlineCode",{parentName:"li"},"sh -x bin/install.sh")," to print out the shell script execution process log, which is convenient for locating the problem"),(0,a.kt)("li",{parentName:"ul"},"Permission problem: ",(0,a.kt)("inlineCode",{parentName:"li"},"mkdir: cannot create directory 'xxxx': Permission denied"),", please confirm whether the deployment user has read and write permissions for the path"))),(0,a.kt)("p",null,"The prompt for successful execution is as follows:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"`Congratulations! You have installed Linkis 1.0.3 successfully, please use sh /data/Install/linkis/sbin/linkis-start-all.sh to start it!\nYour default account password is [hadoop/5e8e312b4]`\n")),(0,a.kt)("h3",{id:"32-add-mysql-driver-package"},(0,a.kt)("font",{color:"red"},"3.2 Add mysql driver package")),(0,a.kt)("admonition",{title:"note",type:"caution"},(0,a.kt)("p",{parentName:"admonition"},"Because the mysql-connector-java driver is under the GPL2.0 protocol, it does not meet the license policy of the Apache open source protocol. Therefore, starting from version 1.0.3, the official deployment package of the Apache version provided by default is no mysql-connector-java-x.x.x.jar (",(0,a.kt)("strong",{parentName:"p"},"If it is installed through the integrated family bucket material package, you do not need to add it manually"),"), you need to add dependencies to the corresponding lib package by yourself during installation and deployment. You can check whether it exists in the corresponding directory, if not, you need to add")),(0,a.kt)("p",null,"To download the mysql driver, take version 5.1.49 as an example: ",(0,a.kt)("a",{parentName:"p",href:"https://repo1.maven.org/maven2/mysql/mysql-connector-java/5.1.49/mysql-connector-java-5.1.49.jar"},"download link")),(0,a.kt)("p",null,"Copy the mysql driver package to the lib package"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"cp mysql-connector-java-5.1.49.jar {LINKIS_HOME}/lib/linkis-spring-cloud-services/linkis-mg-gateway/\ncp mysql-connector-java-5.1.49.jar {LINKIS_HOME}/lib/linkis-commons/public-module/\n")),(0,a.kt)("h3",{id:"33-configuration-adjustment-optional"},"3.3 Configuration Adjustment (Optional)"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"The following operations are related to the dependent environment. According to the actual situation, determine whether the operation is required")),(0,a.kt)("h4",{id:"331-kerberos-authentication"},"3.3.1 kerberos authentication"),(0,a.kt)("p",null,"If the hive cluster used has kerberos mode authentication enabled, modify the configuration ",(0,a.kt)("inlineCode",{parentName:"p"},"${LINKIS_HOME}/conf/linkis.properties")," (<=1.1.3) file"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},'#Append the following configuration\necho "wds.linkis.keytab.enable=true" >> linkis.properties\n')),(0,a.kt)("h4",{id:"332-yarn-authentication"},"3.3.2 Yarn Authentication"),(0,a.kt)("p",null,"When executing spark tasks, you need to use the ResourceManager of yarn, which is controlled by the configuration item ",(0,a.kt)("inlineCode",{parentName:"p"},"YARN_RESTFUL_URL=http://xx.xx.xx.xx:8088 "),".\nDuring installation and deployment, the ",(0,a.kt)("inlineCode",{parentName:"p"},"YARN_RESTFUL_URL=http://xx.xx.xx.xx:8088")," information will be updated to the database table ",(0,a.kt)("inlineCode",{parentName:"p"},"linkis_cg_rm_external_resource_provider"),". By default, access to yarn resources does not require permission verification.\nIf password authentication is enabled in yarn's ResourceManager, please modify the yarn data information generated in the database table ",(0,a.kt)("inlineCode",{parentName:"p"},"linkis_cg_rm_external_resource_provider")," after installation and deployment.\nFor details, please refer to ","[Check whether the yarn address is configured correctly]"," (#811-Check whether the yarn address is configured correctly)"),(0,a.kt)("h4",{id:"333-session"},"3.3.3 session"),(0,a.kt)("p",null,"If you are upgrading to Linkis. Deploy DSS or other projects at the same time, but the dependent linkis version introduced in other software is <1.1.1 (mainly in the lib package, the linkis-module-x.x.x.jar package of the dependent Linkis is <1.1.1), you need to modify the linkis located in ",(0,a.kt)("inlineCode",{parentName:"p"}," ${LINKIS_HOME}/conf/linkis.properties")," file"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},'echo "wds.linkis.session.ticket.key=bdp-user-ticket-id" >> linkis.properties\n')),(0,a.kt)("h3",{id:"34-start-the-service"},"3.4 Start the service"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"sh sbin/linkis-start-all.sh\n")),(0,a.kt)("h3",{id:"35-modification-of-post-installation-configuration"},"3.5 Modification of post-installation configuration"),(0,a.kt)("p",null,"After the installation is complete, if you need to modify the configuration (because of port conflicts or some configuration problems, you need to adjust the configuration), you can re-execute the installation, or modify the configuration ",(0,a.kt)("inlineCode",{parentName:"p"},"${LINKIS_HOME}/conf/*properties")," file of the corresponding service, Restart the corresponding service, such as: ",(0,a.kt)("inlineCode",{parentName:"p"},"sh sbin/linkis-daemon.sh start ps-publicservice")),(0,a.kt)("h3",{id:"36-check-whether-the-service-starts-normally"},"3.6 Check whether the service starts normally"),(0,a.kt)("p",null,"Visit the eureka service page (http://eurekaip:20303),\nThe 1.x.x version will start 8 Linkis microservices by default, and the linkis-cg-engineconn service in the figure below will be started only for running tasks\n",(0,a.kt)("img",{alt:"Linkis1.0_Eureka",src:n(76962).Z,width:"1470",height:"505"})),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"LINKIS-CG-ENGINECONNMANAGER Engine Management Services\nLINKIS-CG-ENGINEPLUGIN Engine Plugin Management Service\nLINKIS-CG-ENTRANCE Computing Governance Entry Service\nLINKIS-CG-LINKISMANAGER Computing Governance Management Service\nLINKIS-MG-EUREKA Microservice registry service\nLINKIS-MG-GATEWAY gateway service\nLINKIS-PS-CS context service\nLINKIS-PS-PUBLICSERVICE Public Service\n")),(0,a.kt)("p",null,"If the data source service function is enabled (not enabled by default), you will see these two services"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"LINKIS-PS-DATA-SOURCE-MANAGER\nLINKIS-PS-METADATAMANAGER\n")),(0,a.kt)("p",null,"If any services are not started, you can view detailed exception logs in the corresponding log/${service name}.log file."),(0,a.kt)("h2",{id:"4-install-the-web-frontend"},"4. Install the web frontend"),(0,a.kt)("p",null,"The web side uses nginx as the static resource server, and the access request process is:\n",(0,a.kt)("inlineCode",{parentName:"p"},"Linkis console request->nginx ip:port->linkis-gateway ip:port->other services")),(0,a.kt)("h3",{id:"41-download-the-front-end-installation-package-and-unzip-it"},"4.1 Download the front-end installation package and unzip it"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"tar -xvf apache-linkis-x.x.x-incubating-web-bin.tar.gz\n")),(0,a.kt)("h3",{id:"42-modify-the-configuration-configsh"},"4.2 Modify the configuration config.sh"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},'#Access the port of the console\nlinkis_port="8188"\n\n#linkis-mg-gatewayService Address\nlinkis_url="http://localhost:9020"\n')),(0,a.kt)("h3",{id:"43-execute-the-deployment-script"},"4.3 Execute the deployment script"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"# nginx requires sudo privileges to install\nsudo sh install.sh\n")),(0,a.kt)("p",null,"After installation, linkis' nginx configuration file is by default in ",(0,a.kt)("inlineCode",{parentName:"p"},"/etc/nginx/conf.d/linkis.conf"),"\nnginx log files are in ",(0,a.kt)("inlineCode",{parentName:"p"},"/var/log/nginx/access.log")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"/var/log/nginx/error.log"),"\nAn example of the nginx configuration file of the generated linkis console is as follows:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-nginx"},"\n        server {\n            listen 8188;# access port If the port is occupied, it needs to be modified\n            server_name localhost;\n            #charset koi8-r;\n            #access_log /var/log/nginx/host.access.log main;\n            location / {\n            root /appcom/Install/linkis-web/dist; # static file directory\n            index index.html index.html;\n            }\n            location /ws {\n            proxy_pass http://localhost:9020;#Address of backend Linkis\n            proxy_http_version 1.1;\n            proxy_set_header Upgrade $http_upgrade;\n            proxy_set_header Connection upgrade;\n            }\n\n            location /api {\n            proxy_pass http://localhost:9020; #Address of backend Linkis\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header x_real_ipP $remote_addr;\n            proxy_set_header remote_addr $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_http_version 1.1;\n            proxy_connect_timeout 4s;\n            proxy_read_timeout 600s;\n            proxy_send_timeout 12s;\n            proxy_set_header Upgrade $http_upgrade;\n            proxy_set_header Connection upgrade;\n            }\n\n            #error_page 404 /404.html;\n            # redirect server error pages to the static page /50x.html\n            #\n            error_page 500 502 503 504 /50x.html;\n            location = /50x.html {\n            root /usr/share/nginx/html;\n            }\n        }\n")),(0,a.kt)("p",null,"If you need to modify the port or static resource directory, etc., please modify the ",(0,a.kt)("inlineCode",{parentName:"p"},"/etc/nginx/conf.d/linkis.conf")," file and execute the ",(0,a.kt)("inlineCode",{parentName:"p"},"sudo nginx -s reload")," command"),(0,a.kt)("admonition",{title:"note",type:"caution"},(0,a.kt)("ul",{parentName:"admonition"},(0,a.kt)("li",{parentName:"ul"},"At present, the visualis function is not integrated. During the installation process, if you are prompted that the installation of linkis/visualis fails, you can ignore it"),(0,a.kt)("li",{parentName:"ul"},"Check whether nginx starts normally: check whether the nginx process exists ",(0,a.kt)("inlineCode",{parentName:"li"},"ps -ef |grep nginx")),(0,a.kt)("li",{parentName:"ul"},"Check if nginx is configured correctly ",(0,a.kt)("inlineCode",{parentName:"li"},"sudo nginx -T")),(0,a.kt)("li",{parentName:"ul"},"If the port is occupied, you can modify the service port ",(0,a.kt)("inlineCode",{parentName:"li"},"/etc/nginx/conf.d/linkis.conf"),"listen port value started by nginx, save it and restart it"),(0,a.kt)("li",{parentName:"ul"},"If interface 502 appears in the access management console, or ",(0,a.kt)("inlineCode",{parentName:"li"},"Unexpected token < in JSON at position 0")," is abnormal, please confirm whether linkis-mg-gateway starts normally. If it starts normally, check the linkis-mg-gateway configured in the nginx configuration file Is the service address correct?"))),(0,a.kt)("h3",{id:"44-login-to-the-console"},"4.4 Login to the console"),(0,a.kt)("p",null,"Browser login ",(0,a.kt)("inlineCode",{parentName:"p"},"http://xx.xx.xx.xx:8188/#/login"),"\nUsername/password can be found in ",(0,a.kt)("inlineCode",{parentName:"p"},"{LINKIS_HOME}/conf/linkis-mg-gateway.properties")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"wds.linkis.admin.user= #User\nwds.linkis.admin.password= #Password\n\n")),(0,a.kt)("p",null,"Refer to the ",(0,a.kt)("a",{parentName:"p",href:"/docs/1.1.2/user-guide/console-manual"},"User Manual")," for the usage guide of the console"),(0,a.kt)("h2",{id:"5-verify-basic-functionality"},"5. Verify basic functionality"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Verify the corresponding engine tasks according to actual needs")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},'#The version number of the engineType of the engine must match the actual version. The following example is the default version number\n#shell engine tasks\nsh bin/linkis-cli -submitUser hadoop -engineType shell-1 -codeType shell -code "whoami"\n\n#hive engine tasks\nsh bin/linkis-cli -submitUser hadoop -engineType hive-2.3.3 -codeType hql -code "show tables"\n\n#spark engine tasks\nsh bin/linkis-cli -submitUser hadoop -engineType spark-2.4.3 -codeType sql -code "show tables"\n\n#python engine task\nsh bin/linkis-cli -submitUser hadoop -engineType python-python2 -codeType python -code \'print("hello, world!")\'\n')),(0,a.kt)("p",null,"If the verification fails, please refer to ","[Step 8]"," for troubleshooting"),(0,a.kt)("h2",{id:"6-installation-of-development-tool-ide-scriptis-optional"},"6 Installation of development tool IDE (Scriptis) (optional)"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"After installing the Scripti tool, it can support writing SQL, Pyspark, HiveQL and other scripts online on the web page")),(0,a.kt)("p",null,"For detailed instructions, see ",(0,a.kt)("a",{parentName:"p",href:"./linkis-scriptis-install"},"Installation and Deployment of Tool Scriptis")),(0,a.kt)("h2",{id:"7-supported-engines"},"7. Supported Engines"),(0,a.kt)("h3",{id:"71-engine-adaptation-list"},"7.1 Engine Adaptation List"),(0,a.kt)("p",null,"Please note: The separate installation package of Linkis only contains four engines by default: Python/Shell/Hive/Spark. If there are other engines (such as jdbc/flink/sqoop and other engines) usage scenarios, you can install them manually. For details, please refer to ",(0,a.kt)("a",{parentName:"p",href:"engine-conn-plugin-installation"}," EngineConnPlugin Engine Plugin Installation Documentation"),"."),(0,a.kt)("p",null,"The list of supported engines that have been adapted in this version is as follows:"),(0,a.kt)("table",null,(0,a.kt)("thead",{parentName:"table"},(0,a.kt)("tr",{parentName:"thead"},(0,a.kt)("th",{parentName:"tr",align:null},"Engine type"),(0,a.kt)("th",{parentName:"tr",align:null},"Adaptation"),(0,a.kt)("th",{parentName:"tr",align:null},"Does the official installation package contain"))),(0,a.kt)("tbody",{parentName:"table"},(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},"Python"),(0,a.kt)("td",{parentName:"tr",align:null},">=1.0.0 Adapted"),(0,a.kt)("td",{parentName:"tr",align:null},"Included")),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},"Shell"),(0,a.kt)("td",{parentName:"tr",align:null},">=1.0.0 Adapted"),(0,a.kt)("td",{parentName:"tr",align:null},"Included")),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},"Hive"),(0,a.kt)("td",{parentName:"tr",align:null},">=1.0.0 Adapted"),(0,a.kt)("td",{parentName:"tr",align:null},"Included")),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},"Spark"),(0,a.kt)("td",{parentName:"tr",align:null},">=1.0.0 Adapted"),(0,a.kt)("td",{parentName:"tr",align:null},"Included")),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},"Pipeline"),(0,a.kt)("td",{parentName:"tr",align:null},">=1.0.0 Adapted"),(0,a.kt)("td",{parentName:"tr",align:null},(0,a.kt)("strong",{parentName:"td"},"Excludes"))),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},"JDBC"),(0,a.kt)("td",{parentName:"tr",align:null},">=1.0.0 Adapted"),(0,a.kt)("td",{parentName:"tr",align:null},(0,a.kt)("strong",{parentName:"td"},"Excludes"))),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},"Flink"),(0,a.kt)("td",{parentName:"tr",align:null},">=1.0.0 already adapted"),(0,a.kt)("td",{parentName:"tr",align:null},(0,a.kt)("strong",{parentName:"td"},"Not included"))),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},"OpenLooKeng"),(0,a.kt)("td",{parentName:"tr",align:null},">=1.1.1 has been adapted"),(0,a.kt)("td",{parentName:"tr",align:null},(0,a.kt)("strong",{parentName:"td"},"Not included"))),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},"Sqoop"),(0,a.kt)("td",{parentName:"tr",align:null},">=1.1.2 Adapted"),(0,a.kt)("td",{parentName:"tr",align:null},(0,a.kt)("strong",{parentName:"td"},"Excludes"))))),(0,a.kt)("h3",{id:"72-view-the-deployed-engine"},"7.2 View the deployed engine"),(0,a.kt)("h4",{id:"method-1-view-the-engine-lib-package-directory"},"Method 1: View the engine lib package directory"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"$ tree linkis-package/lib/linkis-engineconn-plugins/ -L 3\nlinkis-package/lib/linkis-engineconn-plugins/\n\u251c\u2500\u2500 hive\n\u2502 \u251c\u2500\u2500 dist\n\u2502 \u2502 \u2514\u2500\u2500 v2.3.3 #version is 2.3.3 engineType is hive-2.3.3\n\u2502 \u2514\u2500\u2500 plugin\n\u2502 \u2514\u2500\u2500 2.3.3\n\u251c\u2500\u2500 python\n\u2502 \u251c\u2500\u2500 dist\n\u2502 \u2502 \u2514\u2500\u2500 vpython2\n\u2502 \u2514\u2500\u2500 plugin\n\u2502 \u2514\u2500\u2500 python2 #version is python2 engineType is python-python2\n\u251c\u2500\u2500 shell\n\u2502 \u251c\u2500\u2500 dist\n\u2502 \u2502 \u2514\u2500\u2500 v1\n\u2502 \u2514\u2500\u2500 plugin\n\u2502 \u2514\u2500\u2500 1\n\u2514\u2500\u2500 spark\n    \u251c\u2500\u2500 dist\n    \u2502 \u2514\u2500\u2500 v2.4.3\n    \u2514\u2500\u2500 plugin\n        \u2514\u2500\u2500 2.4.3\n")),(0,a.kt)("h4",{id:"method-2-view-the-database-table-of-linkis"},"Method 2: View the database table of linkis"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"select * from linkis_cg_engine_conn_plugin_bml_resources\n")),(0,a.kt)("h2",{id:"8-troubleshooting-guidelines-for-common-abnormal-problems"},"8. Troubleshooting Guidelines for Common Abnormal Problems"),(0,a.kt)("h3",{id:"81-yarn-queue-check"},"8.1. Yarn Queue Check"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"If you need to use spark/hive/flink engine")),(0,a.kt)("p",null,"After logging in, check whether the yarn queue resources can be displayed normally (click the button in the lower right corner of the page) (the front end needs to be installed first)\nNormally as shown below:\n",(0,a.kt)("img",{parentName:"p",src:"https://user-images.githubusercontent.com/7869972/159955494-2f305a38-a3d6-4798-83aa-58cde23bc436.png",alt:"yarn-normal"})),(0,a.kt)("p",null,"If it cannot be displayed: You can adjust it according to the following guidelines"),(0,a.kt)("h4",{id:"811-check-whether-the-yarn-address-is-configured-correctly"},"8.1.1 Check whether the yarn address is configured correctly"),(0,a.kt)("p",null,"Database table ",(0,a.kt)("inlineCode",{parentName:"p"},"linkis_cg_rm_external_resource_provider")," `\nInsert yarn data information"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-sql"},'INSERT INTO `linkis_cg_rm_external_resource_provider`\n(`resource_type`, `name`, `labels`, `config`) VALUES\n(\'Yarn\', \'sit\', NULL,\n\'{\\r\\n"rmWebAddress": "http://xx.xx.xx.xx:8088",\\r\\n"hadoopVersion": "2.7.2",\\r\\n"authorEnable":false, \\r\\n"user":"hadoop",\\r\\n"pwd":"123456"\\r\\n}\'\n);\n\nconfig field properties\n\n"rmWebAddress": "http://xx.xx.xx.xx:8088", #need to bring http and port\n"hadoopVersion": "2.7.2",\n"authorEnable":true, //Whether authentication is required You can verify the username and password by visiting http://xx.xx.xx.xx:8088 in the browser\n"user":"user",//username\n"pwd":"pwd"//Password\n\n')),(0,a.kt)("p",null,"After the update, because the cache is used in the program, if you want to take effect immediately, you need to restart the linkis-cg-linkismanager service"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"sh sbin/linkis-daemon.sh restart cg-linkismanager\n")),(0,a.kt)("h4",{id:"812-check-whether-the-yarn-queue-exists"},"8.1.2 Check whether the yarn queue exists"),(0,a.kt)("p",null,"Exception information: ",(0,a.kt)("inlineCode",{parentName:"p"},"desc: queue ide is not exists in YARN.")," indicates that the configured yarn queue does not exist and needs to be adjusted"),(0,a.kt)("p",null,"Modification method: ",(0,a.kt)("inlineCode",{parentName:"p"},"linkis management console/parameter configuration> global settings>yarn queue name [wds.linkis.rm.yarnqueue]"),", modify a yarn queue that can be used, and the yarn queue to be used can be found at ",(0,a.kt)("inlineCode",{parentName:"p"},"rmWebAddress:http:// xx.xx.xx.xx:8088/cluster/scheduler")),(0,a.kt)("p",null,"View available yarn queues"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"View yarn queue address: http://ip:8888/cluster/scheduler")),(0,a.kt)("h3",{id:"82-check-whether-the-engine-material-resource-is-uploaded-successfully"},"8.2 Check whether the engine material resource is uploaded successfully"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-sql"},"#Login to the linkis database\nselect * from linkis_cg_engine_conn_plugin_bml_resources\n")),(0,a.kt)("p",null,"The normal is as follows:\n",(0,a.kt)("img",{parentName:"p",src:"https://user-images.githubusercontent.com/29391030/156343249-9f6dca8f-4e0d-438b-995f-4f469270a22d.png",alt:"bml"})),(0,a.kt)("p",null,"Check whether the material record of the engine exists (if there is an update, check whether the update time is correct)."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"If it does not exist or is not updated, first try to manually refresh the material resource (for details, see ","[Engine Material Resource Refresh]","(engine-conn-plugin-installation#23-Engine Refresh))."),(0,a.kt)("li",{parentName:"ul"},"Check the specific reasons for material failure through ",(0,a.kt)("inlineCode",{parentName:"li"},"log/linkis-cg-engineplugin.log")," log. In many cases, it may be caused by the lack of permissions in the hdfs directory"),(0,a.kt)("li",{parentName:"ul"},"Check whether the gateway address configuration is correct. The configuration item ",(0,a.kt)("inlineCode",{parentName:"li"},"wds.linkis.gateway.url")," of ",(0,a.kt)("inlineCode",{parentName:"li"},"conf/linkis.properties"))),(0,a.kt)("p",null,"The material resources of the engine are uploaded to the hdfs directory by default as ",(0,a.kt)("inlineCode",{parentName:"p"},"/apps-data/${deployUser}/bml")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"hdfs dfs -ls /apps-data/hadoop/bml\n#If there is no such directory, please manually create the directory and grant ${deployUser} read and write permissions\nhdfs dfs -mkdir /apps-data\nhdfs dfs -chown hadoop:hadoop/apps-data\n")),(0,a.kt)("h3",{id:"83-login-password-problem"},"8.3 Login password problem"),(0,a.kt)("p",null,"By default, linkis uses a static user and password. The static user is the deployment user. The static password will randomly generate a password string during deployment and store it in\n",(0,a.kt)("inlineCode",{parentName:"p"},"{LINKIS_HOME}/conf/linkis-mg-gateway.properties")," (>=1.0.3 version)"),(0,a.kt)("h3",{id:"84-version-compatibility-issues"},"8.4 version compatibility issues"),(0,a.kt)("p",null,"The engine supported by linkis by default, the compatibility with dss can be viewed ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/apache/incubator-linkis/blob/master/README.md"},"this document")),(0,a.kt)("h3",{id:"85-how-to-locate-the-server-exception-log"},"8.5 How to locate the server exception log"),(0,a.kt)("p",null,"Linkis has many microservices. If you are unfamiliar with the system, sometimes you cannot locate the specific module that has an exception. You can search through the global log."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"tail -f log/* |grep -5n exception (or tail -f log/* |grep -5n ERROR)\nless log/* |grep -5n exception (or less log/* |grep -5n ERROR)\n")),(0,a.kt)("h3",{id:"86-exception-troubleshooting-of-execution-engine-tasks"},"8.6 Exception troubleshooting of execution engine tasks"),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"}," step1: Find the startup deployment directory of the engine ")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Method 1: If it is displayed in the execution log, you can view it on the management console as shown below:\n",(0,a.kt)("img",{parentName:"li",src:"https://user-images.githubusercontent.com/29391030/156343802-9d47fa98-dc70-4206-b07f-df439b291028.png",alt:"engine-log"})),(0,a.kt)("li",{parentName:"ul"},"Method 2: If it is not found in method 1, you can find the parameter ",(0,a.kt)("inlineCode",{parentName:"li"},"wds.linkis.engineconn.root.dir")," configured in ",(0,a.kt)("inlineCode",{parentName:"li"},"conf/linkis-cg-engineconnmanager.properties"),", which is the directory where the engine is started and deployed. Subdirectories are segregated by the user executing the engine")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"# If you don't know the taskid, you can select it after sorting by time ll -rt /appcom/tmp/${executed user}/${date}/${engine}/\ncd /appcom/tmp/${executed user}/${date}/${engine}/${taskId}\n")),(0,a.kt)("p",null,"The directory is roughly as follows"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"conf -> /appcom/tmp/engineConnPublickDir/6a09d5fb-81dd-41af-a58b-9cb5d5d81b5a/v000002/conf #engine configuration file\nengineConnExec.sh #Generated engine startup script\nlib -> /appcom/tmp/engineConnPublickDir/45bf0e6b-0fa5-47da-9532-c2a9f3ec764d/v000003/lib #Engine dependent packages\nlogs #Engine startup and execution related logs\n")),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"}," step2: View the log of the engine ")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"less logs/stdout\n")),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"step3: try to execute the script manually (if needed)"),"\nDebugging can be done by trying to execute the script manually"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"sh -x engineConnExec.sh\n")),(0,a.kt)("h3",{id:"87-how-to-modify-the-port-of-the-registry-eureka"},"8.7 How to modify the port of the registry eureka"),(0,a.kt)("p",null,"Sometimes when the eureka port is occupied by other services and the default eureka port cannot be used, the eureka port needs to be modified. Here, the modification of the eureka port is divided into two situations: before the installation is performed and after the installation is performed."),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Modify the eureka port of the registry before performing the installation")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"1. Enter the decompression directory of apache-linkis-x.x.x-incubating-bin.tar.gz\n2. Execute vi deploy-config/linkis-env.sh\n3. Modify EUREKA_PORT=20303 to EUREKA_PORT=port number\n")),(0,a.kt)("ol",{start:2},(0,a.kt)("li",{parentName:"ol"},"Modify the eureka port of the registry after the installation is performed")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"1. Go to the ${LINKIS_HOME}/conf directory\n\n2. Execute grep -r 20303 ./* , the query result is as follows:\n      ./application-eureka.yml: port: 20303\n      ./application-eureka.yml: defaultZone: http://ip:20303/eureka/\n      ./application-linkis.yml: defaultZone: http://ip:20303/eureka/\n      ./linkis-env.sh:EUREKA_PORT=20303\n      ./linkis.properties:wds.linkis.eureka.defaultZone=http://ip:20303/eureka/\n\n3. Change the port in the corresponding location to the new port, and restart all services sh restart sbin/linkis-start-all.sh\n")),(0,a.kt)("h3",{id:"88-notes-on-cdh-adaptation-version"},"8.8 Notes on CDH adaptation version"),(0,a.kt)("p",null,"CDH itself is not the official standard hive/spark package used. When adapting, it is best to modify the hive/spark version dependencies in the source code of linkis to recompile and deploy.\nFor details, please refer to the CDH adaptation blog post\n",(0,a.kt)("a",{parentName:"p",href:"https://mp.weixin.qq.com/s/__QxC1NoLQFwme1yljy-Nw"},"[Linkis1.0 - Installation and Stepping in the CDH5 Environment]"),"\n",(0,a.kt)("a",{parentName:"p",href:"https://mp.weixin.qq.com/s/9Pl9P0hizDWbbTBf1yzGJA"},"[DSS1.0.0+Linkis1.0.2\u2014\u2014Trial record in CDH5 environment]"),"\n",(0,a.kt)("a",{parentName:"p",href:"https://mp.weixin.qq.com/s/vcFge4BNiEuW-7OC3P-yaw"},"[DSS1.0.0 and Linkis1.0.2\u2014\u2014Summary of JDBC engine related issues]"),"\n",(0,a.kt)("a",{parentName:"p",href:"https://mp.weixin.qq.com/s/VxZ16IPMd1CvcrvHFuU4RQ"},"[DSS1.0.0 and Linkis1.0.2\u2014\u2014Summary of Flink engine related issues]")),(0,a.kt)("h3",{id:"89-debugging-of-http-interface"},"8.9 Debugging of Http interface"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Method 1 can enable ","[Login-Free Mode Guide]"," (/docs/latest/api/login-api/#2 Login-Free Configuration)"),(0,a.kt)("li",{parentName:"ul"},"In method 2 postman, the request header brings the cookie value of the successful login\nThe cookie value can be obtained after successful login on the browser side\n",(0,a.kt)("img",{parentName:"li",src:"https://user-images.githubusercontent.com/7869972/157619718-3afb480f-6087-4d5c-9a77-5e75c8cb4a3c.png",alt:"bml"}))),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"Cookie: bdp-user-ticket-id=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Method 3 Add a static Token to the http request header\nToken is configured in conf/token.properties\nSuch as: TEST-AUTH=hadoop,root,user01")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"Token-Code: TEST-AUTH\nToken-User:hadoop\n")),(0,a.kt)("h3",{id:"810-troubleshooting-process-for-abnormal-problems"},"8.10 Troubleshooting process for abnormal problems"),(0,a.kt)("p",null,"First, follow the above steps to check whether the service/environment, etc. are all started normally\nTroubleshoot basic problems according to some of the scenarios listed above\n",(0,a.kt)("a",{parentName:"p",href:"https://docs.qq.com/doc/DSGZhdnpMV3lTUUxq"},"QA documentation")," Find out if there is a solution, link: ",(0,a.kt)("a",{parentName:"p",href:"https://docs.qq.com/doc/DSGZhdnpMV3lTUUxq"},"https://docs.qq.com/doc/DSGZhdnpMV3lTUUxq"),"\nSee if you can find a solution by searching the content in the issue\n",(0,a.kt)("img",{parentName:"p",src:"https://user-images.githubusercontent.com/29391030/156343419-81cc25e0-aa94-4c06-871c-bb036eb6d4ff.png",alt:"issues"}),'\nThrough the official website document search, for some problems, you can search for keywords through the official website, such as searching for "deployment". (If 404 appears, please refresh your browser)\n',(0,a.kt)("img",{parentName:"p",src:"https://user-images.githubusercontent.com/29391030/156343459-7911bd05-4d8d-4a7b-b9f8-35c152d52c41.png",alt:"search"})),(0,a.kt)("h2",{id:"9-how-to-obtain-relevant-information"},"9. How to obtain relevant information"),(0,a.kt)("p",null,"Linkis official website documents are constantly improving, you can view/keyword search related documents on this official website.\nRelated blog post links"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Linkis technical blog collection ",(0,a.kt)("a",{parentName:"li",href:"https://github.com/apache/incubator-linkis/issues/1233"},"https://github.com/apache/incubator-linkis/issues/1233")),(0,a.kt)("li",{parentName:"ul"},"Technical blog post on the official account ",(0,a.kt)("a",{parentName:"li",href:"https://mp.weixin.qq.com/mp/homepage?__biz=MzI4MDkxNzUxMg==&hid=1&sn=088cbf2bbed1c80d003c5865bc92ace8&scene=18"},"https://mp.weixin.qq.com/mp/homepage?__biz=MzI4MDkxNzUxMg==&hid=1&sn=088cbf2bbed1c80d003c5865bc92ace8&scene=18")),(0,a.kt)("li",{parentName:"ul"},"Official website documentation ",(0,a.kt)("a",{parentName:"li",href:"https://linkis.apache.org/docs/latest/introduction"},"https://linkis.apache.org/docs/latest/introduction")),(0,a.kt)("li",{parentName:"ul"},"bili technology sharing video ",(0,a.kt)("a",{parentName:"li",href:"https://space.bilibili.com/598542776?spm_id_from=333.788.b_765f7570696e666f.2"},"https://space.bilibili.com/598542776?spm_id_from=333.788.b_765f7570696e666f.2"))))}c.isMDXComponent=!0},76962:(e,t,n)=>{n.d(t,{Z:()=>i});const i=n.p+"assets/images/Linkis1.0_combined_eureka-3d096175871c82b66a0a8baedfed2987.png"}}]);