<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-faq docs-doc-id-main">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.2.0">
<title data-rh="true">FAQ | Apache Linkis</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://linkis.apache.org/faq/main"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-faq-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-faq-current"><meta data-rh="true" property="og:title" content="FAQ | Apache Linkis"><meta data-rh="true" name="description" content="Linkis1.0 common problems and solutions//docs.qq.com/doc/DWlN4emlJeEJxWlR0"><meta data-rh="true" property="og:description" content="Linkis1.0 common problems and solutions//docs.qq.com/doc/DWlN4emlJeEJxWlR0"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://linkis.apache.org/faq/main"><link data-rh="true" rel="alternate" href="https://linkis.apache.org/faq/main" hreflang="en"><link data-rh="true" rel="alternate" href="https://linkis.apache.org/zh-CN/faq/main" hreflang="zh-CN"><link data-rh="true" rel="alternate" href="https://linkis.apache.org/faq/main" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://AE29KQB3IA-dsn.algolia.net" crossorigin="anonymous"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Apache Linkis RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Apache Linkis Atom Feed">
<link rel="alternate" type="application/json" href="/blog/feed.json" title="Apache Linkis JSON Feed">



<link rel="search" type="application/opensearchdescription+xml" title="Apache Linkis" href="/opensearch.xml"><link rel="stylesheet" href="/assets/css/styles.fee819ac.css">
<link rel="preload" href="/assets/js/runtime~main.4d57b696.js" as="script">
<link rel="preload" href="/assets/js/main.6d8daa6a.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.png" alt="Apache Linkis Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/logo.png" alt="Apache Linkis Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Apache Linkis</b></a><a class="navbar__item navbar__link" href="/download/main">Download</a><a class="navbar__item navbar__link" href="/community/how-to-subscribe">Community</a><a class="navbar__item navbar__link" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/team">Team</a><a class="navbar__item navbar__link" href="/user">Users</a><a href="https://docs.qq.com/doc/DUkdTTGhVSlZ0VXVt" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">FAQ</a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">ASF</a><ul class="dropdown__menu"><li><a href="https://www.apache.org/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Foundation</a></li><li><a href="https://www.apache.org/licenses/" target="_blank" rel="noopener noreferrer" class="dropdown__link">License</a></li><li><a href="https://www.apache.org/events/current-event" target="_blank" rel="noopener noreferrer" class="dropdown__link">Events</a></li><li><a href="https://www.apache.org/security/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Security</a></li><li><a href="https://www.apache.org/foundation/sponsorship.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">Sponsorship</a></li><li><a href="https://privacy.apache.org/policies/privacy-policy-public.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">Privacy</a></li><li><a href="https://www.apache.org/foundation/thanks.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">Thanks</a></li></ul></div></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Doc</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/docs/latest/about/introduction">1.4.0</a></li><li><a class="dropdown__link" href="/docs/1.3.2/about/introduction">1.3.2</a></li><li><a class="dropdown__link" href="/docs/1.5.0/about/introduction">Next(1.5.0)</a></li><li><a class="dropdown__link" href="/versions">All Version</a></li></ul></div><a href="https://github.com/apache/linkis" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub"></a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>English</a><ul class="dropdown__menu"><li><a href="/faq/main" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="en">English</a></li><li><a href="/zh-CN/faq/main" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-CN">简体中文</a></li></ul></div><div class="searchBox_ZlJk"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebar_njMd"><nav class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" href="/faq/main">FAQ</a></li></ul></nav></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_OVgt"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">FAQ</span><meta itemprop="position" content="1"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>FAQ</h1><blockquote><p>Linkis1.0 common problems and solutions: <a href="https://docs.qq.com/doc/DWlN4emlJeEJxWlR0" target="_blank" rel="noopener noreferrer">https://docs.qq.com/doc/DWlN4emlJeEJxWlR0</a></p></blockquote><h1>1. Use problems</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q1-the-ps-cs-service-log-of-linkis-reports-this-error-figservletwebserverapplicationcontext-559">Q1: The ps-cs service log of linkis reports this error: figServletWebServerApplicationContext (559)<a class="hash-link" href="#q1-the-ps-cs-service-log-of-linkis-reports-this-error-figservletwebserverapplicationcontext-559" title="Direct link to heading">​</a></h2><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">[refresh] - Exception encountered during context initi</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">alization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name &#x27;eurekaInstanceLabelClient&#x27;: Invocation of initkaba method failed; nested exception is java.lang.RuntimeException: com.netflix.client.ClientException: Load balancer does not have available server for client: linkis-ps-publicservice</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>A: This is because the publicservice service did not start successfully. It is recommended to manually restart the publicservice sh/sbin/linkis-dameo.sh restart ps-publicservice</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q2-linkis-eureka-debugging-instructions">Q2: Linkis-eureka debugging instructions<a class="hash-link" href="#q2-linkis-eureka-debugging-instructions" title="Direct link to heading">​</a></h2><p>A: If you need to debug the eureka program, you need to do some configuration first, as shown below
application-eureka.yml needs to remove part of the comment configuration, and the normal startup configuration is as follows:
<img loading="lazy" alt="1639466558031" src="/assets/images/q2_1-697a210422acb1835076820356a56df5.png" width="2047" height="914" class="img_ev3q"></p><p><img loading="lazy" alt="1639466558031" src="/assets/images/q2_2-0b84185f007116f30800e4c4f5639004.png" width="1028" height="1079" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q3-eureka-automatically-stops-when-it-starts-for-the-first-time-and-needs-to-be-restarted-manually">Q3: eureka automatically stops when it starts for the first time, and needs to be restarted manually<a class="hash-link" href="#q3-eureka-automatically-stops-when-it-starts-for-the-first-time-and-needs-to-be-restarted-manually" title="Direct link to heading">​</a></h2><p>A: This is because eureka does not use nohup when starting the Java process. After the session exits, the task is automatically cleaned up by the operating system. You need to modify the eureka startup script and add nohup:</p><p><img loading="lazy" src="/assets/images/q3_1-d1ab012f4d757efb95241370f4e2e3e1.png" width="1042" height="83" class="img_ev3q"></p><p>You can refer to PR: <a href="https://github.com/apache/linkis/pull/837/files" target="_blank" rel="noopener noreferrer">https://github.com/apache/linkis/pull/837/files</a></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q4-linkis-entrance-logwriter-missing-dependencies">Q4: Linkis Entrance LogWriter missing dependencies<a class="hash-link" href="#q4-linkis-entrance-logwriter-missing-dependencies" title="Direct link to heading">​</a></h2><p>A: Hadoop 3 needs to modify the linkis-hadoop-common pom file, see: <a href="https://linkis.apache.org/zh-CN/docs/next/development/linkis-compile-and-package/" target="_blank" rel="noopener noreferrer">https://linkis.apache.org/zh-CN/docs/next/development/linkis-compile-and-package/</a></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q5-when-linkis10-executes-tasks-the-ecp-service-throws-the-following-error-caused-by-javautilnosuchelementexception-noneget">Q5: When Linkis1.0 executes tasks, the ECP service throws the following error: Caused by: java.util.NoSuchElementException: None.get?<a class="hash-link" href="#q5-when-linkis10-executes-tasks-the-ecp-service-throws-the-following-error-caused-by-javautilnosuchelementexception-noneget" title="Direct link to heading">​</a></h2><p>Error detailed log:</p><p>Solution:
At this time, because the corresponding engine version material does not have a corresponding record in the database table, it may be caused by an error when the ecp service is started. You can restart the ecp service to see if there is an error when uploading the BML. The corresponding table is: linkis_cg_engine_conn_plugin_bml_resources</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q6-linkis1x-general-troubleshooting-method-for-insufficient-resources">Q6: Linkis1.X general troubleshooting method for insufficient resources<a class="hash-link" href="#q6-linkis1x-general-troubleshooting-method-for-insufficient-resources" title="Direct link to heading">​</a></h2><p>Insufficient resources fall into two situations:</p><ol><li>Insufficient resources of the server itself</li><li>The user&#x27;s own resources are insufficient (linkis will control user resources).
These two resources are recorded in linkis_cg_manager_label_resource and linkis_cg_manager_linkis_resource in linkis1.X, the former is the association table of label and resource, and the latter is the resource table
Normally, linkis1.0 is safe for high concurrency control of resources, and it is not recommended to forcibly reset user resource records by modifying table records. However, due to the difference in the execution environment of linkis during the installation and debugging process, engine startup failures may occur, or repeated restarts of microservices during the engine startup process lead to unsafe release of resources, or the monitor does not have time to automatically clean up (some hours) level delay), there may be a problem of insufficient resources, and in severe cases, most of the user&#x27;s resources will be locked. Therefore, you can refer to the following steps to troubleshoot insufficient resources:
a. Confirm on the management console whether the remaining resources of the ECM are greater than the requested resources of the engine. If the remaining resources of the ECM are very small, it will cause the request for a new engine to fail. You need to manually turn off some idle engines in the ECM. There is also a mechanism for automatic release when idle, but this time is set relatively long by default.
b. If the ECM resources are sufficient, it must be that the remaining resources of the user are not enough to request a new engine. First, determine the label generated when the user executes the task. For example, if the user hadoop executes the spark2.4.3 script on Scriptis, it will be corresponding in the linkis_cg_manager_label table next record
We get the id value of this label, find the corresponding resourceId in the association table linkis_cg_manager_label_resource, and find the corresponding resource record of the label in linkis_cg_manager_linkis_resource through resourceId, you can check the remaining resources in this record</li></ol><p>If this resource is checked and determined to be abnormal, that is, it does not match the resources generated by the actual engine startup. The following operations can be performed to recover:
After confirming that all engines under the label have been shut down, you can directly delete this resource and the associated record corresponding to the association table linkis_cg_manager_label_resource, and this resource will be automatically reset when you request again.
Note: All engines of this label have been shut down. In the previous example, it means that the spark2.4.3 engines started by the hadoop user on Scriptis have all been shut down. You can see all the engines started by the user in the resource management of the management console. instance. Otherwise, the resource record exception of the label may also occur.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q7-linkis-startup-error-nosuchmethoderrorgetsessionmanagerlorgeclipsejettyserversessionmanager">Q7: linkis startup error: NoSuchMethodErrorgetSessionManager()Lorg/eclipse/jetty/server/SessionManager<a class="hash-link" href="#q7-linkis-startup-error-nosuchmethoderrorgetsessionmanagerlorgeclipsejettyserversessionmanager" title="Direct link to heading">​</a></h2><p>Specific stack:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">startup of context o.s.b.w.e.j.JettyEmbeddedWebAppContext@6c6919ff{application,/,[file:///tmp/jetty-docbase.9102.6375358926927953589/],UNAVAILABLE} java.lang.NoSuchMethodError: org.eclipse.jetty.server.session.SessionHandler.getSessionManager()Lorg/eclipse/jetty/server/SessionManager;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.eclipse.jetty.servlet.ServletContextHandler\$Context.getSessionCookieConfig(ServletContextHandler.java:1415) ~[jetty-servlet-9.3.20.v20170531.jar:9.3.20.v20170531]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Solution: jetty-servlet and jetty-security versions need to be upgraded from 9.3.20 to 9.4.20;</p><h1>2. Environmental issues</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q1-linkis10-execution-task-report-select-list-is-not-in-group-by-clause">Q1: Linkis1.0 execution task report: select list is not in group by clause<a class="hash-link" href="#q1-linkis10-execution-task-report-select-list-is-not-in-group-by-clause" title="Direct link to heading">​</a></h2><p><img loading="lazy" alt="1639466558031" src="/assets/images/q5_1-0ee7a3e215d17b5032fba9039eaf41f9.jpg" width="2560" height="1139" class="img_ev3q"></p><p><img loading="lazy" alt="1639466558031" src="/assets/images/q5_2-7c44e577054f2a65c49d197babf7a702.png" width="1087" height="444" class="img_ev3q"></p><p>This problem is caused by the default value of the global setting mode in mysql 5.8 version, you need to execute the following line in the mysql cli:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">SET GLOBAL sql_mode=(SELECT REPLACE(@@sql_mode,&#x27;ONLY_FULL_GROUP_BY&#x27;,&#x27;&#x27;));</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q2-when-executing-scripts-after-deployment-executing-commands-and-collecting-results-i-encountered-such-an-error-ioexception-file-header-type-must-be-dolphin">Q2: When executing scripts after deployment, executing commands, and collecting results, I encountered such an error, IOException: File header type must be dolphin:<a class="hash-link" href="#q2-when-executing-scripts-after-deployment-executing-commands-and-collecting-results-i-encountered-such-an-error-ioexception-file-header-type-must-be-dolphin" title="Direct link to heading">​</a></h2><p>A: This should be caused by repeated installations, resulting in the result set being written in the same file. The previous Linkis 0.X version used the result set to write append, and 1.0 has been modified to add a new one. You can clean up the result set Directory: The configuration parameter is wds.linkis.resultSet.store.path, you can clean up this directory</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q3-the-json4s-package-conflict-caused-by-inconsistent-spark-versions-the-error-is-as-follows-error-message-caused-by-javalangnosuchmethoderror-orgjson4sjacksonjsonmethod">Q3: The json4s package conflict caused by inconsistent Spark versions, the error is as follows: Error message: caused by: java.lang.NoSuchMethodError: org.json4s.jackson.jsonMethod$<a class="hash-link" href="#q3-the-json4s-package-conflict-caused-by-inconsistent-spark-versions-the-error-is-as-follows-error-message-caused-by-javalangnosuchmethoderror-orgjson4sjacksonjsonmethod" title="Direct link to heading">​</a></h2><p>solution:
This is because of Spark jars&#x27; json4s and lib/linkis-engineplugins/spark/dist/version/lib
The json4s version in the package is inconsistent. When the official release is released, the supported version of Spark will be indicated later. If it is inconsistent, this problem will exist.
The solution is to replace the json4s package in Spark jars with lib/linkis-engineplugins/spark/dist/version/lib
The json4s version inside the package. In addition, there may be conflicts in the netty package, which can be handled according to the method of Json4s. Then restart the ecp service: sh sbin/linkis-damon.sh restart cg-engineplugin</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q4-when-linkis1x-submits-spark-sql-tasks-in-version-cdh5161-how-to-troubleshoot-404-problems">Q4: When Linkis1.X submits spark sql tasks in version CDH5.16.1, how to troubleshoot 404 problems<a class="hash-link" href="#q4-when-linkis1x-submits-spark-sql-tasks-in-version-cdh5161-how-to-troubleshoot-404-problems" title="Direct link to heading">​</a></h2><p>The main error message is as follows:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">21304, Task is Failed,errorMsg: errCode: 12003 ,desc: ip:port_x Failed to async get EngineNode FeignException.NotFound: status 404 reading RPCReceiveRemote#receiveAndReply(Message) ,ip: xxxxx ,port: 9104 ,serviceKind: linkis-cg-entrance</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">org.apache.jasper.servlet.JspServlet 89 warn - PWC6117: File &quot;/home/hadoop/dss1.0/tmp/hadoop/workDir/7c3b796f-aadd-46a5-b515-0779e523561a/tmp/jetty-docbase.1802511762054502345.46019/api/rest_j/v1/rpc/receiveAndReply&quot; not found</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>The above error message is mainly caused by the jar conflict in the cdh environment variable. You need to find the jar package where the org.apache.jasper.servlet.JspServlet class is located. The local cdh environment variable path is: /opt/cloudera/parcels/CDH -5.16.1-1.cdh5.16.1.p0.3/jars, delete the corresponding jasper-compile-${version}.jar and jsp-${version}.jar jar packages under this directory, The spark sql task can be run again without restarting the service, and the problem is solved.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q5-running-error-report-missing-package-matplotlib">Q5: running error report missing package matplotlib<a class="hash-link" href="#q5-running-error-report-missing-package-matplotlib" title="Direct link to heading">​</a></h2><p>In the standard python environment, anaconda2 and anaconda3 need to be installed, and the default anaconda is anaconda2. This contains most common python libraries.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q6-when-the-microservice-linkis-ps-cs-is-started-debuggclasswriter-overrides-final-method-visit-is-reported">Q6: When the microservice linkis-ps-cs is started, DebuggClassWriter overrides final method visit is reported<a class="hash-link" href="#q6-when-the-microservice-linkis-ps-cs-is-started-debuggclasswriter-overrides-final-method-visit-is-reported" title="Direct link to heading">​</a></h2><p>Specific exception stack:</p><p>Solution: jar package conflict, delete asm-5.0.4.jar;</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q7-when-the-shell-engine-schedules-execution-the-engine-execution-directory-reports-the-following-error-binjava-no-such-file-or-directory">Q7: When the shell engine schedules execution, the engine execution directory reports the following error /bin/java: No such file or directory:<a class="hash-link" href="#q7-when-the-shell-engine-schedules-execution-the-engine-execution-directory-reports-the-following-error-binjava-no-such-file-or-directory" title="Direct link to heading">​</a></h2><p><img loading="lazy" src="/assets/images/q24_1-ba0715c637d27f81c926e66cc6858102.png" width="746" height="173" class="img_ev3q"></p><p>Solution: There is a problem with the environment variables of the local java, and a symbolic link needs to be made to the java command.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q8-when-the-hive-engine-is-scheduled-the-error-log-of-engineconnmanager-is-as-follows-method-did-not-exist-sessionhandler">Q8: When the hive engine is scheduled, the error log of engineConnManager is as follows: method did not exist: SessionHandler:<a class="hash-link" href="#q8-when-the-hive-engine-is-scheduled-the-error-log-of-engineconnmanager-is-as-follows-method-did-not-exist-sessionhandler" title="Direct link to heading">​</a></h2><p><img loading="lazy" src="/assets/images/q27_1-9604d3aee4192bf09b279225c011357b.png" width="2864" height="1626" class="img_ev3q"></p><p>Solution: Under the hive engine lib, the jetty jar package conflicts, replace jetty-security and jetty-server with 9.4.20;</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q9-when-the-hive-engine-is-executing-the-following-error-is-reported-lcomgooglecommoncollectunmodifiableiterator">Q9: When the hive engine is executing, the following error is reported Lcom/google/common/collect/UnmodifiableIterator:<a class="hash-link" href="#q9-when-the-hive-engine-is-executing-the-following-error-is-reported-lcomgooglecommoncollectunmodifiableiterator" title="Direct link to heading">​</a></h2><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">2021-03-16 13:32:23.304 ERROR [pool-2-thread-1]com.webank.wedatasphere.linkis.engineplugin.hive.executor.HiveEngineConnExecutor 140 run - query failed, reason : java.lang.AccessError: tried to access method com.google.common.collect.Iterators.emptyIterator() Lcom/google/common/collect/UnmodifiableIterator; from class org.apache.hadoop.hive.ql.exec.FetchOperator </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.hadoop.hive.ql.exec.FetchOperator.&lt;init&gt;(FetchOperator.java:108) ~[hive-exec-2.1.1-cdh6.1.0.jar:2.1.1-cdh6.1.0]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.hadoop.hive.ql.exec.FetchTask.initialize(FetchTask.java:86) ~[hive-exec-2.1.1-cdh6.1.0.jar:2.1.1-cdh6.1.0]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.hadoop.hive.ql..compile(Driver.java:629) ~[hive-exec-2.1.1-cdh6.1.0.jar:2.1.1-cdh6.1.0]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1414) ~[hive-exec-2.1.1-cdh6.1.0.jar:2.1.1-cdh6.1.0]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1543) ~[hive-exec-2.1.1-cdh6.1.0.jar:2.1.1-cdh6.1.0]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1332) ~[hive-exec-2.1.1-cdh6.1.0.jar:2.1.1-cdh6.1.0]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1321) ~[hive-exec-2.1.1-cdh6.1.0.jar:2.1.1-cdh6.1.0]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">atcom.webank.wedatasphere.linkis.engineplugin.hive.executor.HiveEngineConnExecutor$$anon$1.run(HiveEngineConnExecutor.scala:152) [linkis-engineplugin-hive-dev-1.0.0.jar:?]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">atcom.webank.wedatasphere.linkis.engineplugin.hive.executor.HiveEngineConnExecutor$$anon$1.run(HiveEngineConnExecutor.scala:126) [linkis-engineplugin-hive-dev-1.0.0.jar:?]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Solution: guava package conflict, delete guava-25.1-jre.jar under hive/dist/v1.2.1/lib;</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q10-during-engine-scheduling-the-following-error-is-reported-python-processes-is-not-alive">Q10: During engine scheduling, the following error is reported: Python processes is not alive:<a class="hash-link" href="#q10-during-engine-scheduling-the-following-error-is-reported-python-processes-is-not-alive" title="Direct link to heading">​</a></h2><p><img loading="lazy" src="/assets/images/q29_1-1787e33057b87430ad3e23f25c945720.png" width="1761" height="204" class="img_ev3q"></p><p>Solution: Install the anaconda3 package manager on the server. After debugging python, two problems were found: (1) lack of pandas and matplotlib modules, which need to be installed manually; (2) when the new version of the python engine is executed, it depends on a higher version of python, and python3 is installed first. Next, make a symbolic link (as shown below), and restart the engineplugin service.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q11-when-the-spark-engine-is-running-the-following-error-is-reported-noclassdeffounderror-orgapachehadoophiveqlioorcorcfile">Q11: When the spark engine is running, the following error is reported: NoClassDefFoundError: org/apache/hadoop/hive/ql/io/orc/OrcFile:<a class="hash-link" href="#q11-when-the-spark-engine-is-running-the-following-error-is-reported-noclassdeffounderror-orgapachehadoophiveqlioorcorcfile" title="Direct link to heading">​</a></h2><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">2021-03-19 15:12:49.227 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler 57 logInfo -ShuffleMapStage 5 (show at &lt;console&gt;:69) failed in 21.269 s due to Job aborted due to stage failure: Task 1 in stage 5.0 failed 4 times, most recent failure: Lost task 1.3 in stage 5.0 (TID 139, cdh03, executor 6):java.lang.NoClassDefFoundError: org/apache/hadoop/hive/ql/io/orc/OrcFile </span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Solution: The classpath of the cdh6.3.2 cluster spark engine only has /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/spark/jars, you need to add hive-exec-2.1.1- cdh6.1.0.jar, and restart spark.</p><h1>Three, configuration problems</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q1-the-database-on-the-left-side-of-the-script-cannot-be-refreshed">Q1: The database on the left side of the script cannot be refreshed<a class="hash-link" href="#q1-the-database-on-the-left-side-of-the-script-cannot-be-refreshed" title="Direct link to heading">​</a></h2><p>solution:
a. The reason may be that the linkis-metatdata service did not read the HIVE_CONF_DIR error, you can configure the parameters of linkis-metadata: corresponding to the JDBC connection string of the metadata database</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">hive.meta.url=</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">hive.meta.user=</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">hive.meta.password=</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q2-the-right-side-of-scriptis-cannot-refresh-the-database-and-it-has-been-refreshing-it-should-be-noted-that-the-metadata-of-linkis-does-not-support-docking-sentry-and-ranger-for-the-time-being-only-supports-native-permission-control-of-hive-error-message-the-front-end-database-tab-has-been-refreshing-state">Q2: The right side of Scriptis cannot refresh the database, and it has been refreshing (it should be noted that the metadata of linkis does not support docking sentry and Ranger for the time being, only supports native permission control of hive), error message: the front-end database tab has been refreshing state<a class="hash-link" href="#q2-the-right-side-of-scriptis-cannot-refresh-the-database-and-it-has-been-refreshing-it-should-be-noted-that-the-metadata-of-linkis-does-not-support-docking-sentry-and-ranger-for-the-time-being-only-supports-native-permission-control-of-hive-error-message-the-front-end-database-tab-has-been-refreshing-state" title="Direct link to heading">​</a></h2><p>solution:
This is because we have restricted permissions for the database on the right, and this relies on hive to enable authorized access:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">hive.security.authorization.enabled=true; </span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>For details, please refer to: <a href="https://blog.csdn.net/yancychas/article/details/84202400" target="_blank" rel="noopener noreferrer">https://blog.csdn.net/yancychas/article/details/84202400</a>
If you have configured this parameter and have not yet enabled it, you need to grant the user the corresponding database table permission and execute the grant statement. You can refer to the same link authorization section.</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Authorization reference Take hadoop as an example:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Enter the hive client to check the hadoop user database authorization status:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">show grant user hadoop on database default;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Authorize the user database:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">grant all on database default to user hadoop;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>If you don&#x27;t want to enable permission control, that is, every user can see the library table, you can modify: com/webank/wedatasphere/linkis/metadata/hive/dao/impl/HiveMetaDao.xml sql remove the permission control part</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q3-scriptisworkspace-when-i-log-in-to-scriptis-the-root-directory-does-not-exist-and-there-are-two-root-directories-workspace-and-hdfs-error-message-after-logging-in-the-front-end-pops-up-the-following-message-the-users-local-directory-does-not-exist-please-contact-admin-to-add">Q3: <!-- -->[<!-- -->Scriptis]<!-- -->[Workspace]<!-- --> When I log in to Scriptis, the root directory does not exist, and there are two root directories: workspace and HDFS: Error message: After logging in, the front end pops up the following message (the user’s local directory does not exist, please Contact admin to add)<a class="hash-link" href="#q3-scriptisworkspace-when-i-log-in-to-scriptis-the-root-directory-does-not-exist-and-there-are-two-root-directories-workspace-and-hdfs-error-message-after-logging-in-the-front-end-pops-up-the-following-message-the-users-local-directory-does-not-exist-please-contact-admin-to-add" title="Direct link to heading">​</a></h2><p>solution:</p><ul><li>a. Confirm the linkis.properties parameter in the conf directory of linkis-ps-publicservice: wds.linkis.workspace.filesystem.localuserrootpath=file:///tmp/linkis/ Does it start with file://?</li><li>b. Confirm whether wds.linkis.workspace.filesystem.hdfsuserrootpath.prefix=hdfs:///tmp/linkis/ starts with hdfs://</li><li>c. Confirm whether there is a user directory under the /tmp/linkis directory. The user here refers to the front-end login user, such as hadoop user login, then create: /tmp/linkis/hadoop directory, if the directory exists, confirm the directory permission login user It can be operated. If it still doesn’t work, you can refer to the error report of publicservice. The error will explain the permission or the path problem.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q4-management-consolesettings-how-to-adjust-the-yarn-queue-used-by-the-task-error-message-when-executing-the-sql-task-it-is-reported-that-1-obtaining-the-yarn-queue-information-is-abnormal-or-user-xx-cannot-submit-to-the-queue">Q4: <!-- -->[<!-- -->Management Console]<!-- -->[Settings]<!-- --> How to adjust the yarn queue used by the task? Error message: When executing the sql task, it is reported that 1. Obtaining the Yarn queue information is abnormal or user XX cannot submit to the queue<a class="hash-link" href="#q4-management-consolesettings-how-to-adjust-the-yarn-queue-used-by-the-task-error-message-when-executing-the-sql-task-it-is-reported-that-1-obtaining-the-yarn-queue-information-is-abnormal-or-user-xx-cannot-submit-to-the-queue" title="Direct link to heading">​</a></h2><p>solution:
In the front end - management console - settings - general settings - Yarn queue configuration login user has permission queue</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q5-when-hive-queries-it-reports-can-not-find-zk-related-classes-such-as-orgapachecurator-error-message-when-executing-hive-tasks-the-log-report-cannot-find-the-class-starting-with-orgapachecurator--classnotfound">Q5: When Hive queries, it reports: Can not find zk-related classes such as: org.apache.curator.<em>, error message: When executing hive tasks, the log report cannot find the class starting with org.apache.curator.</em> , classNotFound<a class="hash-link" href="#q5-when-hive-queries-it-reports-can-not-find-zk-related-classes-such-as-orgapachecurator-error-message-when-executing-hive-tasks-the-log-report-cannot-find-the-class-starting-with-orgapachecurator--classnotfound" title="Direct link to heading">​</a></h2><p>solution:
This is because the hive transaction is enabled, you can modify the hive-site.xml on the linkis machine to turn off the transaction configuration, refer to the hive transaction: <a href="https://www.jianshu.com/p/aa0f0fdd234c" target="_blank" rel="noopener noreferrer">https://www.jianshu.com/p/aa0f0fdd234c</a>
Or put the relevant package into the engine plugin directory lib/linkis-engineplugins/hive/dist/version/lib</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q6-how-does-linkis-support-kerberos">Q6: How does Linkis support kerberos<a class="hash-link" href="#q6-how-does-linkis-support-kerberos" title="Direct link to heading">​</a></h2><p>solution:
Obtaining Hadoop&#x27;s FileSystem in linkis is implemented through the HDFSUtils class, so we put kerberos in this class, and users can see the logic of this class. The login modes currently supported are as follows:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">if(KERBEROS_ENABLE.getValue) {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      val path = new File(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      TAB_FILE.getValue ， userName + &quot;.keytab&quot;).getPath</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      val user = getKerberosUser(userName)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      UserGroupInformation.setConfiguration(getConfiguration(userName))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      UserGroupInformation.loginUserFromKeytabAndReturnUGI(user， path)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    } else {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      UserGroupInformation.createRemoteUser(userName)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Users only need to configure the following parameters in the configuration file linkis.properties:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">wds.linkis.keytab.enable=true</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">wds.linkis.keytab.file=/appcom/keytab/ #keytab placement directory, which stores the username.keytab files of multiple users</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">wds.linkis.keytab.host.enabled=false #Whether to bring principle client authentication</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">wds.linkis.keytab.host=127.0.0.1 #principle authentication needs to bring the client IP</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q7-regarding-linkis-besides-supporting-deployment-user-login-can-other-user-logins-be-configured">Q7: Regarding Linkis, besides supporting deployment user login, can other user logins be configured?<a class="hash-link" href="#q7-regarding-linkis-besides-supporting-deployment-user-login-can-other-user-logins-be-configured" title="Direct link to heading">​</a></h2><p>solution:
sure. Deployment users are for convenience only. linkis-mg-gateway supports access by configuring LDAP service and SSO service. It does not have a user verification system. For example, to enable LDAP service access, you only need to configure linkis-mg-gateway.properties. The configuration of your LDAP server is as follows:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">wds.linkis.ldap.proxy.url=ldap://127.0.0.1:1389/#Your LDAP service URL</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">wds.linkis.ldap.proxy.baseDN=dc=webank，dc=com#Configuration of your LDAP service</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>If the user needs to perform tasks, a user with the corresponding user name needs to be created on the Linux server. If it is a standard version, the user needs to be able to perform Spark and hive tasks, and needs to establish a corresponding user in the local workspace and HDFS directory /tmp/linkis directory.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q8-how-to-open-linkis-management-console-administrator-page-ecm-and-microservice-management">Q8: How to open Linkis management console, administrator page ECM and microservice management?<a class="hash-link" href="#q8-how-to-open-linkis-management-console-administrator-page-ecm-and-microservice-management" title="Direct link to heading">​</a></h2><p><img loading="lazy" src="/assets/images/q15_1-7df6cf4928b02cb4cf2335fabbdaa193.png" width="238" height="336" class="img_ev3q"></p><p>Solution: You need to set the administrator in the conf/linkis.properties file:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">wds.linkis.governance.station.admin=hadoop,peacewong</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>After the setting is complete, restart the publicservice service</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q9-when-starting-the-microservice-linkis-ps-publicservice-kjdbcutilsgetdriverclassname-npe">Q9: When starting the microservice linkis-ps-publicservice, kJdbcUtils.getDriverClassName NPE<a class="hash-link" href="#q9-when-starting-the-microservice-linkis-ps-publicservice-kjdbcutilsgetdriverclassname-npe" title="Direct link to heading">​</a></h2><p>Specific exception stack: ExternalResourceProvider</p><p><img loading="lazy" src="/assets/images/q23_1-9745a8c9c95053318ee900d53cb50771.png" width="1908" height="739" class="img_ev3q"></p><p>Solution: Caused by linkis-ps-publicservice configuration problem, modify the three parameters at the beginning of linkis.properties hive.meta:</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q10-when-scheduling-the-hive-engine-the-following-error-is-reported-engineconnpluginnotfoundexception-errorcode-70063">Q10: When scheduling the hive engine, the following error is reported: EngineConnPluginNotFoundException: errorCode: 70063<a class="hash-link" href="#q10-when-scheduling-the-hive-engine-the-following-error-is-reported-engineconnpluginnotfoundexception-errorcode-70063" title="Direct link to heading">​</a></h2><p><img loading="lazy" src="/assets/images/q25_1-feffb49fb454a8fc0b0fd32dd2fe8c1a.png" width="1001" height="492" class="img_ev3q"></p><p>Solution: The version of the corresponding engine was not modified during installation, so the engine type inserted into the db by default is the default version, and the compiled version is not the default version.</p><p>Specific modification steps:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd /appcom/Install/dss-linkis/linkis/lib/linkis-engineconn-plugins/，</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Modify the v2.1.1 directory name in the dist directory to v1.2.1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Modify the subdirectory name 2.1.1 under the plugin directory to the default version 1.2.1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">If it is Spark, you need to modify dist/2.4.3 and plugin/2.4.3 accordingly</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Finally restart the engineplugin service.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q11-when-the-hive-engine-schedules-execution-the-following-error-is-reported-opertion-failed-nullpointerexception">Q11: When the hive engine schedules execution, the following error is reported: opertion failed NullPointerException:<a class="hash-link" href="#q11-when-the-hive-engine-schedules-execution-the-following-error-is-reported-opertion-failed-nullpointerexception" title="Direct link to heading">​</a></h2><p><img loading="lazy" src="/assets/images/q26_1-3ce3dfd6f40af09fce2c891b647df7d1.png" width="1855" height="577" class="img_ev3q"></p><p>Solution: The server lacks environment variables, and /etc/profile adds <code>export HIVE_CONF_DIR=/etc/hive/conf;</code></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q12-when-the-spark-engine-starts-an-error-is-reported-get-the-queue-information-excepiton-obtaining-yarn-queue-information-exception-and-http-link-exception">Q12: When the spark engine starts, an error is reported get the queue information excepiton. (obtaining Yarn queue information exception) and http link exception<a class="hash-link" href="#q12-when-the-spark-engine-starts-an-error-is-reported-get-the-queue-information-excepiton-obtaining-yarn-queue-information-exception-and-http-link-exception" title="Direct link to heading">​</a></h2><p>Solution: To migrate the address configuration of yarn to the DB configuration, the following configuration needs to be added:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">INSERT INTO `linkis_cg_rm_external_resource_provider` (`resource_type`, `name`, `labels`, `config`) VALUES (&#x27;Yarn&#x27;, &#x27;default&#x27;, NULL, &#x27;{\r\n&quot;rmWebAddress&quot;: &quot;http://xxip:xxport&quot;,\r\n&quot;hadoopVersion&quot;: &quot;2.7.2&quot;,\r\n&quot;authorEnable&quot;:true,\r\n&quot;user&quot;:&quot;hadoop&quot;,\r\n&quot;pwd&quot;:&quot;xxxx&quot;\r\n}&#x27;);</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">config field example</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">{</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">&quot;rmWebAddress&quot;: &quot;http://10.10.10.10:8080&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">&quot;hadoopVersion&quot;: &quot;2.7.2&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">&quot;authorEnable&quot;:true,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">&quot;user&quot;:&quot;hadoop&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">&quot;pwd&quot;:&quot;passwordxxx&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><img loading="lazy" src="/assets/images/q31_1-82ad7f3ad31c7ce507e41fa27f939e2a.png" width="1414" height="435" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q13-pythonspark-scheduling-execution-error-initialize-python-executor-failed-classnotfoundexception-orgslf4jimplstaticloggerbinder">Q13: pythonspark scheduling execution, error: initialize python executor failed ClassNotFoundException org.slf4j.impl.StaticLoggerBinder<a class="hash-link" href="#q13-pythonspark-scheduling-execution-error-initialize-python-executor-failed-classnotfoundexception-orgslf4jimplstaticloggerbinder" title="Direct link to heading">​</a></h2><p>details as follows:</p><p><img loading="lazy" src="/assets/images/q32_2-6771db328f6fedb7edde749b18e26be6.png" width="1912" height="350" class="img_ev3q"></p><p>Solution: The reason is that the spark server lacks slf4j-log4j12-1.7.25.jar, copy the above jar to /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/spark/jars .</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q14-common-package-conflicts">Q14: Common package conflicts:<a class="hash-link" href="#q14-common-package-conflicts" title="Direct link to heading">​</a></h2><ol><li><p>java.lang.NoSuchMethodError: javax.ws.rs.core.Application.getProperties()Ljava/util/Map;
The conflict package is: jsr311-api-1.1.1.jar may also conflict with jessery</p></li><li><p>java.lang.BootstrapMethodError: java.lang.NoSuchMethodError: javax.servlet.ServletContext.setInitParameter(Ljava/lang/String;Ljava/lang/String;)Z</p><p>The conflict package is: servlet-api.jar</p></li><li><p>org/eclipse/jetty/util/processorUtils
The conflicting package is: jetty-util-9.4.11.v20180605.jar This is the correct version</p></li><li><p>java.lang.NoClassDefFoundError: Could not initialize class dispatch.Http$</p><p>The conflicting package needs to be copied in: netty-3.6.2.Final.jar</p></li><li><p>Conflicts caused by other jars brought in by hive-exec Calcite-avatica-1.6.0.jar may also bring conflicts in the jackson package, resulting in errors related to com.fasterxml.jackson.databind
Cannot inherit from final class is caused by calcite-avatica-1.6.0.jar</p></li><li><p>LZO compression problem hadoop-lzo jar
7.org.eclipse.jetty.server.session.SessionHandler.getSessionManager()Lorg/eclipse/jetty/server/SessionManager;
Need to replace conflicting packages: jetty-servlet and jetty-security with 9.4.20</p></li></ol><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q15-the-mysql-script-running-scripts-reports-an-errorsql-engine-reports-an-error">Q15: The Mysql script running Scripts reports an error\sql engine reports an error<a class="hash-link" href="#q15-the-mysql-script-running-scripts-reports-an-errorsql-engine-reports-an-error" title="Direct link to heading">​</a></h2><p>MYSQL script: run sql error:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">com.webank.wedatasphere.linkis.orchestrator.ecm.exception.ECMPluginErrorException: errCode: 12003 ,desc: localhost:9101_0 Failed  to async get EngineNode RMErrorException: errCode: 11006 ,desc: Failed to request external resourceClassCastException: org.json4s.JsonAST$JNothing$ cannot be cast to org.json4s.JsonAST$JString ,ip: localhost ,port: 9101 ,serviceKind: linkis-cg-linkismanager ,ip: localhost ,port: 9104 ,serviceKind: linkis-cg-entrance</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    at com.webank.wedatasphere.linkis.orchestrator.ecm.ComputationEngineConnManager.getEngineNodeAskManager(ComputationEngineConnManager.scala:157) ~[linkis-orchestrator-ecm-plugin-1.0.2.jar:?]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Solution: modify the correct yarn address in the linkis_cg_rm_external_resource_provider table</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q16-the-waiting-time-for-scriptis-to-execute-the-script-is-long">Q16: The waiting time for scriptis to execute the script is long<a class="hash-link" href="#q16-the-waiting-time-for-scriptis-to-execute-the-script-is-long" title="Direct link to heading">​</a></h2><p><img loading="lazy" src="/assets/images/q35_1-c00cc3df2f86dd1c3eee9a152d93bb2a.png" width="1483" height="177" class="img_ev3q"></p><p>scriptis execution script waits for a long time, and reports Failed to async get EngineNode TimeoutException:
Solution: You can check the linkismanager log, usually because the engine startup timed out</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q17-scriptis-executes-jdbc-script-and-reports-an-error">Q17: scriptis executes jdbc script and reports an error<a class="hash-link" href="#q17-scriptis-executes-jdbc-script-and-reports-an-error" title="Direct link to heading">​</a></h2><p>scriptis executes the jdbc script and reports an error</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">Failed  to async get EngineNode ErrorException: errCode: 0 ,desc: operation failed(操作失败)s！the reason(原因)：EngineConnPluginNotFoundException: errCode: 70063 ,desc: No plugin foundjdbc-4please check your configuration </span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Solution
You need to install the corresponding engine plug-in, you can refer to: <a href="/docs/latest/deployment/install-engineconn">Engine Installation Guide</a></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q18-turn-off-resource-checking">Q18: Turn off resource checking<a class="hash-link" href="#q18-turn-off-resource-checking" title="Direct link to heading">​</a></h2><p>Error reporting phenomenon: Insufficient resources
Linkismanager service modify this configuration: wds.linkis.manager.rm.request.enable=false
You can clean up resource records, or set smaller resources
or turn off detection
Linkismanager service modify this configuration: wds.linkis.manager.rm.request.enable=false</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q19-executing-the-script-reports-an-error">Q19: Executing the script reports an error<a class="hash-link" href="#q19-executing-the-script-reports-an-error" title="Direct link to heading">​</a></h2><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">GatewayErrorException: errCode: 11012 ,desc: Cannot find an instance in the routing chain of serviceId [linkis-cg-entrance], please retry ,ip: localhost ,port: 9001 ,serviceKind: linkis-mg-gateway</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><img loading="lazy" src="/assets/images/q39_1-764160ac65a63a31c9cc9e2ea6f36f5c.png" width="1309" height="92" class="img_ev3q"></p><p>A: Please check whether the linkis-cg-entrance service starts normally.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q20-scriptis-execute-script-timeoutexception">Q20: ScriptIs execute script TimeoutException<a class="hash-link" href="#q20-scriptis-execute-script-timeoutexception" title="Direct link to heading">​</a></h2><p><img loading="lazy" src="/assets/images/q41_1-fc7fee9a7949d93925853282d6b34519.png" width="2144" height="1344" class="img_ev3q"></p><p>In linkis-cg-linkismanager.log, Need a ServiceInstance(linkis-cg-entrance, localhost:9104), but cannot find in DiscoveryClient refresh list is repeatedly printed.
This is because the instance is forcibly shut down, but the persistence in the database thinks that the instance still exists. The solution is to clear the two tables linkis_cg_manager_service_instance and linkis_cg_manager_service_instance_metrics after stopping the service.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q21-engine-timeout-setting">Q21: Engine timeout setting<a class="hash-link" href="#q21-engine-timeout-setting" title="Direct link to heading">​</a></h2><p><img loading="lazy" src="/assets/images/q43_1-2eab821fc930ab31beb6990a6c5db7a1.png" width="1852" height="1648" class="img_ev3q"></p><p>① The parameter configuration of the management console can correspond to the engine parameters, and the timeout time can be modified. After saving, kill the existing engine.
②If the timeout configuration is not displayed, you need to manually modify the linkis-engineplugins directory, the corresponding engine plugin directory such as spark/dist/v2.4.3/conf/linkis-engineconn.properties, the default configuration is wds.linkis.engineconn.max.free.time =1h, means 1h overtime, and can have units m and h. 0 means no timeout, no automatic kill. After the change, you need to restart ecp, and kill the existing engine, and run a new task to start the engine to take effect.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q22-when-creating-a-new-workflow-it-prompts-504-gateway-time-out">Q22: When creating a new workflow, it prompts &quot;504 Gateway Time-out&quot;<a class="hash-link" href="#q22-when-creating-a-new-workflow-it-prompts-504-gateway-time-out" title="Direct link to heading">​</a></h2><p><img loading="lazy" src="/assets/images/q44_1-bf45a4798e444d605dacf795803cbd9c.png" width="3366" height="855" class="img_ev3q"></p><p>Error message: The instance 05f211cb021e:9108 of application linkis-ps-cs is not exists. ,ip: 5d30e4bb2f42 ,port: 9001 ,serviceKind: linkis-mg-gateway, as shown below:</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q23-scripts-execute-python-scripts-the-content-of-the-script-is-very-simple-print-and-execute-successfully-normally-it-can-also-be-executed-successfully-through-the-task-scheduling-system-it-can-also-be-executed-successfully-through-the-job-flow-editing-job-script-page-but-an-error-is-reported-through-job-flow-execution">Q23: Scripts execute python scripts (the content of the script is very simple print) and execute successfully normally. It can also be executed successfully through the task scheduling system. It can also be executed successfully through the job flow editing job script page, but an error is reported through job flow execution.<a class="hash-link" href="#q23-scripts-execute-python-scripts-the-content-of-the-script-is-very-simple-print-and-execute-successfully-normally-it-can-also-be-executed-successfully-through-the-task-scheduling-system-it-can-also-be-executed-successfully-through-the-job-flow-editing-job-script-page-but-an-error-is-reported-through-job-flow-execution" title="Direct link to heading">​</a></h2><p>Error message:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">You can go to this path(/opt/kepler/work/engine/hadoop/workDir/9c28976e-63ba-4d9d-b85e-b37d84144596/logs) to find the reason or ask the administrator for help ,ip: host1 ,port: 9101 ,serviceKind: linkis-cg-linkismanager ,ip: host1 ,port: 9104 ,serviceKind: linkis-cg-entrance</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Exception in thread &quot;main&quot; java.lang.NullPointerException</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    at com.webank.wedatasphere.linkis.rpc.sender.SpringCloudFeignConfigurationCache$.getClient(SpringCloudFeignConfigurationCache.scala:73)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    at com.webank.wedatasphere.linkis.rpc.sender.SpringMVCRPCSender.doBuilder(SpringMVCRPCSender.scala:49)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=250m; support was removed in 8.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Java HotSpot(TM) 64-Bit Server VM warning: ignoring option PermSize=128m; support was removed in 8.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Exception in thread &quot;main&quot; java.lang.NullPointerException</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    at com.webank.wedatasphere.linkis.rpc.sender.SpringCloudFeignConfigurationCache$.getClient(SpringCloudFeignConfigurationCache.scala:73)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    at com.webank.wedatasphere.linkis.rpc.sender.SpringMVCRPCSender.doBuilder(SpringMVCRPCSender.scala:49)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    at com.webank.wedatasphere.linkis.rpc.BaseRPCSender.newRPC(BaseRPCSender.scala:67)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    at com.webank.wedatasphere.linkis.rpc.BaseRPCSender.com$webank$wedatasphere$linkis$rpc$BaseRPCSender$$getRPC(BaseRPCSender.scala:54)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    at com.webank.wedatasphere.linkis.rpc.BaseRPCSender.send(BaseRPCSender.scala:105)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    at com.webank.wedatasphere.linkis.engineconn.callback.service.AbstractEngineConnStartUpCallback.callback(EngineConnCallback.scala:39)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    at com.webank.wedatasphere.linkis.engineconn.callback.hook.CallbackEngineConnHook.afterEngineServerStartFailed(CallbackEngineConnHook.scala:63)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    at com.webank.wedatasphere.linkis.engineconn.launch.EngineConnServer$$anonfun$main$15.apply(EngineConnServer.scala:64)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    at com.webank.wedatasphere.linkis.engineconn.launch.EngineConnServer$$anonfun$main$15.apply(EngineConnServer.scala:64)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    at com.webank.wedatasphere.linkis.engineconn.launch.EngineConnServer$.main(EngineConnServer.scala:64)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    at com.webank.wedatasphere.linkis.engineconn.launch.EngineConnServer.main(EngineConnServer.scala)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Solution: The conf in the /opt/kepler/work/engine/hadoop/workDir/9c28976e-63ba-4d9d-b85e-b37d84144596 directory is empty. lib and conf are detected by the system (linkis/lib/linkis-engineconn-plugins/python) when the microservice starts, and the python engine material package zip changes, and are automatically uploaded to the engine/engineConnPublickDir/ directory. The temporary solution to the problem is to copy the lib and conf content under linkis/lib/linkis-engineconn-plugins/python to the corresponding directory of engine/engineConnPublicDir/ (that is, the external link referenced in workDir/9c28976e-63ba-4d9d-b85e-b37d84144596 Under contents. The official solution needs to solve the problem that the change of the material package cannot be successfully uploaded to engineConnPublicDir.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q24-after-installing-exchangis050-click-on-the-dss-menu-to-enter-a-new-page-and-prompt-sorry-page-not-found-f12-view-has-404-exception">Q24: After installing Exchangis0.5.0, click on the dss menu to enter a new page and prompt &quot;Sorry, Page Not Found&quot;. F12 view has 404 exception<a class="hash-link" href="#q24-after-installing-exchangis050-click-on-the-dss-menu-to-enter-a-new-page-and-prompt-sorry-page-not-found-f12-view-has-404-exception" title="Direct link to heading">​</a></h2><p>Error message: F12 view vue.runtime.esm.js:6785 GET <a href="http://10.0.xx.xx:29008/udes/auth?redirect=http%3A%2F%2F10.0.xx.xx%3A29008&amp;dssurl=" target="_blank" rel="noopener noreferrer">http://10.0.xx.xx:29008/udes/auth?redirect=http%3A%2F%2F10.0.xx.xx%3A29008&amp;dssurl=</a> http%3A%2F%2F10.0.xx.xx%3A8088&amp;cookies=bdp-user-ticket-id%3DM7UZXQP9Ld1xeftV5DUGYeHdOc9oAFgW2HLiVea4FcQ%3D%3B%20workspaceId%3D225 404 (Not Found)</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q25-there-is-an-infinite-loop-in-configuring-atlas-in-hive-resulting-in-stack-overflow">Q25: There is an infinite loop in configuring atlas in HIVE, resulting in stack overflow<a class="hash-link" href="#q25-there-is-an-infinite-loop-in-configuring-atlas-in-hive-resulting-in-stack-overflow" title="Direct link to heading">​</a></h2><p>You need to add all the content jar packages and subdirectories under ${ATLAS_HOME}/atlas/hook/hive/ to the lib directory of hive engine, otherwise AtlasPluginClassLoader cannot find the correct implementation class and finds the one under hive-bridge-shim class, resulting in an infinite loop
However, the current execution method of Linkis (1.0.2) does not support subdirectories under lib, and the code needs to be modified. Refer to:
<a href="https://github.com/apache/linkis/pull/1058" target="_blank" rel="noopener noreferrer">https://github.com/apache/linkis/pull/1058</a></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q26-linkis10x-compiles-based-on-spark3-hadoop3-hive3-or-hdp314-please-refer-to">Q26: Linkis1.0.X compiles based on spark3 hadoop3 hive3 or hdp3.1.4, please refer to:<a class="hash-link" href="#q26-linkis10x-compiles-based-on-spark3-hadoop3-hive3-or-hdp314-please-refer-to" title="Direct link to heading">​</a></h2><p><a href="https://github.com/lordk911/Linkis/commits/master" target="_blank" rel="noopener noreferrer">https://github.com/lordk911/Linkis/commits/master</a>
After compiling, please recompile DSS according to the compiled package, keep the same version of scala, and use the family bucket for web modules</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q27-linkis-cannot-get-user-name-when-executing-jdbc-task">Q27 Linkis cannot get user name when executing jdbc task<a class="hash-link" href="#q27-linkis-cannot-get-user-name-when-executing-jdbc-task" title="Direct link to heading">​</a></h2><p>2021-10-31 05:16:54.016 ERROR Task is Failed,errorMsg: NullPointerException: jdbc.username cannot be null.
Source code: com.webank.wedatasphere.linkis.manager.engineplugin.jdbc.executer.JDBCEngineConnExecutor Received val properties = engineExecutorContext.getProperties.asInstanceOf[util.Map<!-- -->[String, String]<!-- -->] No jdbc.username parameter</p><p>Solution 1:
Documentation: Temporary fixes for JDBC issues.note
Link: <a href="http://note.youdao.com/noteshare?id=08163f429dd2e226a13877eba8bad1e3&amp;sub=4ADEE86F433B4A59BBB20621A1C4B2AE" target="_blank" rel="noopener noreferrer">http://note.youdao.com/noteshare?id=08163f429dd2e226a13877eba8bad1e3&amp;sub=4ADEE86F433B4A59BBB20621A1C4B2AE</a>
Solution 2: Compare and modify this file
<a href="https://github.com/apache/linkis/blob/319213793881b0329022cf4137ee8d4c502395c7/linkis-engineconn-plugins/engineconn-plugins/jdbc/src/main/scala/com/webank/wedatasphere/linkis/manager/engineplugin/jdbc/" target="_blank" rel="noopener noreferrer">https://github.com/apache/linkis/blob/319213793881b0329022cf4137ee8d4c502395c7/linkis-engineconn-plugins/engineconn-plugins/jdbc/src/main/scala/com/webank/wedatasphere/linkis/manager/engineplugin/jdbc/</a> executor/JDBCEngineConnExecutor.scala</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q28-after-changing-the-hive-version-in-the-configuration-before-installation-the-configuration-of-the-management-console-still-shows-the-version-as-233">Q28: After changing the hive version in the configuration before installation, the configuration of the management console still shows the version as 2.3.3<a class="hash-link" href="#q28-after-changing-the-hive-version-in-the-configuration-before-installation-the-configuration-of-the-management-console-still-shows-the-version-as-233" title="Direct link to heading">​</a></h2><p><img loading="lazy" src="/assets/images/q50_1-da3747bd98c7849f807cf006c80fc4d0.png" width="1684" height="922" class="img_ev3q"></p><p>Solution 1: It is determined that there is a bug in the install.sh script, please change the hive-1.2.1 here to hive-2.3.3 and reinstall it.
Solution 2: If you don’t want to reinstall, you need to change all the values ​​of hive-2.3.3 in the label_value in the linkis_cg_manager_label table to the desired hive version
Note: You are welcome to submit a PR to the github Linkis project to fix this problem, and then let us know, we will review and merge it into the code as soon as possible (currently unfixed, Deadline November 30, 2021)</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q29-when-linkis-cli-submits-a-task-it-prompts-group-by-clause-sql_modeonly_full_group_by-error">Q29: When linkis-cli submits a task, it prompts GROUP BY clause; sql_mode=only_full_group_by error<a class="hash-link" href="#q29-when-linkis-cli-submits-a-task-it-prompts-group-by-clause-sql_modeonly_full_group_by-error" title="Direct link to heading">​</a></h2><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">_8_codeExec_8 com.webank.wedatasphere.linkis.orchestrator.ecm.exception.ECMPluginErrorException: errCode: 12003 ,desc: uathadoop01:9101_8 Failed  to async get EngineNode MySQLSyntaxErrorException: Expression #6 of SELECT list is not in GROUP BY clause and contains nonaggregated column &#x27;dss_linkis.si.name&#x27; which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode=only_full_group_by ,ip: uathadoop01 ,port: 9104 ,serviceKind: linkis-cg-entrance</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Reason: This error occurs in mysql version 5.7 and above. Problem: Because the configuration strictly implements the &quot;SQL92 standard&quot;, the solution: enter the /etc/mysql directory to modify the my.cnf file and add code under <!-- -->[mysqld]<!-- -->:
sql_mode = STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q30-an-error-is-reported-when-the-flink-engine-starts-and-the-tokencache-is-found">Q30: An error is reported when the flink engine starts and the TokenCache is found<a class="hash-link" href="#q30-an-error-is-reported-when-the-flink-engine-starts-and-the-tokencache-is-found" title="Direct link to heading">​</a></h2><p>ERROR <!-- -->[main]<!-- --> com.webank.wedatasphere.linkis.engineconn.computation.executor.hook.ComputationEngineConnHook 57 error - EngineConnSever start failed! now exit. java.lang.NoClassDefFoundError: org/apache/hadoop/mapreduce/security/TokenCache
Reason: The jar package hadoop-mapreduce-client-core.jar is missing under flink-enginecon lib, just copy a copy from hadoop lib.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q31-when-starting-the-flink-enginespark-engine-the-engine-entrance-reports-an-error-orgjson4sjsonastjnothing-cannot-be-cast-to-orgjson4sjsonastjstring">Q31: When starting the flink engine/spark engine, the engine-entrance reports an error org.json4s.JsonAST$JNothing$ cannot be cast to org.json4s.JsonAST$JString<a class="hash-link" href="#q31-when-starting-the-flink-enginespark-engine-the-engine-entrance-reports-an-error-orgjson4sjsonastjnothing-cannot-be-cast-to-orgjson4sjsonastjstring" title="Direct link to heading">​</a></h2><p>The reason is that linkis-manager reports an error in the yarn queue to obtain an exception
Solution: Modify the linkis_cg_rm_external_resource_provider table and modify the yarn queue information corresponding to config</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q32-classnotfoundexception-is-reported-when-the-function-script-is-executed">Q32: ClassNotFoundException is reported when the function script is executed<a class="hash-link" href="#q32-classnotfoundexception-is-reported-when-the-function-script-is-executed" title="Direct link to heading">​</a></h2><p><img loading="lazy" src="/assets/images/q55_1-dcb8abee478065f48183c591ca54f431.png" width="1002" height="192" class="img_ev3q"></p><p>Reason: linkis creates a function by adding the path of the function to the classPath, and then executing create temporary function. . . Statement, when submitting tasks to the yarn cluster in this way, the jar package of the function will not be uploaded to hdfs, resulting in class loading failure!</p><p>Solution: Modify the method of generating function statements, or use HiveAddJarsEngineHook to solve it. Here, modify the constructCode method of JarUdfEngineHook. After packaging replace all</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">  override protected def constructCode(udfInfo: UDFInfo): String = {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;%sql\n&quot; + &quot;add jar &quot; + udfInfo.getPath + &quot;\n%sql\n&quot; + udfInfo.getRegisterFormat</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  }</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q33-failed-to-start-bean-webserverstartstop-when-linkis-executes-spark-task-in-cdh-environment">Q33: Failed to start bean &#x27;webServerStartStop when Linkis executes Spark task in CDH environment<a class="hash-link" href="#q33-failed-to-start-bean-webserverstartstop-when-linkis-executes-spark-task-in-cdh-environment" title="Direct link to heading">​</a></h2><p>Detailed log:</p><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">Caused by: java.lang.IllegalStateException</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.eclipse.jetty.servlet.ServletHolder.setClassFrom</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">ServletHolder.java:300</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> ~</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">jetty-servlet-9.4.48.v20220622.jar:9.4.48.v20220622</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.eclipse.jetty.servlet.ServletHolder.doStart</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">ServletHolder.java:347</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> ~</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">jetty-servlet-9.4.48.v20220622.jar:9.4.48.v20220622</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.eclipse.jetty.util.component.AbstractLifeCycle.start</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">AbstractLifeCycle.java:73</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> ~</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">jetty-util-9.4.48.v20220622.jar:9.4.48.v20220622</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.eclipse.jetty.servlet.ServletHandler.lambda</span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$initialize</span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">ServletHandler.java:749</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> ~</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">jetty-servlet-9.4.48.v20220622.jar:9.4.48.v20220622</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at java.util.stream.SortedOps</span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$SizedRefSortingSink</span><span class="token plain">.end</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">SortedOps.java:357</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> ~</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">?:1.8.0_292</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at java.util.stream.AbstractPipeline.copyInto</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">AbstractPipeline.java:483</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> ~</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">?:1.8.0_292</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at java.util.stream.AbstractPipeline.wrapAndCopyInto</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">AbstractPipeline.java:472</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> ~</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">?:1.8.0_292</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at java.util.stream.StreamSpliterators</span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$WrappingSpliterator</span><span class="token plain">.forEachRemaining</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">StreamSpliterators.java:313</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> ~</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">?:1.8.0_292</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at java.util.stream.Streams</span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$ConcatSpliterator</span><span class="token plain">.forEachRemaining</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">Streams.java:743</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> ~</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">?:1.8.0_292</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at java.util.stream.ReferencePipeline</span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$Head</span><span class="token plain">.forEach</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">ReferencePipeline.java:647</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> ~</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">?:1.8.0_292</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.eclipse.jetty.servlet.ServletHandler.initialize</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">ServletHandler.java:774</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> ~</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">jetty-servlet-9.4.48.v20220622.jar:9.4.48.v20220622</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.springframework.boot.web.embedded.jetty.JettyEmbeddedWebAppContext</span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$JettyEmbeddedServletHandler</span><span class="token plain">.deferredInitialize</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">JettyEmbeddedWebAppContext.java:46</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> ~</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">spring-boot-2.3.12.RELEASE.jar:2.3.12.RELEASE</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Reason: This is due to the conflict between the classPath and Linkis that CDH-Spark depends on at the bottom.
Solution: On the machine where linkis is deployed, you can check the classPath in spark-env.sh, comment it out, and run it again. For details, please refer to <a href="https://github.com/apache/linkis/issues/3282" target="_blank" rel="noopener noreferrer">3282</a></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="q34-an-error-is-reported-when-running-the-flink-task-failed-to-create-engineconnplugin-comwebankwedataspherelinkisenginepluginhivehiveengineconnpluginjavalangclassnotfoundexception-comwebankwedataspherelinkisenginepluginhivehiveengineconnplugin">Q34: An error is reported when running the flink task: Failed to create engineConnPlugin: com.webank.wedatasphere.linkis.engineplugin.hive.HiveEngineConnPluginjava.lang.ClassNotFoundException: com.webank.wedatasphere.linkis.engineplugin.hive.HiveEngineConnPlugin<a class="hash-link" href="#q34-an-error-is-reported-when-running-the-flink-task-failed-to-create-engineconnplugin-comwebankwedataspherelinkisenginepluginhivehiveengineconnpluginjavalangclassnotfoundexception-comwebankwedataspherelinkisenginepluginhivehiveengineconnplugin" title="Direct link to heading">​</a></h2><p><img loading="lazy" src="/assets/images/q53_1-e521f8846a09ef0f3e8bf245174ca474.png" width="1286" height="174" class="img_ev3q"></p><p>Reason: The configuration file in the conf in the flink engine directory is empty, and the default configuration is read (by default, the hived engine configuration is read), delete the conf about flink in the configuration table and restart ecp</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/apache/linkis-website/edit/dev/faq/main.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#q1-the-ps-cs-service-log-of-linkis-reports-this-error-figservletwebserverapplicationcontext-559" class="table-of-contents__link toc-highlight">Q1: The ps-cs service log of linkis reports this error: figServletWebServerApplicationContext (559)</a></li><li><a href="#q2-linkis-eureka-debugging-instructions" class="table-of-contents__link toc-highlight">Q2: Linkis-eureka debugging instructions</a></li><li><a href="#q3-eureka-automatically-stops-when-it-starts-for-the-first-time-and-needs-to-be-restarted-manually" class="table-of-contents__link toc-highlight">Q3: eureka automatically stops when it starts for the first time, and needs to be restarted manually</a></li><li><a href="#q4-linkis-entrance-logwriter-missing-dependencies" class="table-of-contents__link toc-highlight">Q4: Linkis Entrance LogWriter missing dependencies</a></li><li><a href="#q5-when-linkis10-executes-tasks-the-ecp-service-throws-the-following-error-caused-by-javautilnosuchelementexception-noneget" class="table-of-contents__link toc-highlight">Q5: When Linkis1.0 executes tasks, the ECP service throws the following error: Caused by: java.util.NoSuchElementException: None.get?</a></li><li><a href="#q6-linkis1x-general-troubleshooting-method-for-insufficient-resources" class="table-of-contents__link toc-highlight">Q6: Linkis1.X general troubleshooting method for insufficient resources</a></li><li><a href="#q7-linkis-startup-error-nosuchmethoderrorgetsessionmanagerlorgeclipsejettyserversessionmanager" class="table-of-contents__link toc-highlight">Q7: linkis startup error: NoSuchMethodErrorgetSessionManager()Lorg/eclipse/jetty/server/SessionManager</a></li><li><a href="#q1-linkis10-execution-task-report-select-list-is-not-in-group-by-clause" class="table-of-contents__link toc-highlight">Q1: Linkis1.0 execution task report: select list is not in group by clause</a></li><li><a href="#q2-when-executing-scripts-after-deployment-executing-commands-and-collecting-results-i-encountered-such-an-error-ioexception-file-header-type-must-be-dolphin" class="table-of-contents__link toc-highlight">Q2: When executing scripts after deployment, executing commands, and collecting results, I encountered such an error, IOException: File header type must be dolphin:</a></li><li><a href="#q3-the-json4s-package-conflict-caused-by-inconsistent-spark-versions-the-error-is-as-follows-error-message-caused-by-javalangnosuchmethoderror-orgjson4sjacksonjsonmethod" class="table-of-contents__link toc-highlight">Q3: The json4s package conflict caused by inconsistent Spark versions, the error is as follows: Error message: caused by: java.lang.NoSuchMethodError: org.json4s.jackson.jsonMethod$</a></li><li><a href="#q4-when-linkis1x-submits-spark-sql-tasks-in-version-cdh5161-how-to-troubleshoot-404-problems" class="table-of-contents__link toc-highlight">Q4: When Linkis1.X submits spark sql tasks in version CDH5.16.1, how to troubleshoot 404 problems</a></li><li><a href="#q5-running-error-report-missing-package-matplotlib" class="table-of-contents__link toc-highlight">Q5: running error report missing package matplotlib</a></li><li><a href="#q6-when-the-microservice-linkis-ps-cs-is-started-debuggclasswriter-overrides-final-method-visit-is-reported" class="table-of-contents__link toc-highlight">Q6: When the microservice linkis-ps-cs is started, DebuggClassWriter overrides final method visit is reported</a></li><li><a href="#q7-when-the-shell-engine-schedules-execution-the-engine-execution-directory-reports-the-following-error-binjava-no-such-file-or-directory" class="table-of-contents__link toc-highlight">Q7: When the shell engine schedules execution, the engine execution directory reports the following error /bin/java: No such file or directory:</a></li><li><a href="#q8-when-the-hive-engine-is-scheduled-the-error-log-of-engineconnmanager-is-as-follows-method-did-not-exist-sessionhandler" class="table-of-contents__link toc-highlight">Q8: When the hive engine is scheduled, the error log of engineConnManager is as follows: method did not exist: SessionHandler:</a></li><li><a href="#q9-when-the-hive-engine-is-executing-the-following-error-is-reported-lcomgooglecommoncollectunmodifiableiterator" class="table-of-contents__link toc-highlight">Q9: When the hive engine is executing, the following error is reported Lcom/google/common/collect/UnmodifiableIterator:</a></li><li><a href="#q10-during-engine-scheduling-the-following-error-is-reported-python-processes-is-not-alive" class="table-of-contents__link toc-highlight">Q10: During engine scheduling, the following error is reported: Python processes is not alive:</a></li><li><a href="#q11-when-the-spark-engine-is-running-the-following-error-is-reported-noclassdeffounderror-orgapachehadoophiveqlioorcorcfile" class="table-of-contents__link toc-highlight">Q11: When the spark engine is running, the following error is reported: NoClassDefFoundError: org/apache/hadoop/hive/ql/io/orc/OrcFile:</a></li><li><a href="#q1-the-database-on-the-left-side-of-the-script-cannot-be-refreshed" class="table-of-contents__link toc-highlight">Q1: The database on the left side of the script cannot be refreshed</a></li><li><a href="#q2-the-right-side-of-scriptis-cannot-refresh-the-database-and-it-has-been-refreshing-it-should-be-noted-that-the-metadata-of-linkis-does-not-support-docking-sentry-and-ranger-for-the-time-being-only-supports-native-permission-control-of-hive-error-message-the-front-end-database-tab-has-been-refreshing-state" class="table-of-contents__link toc-highlight">Q2: The right side of Scriptis cannot refresh the database, and it has been refreshing (it should be noted that the metadata of linkis does not support docking sentry and Ranger for the time being, only supports native permission control of hive), error message: the front-end database tab has been refreshing state</a></li><li><a href="#q3-scriptisworkspace-when-i-log-in-to-scriptis-the-root-directory-does-not-exist-and-there-are-two-root-directories-workspace-and-hdfs-error-message-after-logging-in-the-front-end-pops-up-the-following-message-the-users-local-directory-does-not-exist-please-contact-admin-to-add" class="table-of-contents__link toc-highlight">Q3: [Scriptis]Workspace When I log in to Scriptis, the root directory does not exist, and there are two root directories: workspace and HDFS: Error message: After logging in, the front end pops up the following message (the user’s local directory does not exist, please Contact admin to add)</a></li><li><a href="#q4-management-consolesettings-how-to-adjust-the-yarn-queue-used-by-the-task-error-message-when-executing-the-sql-task-it-is-reported-that-1-obtaining-the-yarn-queue-information-is-abnormal-or-user-xx-cannot-submit-to-the-queue" class="table-of-contents__link toc-highlight">Q4: [Management Console]Settings How to adjust the yarn queue used by the task? Error message: When executing the sql task, it is reported that 1. Obtaining the Yarn queue information is abnormal or user XX cannot submit to the queue</a></li><li><a href="#q5-when-hive-queries-it-reports-can-not-find-zk-related-classes-such-as-orgapachecurator-error-message-when-executing-hive-tasks-the-log-report-cannot-find-the-class-starting-with-orgapachecurator--classnotfound" class="table-of-contents__link toc-highlight">Q5: When Hive queries, it reports: Can not find zk-related classes such as: org.apache.curator.<em>, error message: When executing hive tasks, the log report cannot find the class starting with org.apache.curator.</em> , classNotFound</a></li><li><a href="#q6-how-does-linkis-support-kerberos" class="table-of-contents__link toc-highlight">Q6: How does Linkis support kerberos</a></li><li><a href="#q7-regarding-linkis-besides-supporting-deployment-user-login-can-other-user-logins-be-configured" class="table-of-contents__link toc-highlight">Q7: Regarding Linkis, besides supporting deployment user login, can other user logins be configured?</a></li><li><a href="#q8-how-to-open-linkis-management-console-administrator-page-ecm-and-microservice-management" class="table-of-contents__link toc-highlight">Q8: How to open Linkis management console, administrator page ECM and microservice management?</a></li><li><a href="#q9-when-starting-the-microservice-linkis-ps-publicservice-kjdbcutilsgetdriverclassname-npe" class="table-of-contents__link toc-highlight">Q9: When starting the microservice linkis-ps-publicservice, kJdbcUtils.getDriverClassName NPE</a></li><li><a href="#q10-when-scheduling-the-hive-engine-the-following-error-is-reported-engineconnpluginnotfoundexception-errorcode-70063" class="table-of-contents__link toc-highlight">Q10: When scheduling the hive engine, the following error is reported: EngineConnPluginNotFoundException: errorCode: 70063</a></li><li><a href="#q11-when-the-hive-engine-schedules-execution-the-following-error-is-reported-opertion-failed-nullpointerexception" class="table-of-contents__link toc-highlight">Q11: When the hive engine schedules execution, the following error is reported: opertion failed NullPointerException:</a></li><li><a href="#q12-when-the-spark-engine-starts-an-error-is-reported-get-the-queue-information-excepiton-obtaining-yarn-queue-information-exception-and-http-link-exception" class="table-of-contents__link toc-highlight">Q12: When the spark engine starts, an error is reported get the queue information excepiton. (obtaining Yarn queue information exception) and http link exception</a></li><li><a href="#q13-pythonspark-scheduling-execution-error-initialize-python-executor-failed-classnotfoundexception-orgslf4jimplstaticloggerbinder" class="table-of-contents__link toc-highlight">Q13: pythonspark scheduling execution, error: initialize python executor failed ClassNotFoundException org.slf4j.impl.StaticLoggerBinder</a></li><li><a href="#q14-common-package-conflicts" class="table-of-contents__link toc-highlight">Q14: Common package conflicts:</a></li><li><a href="#q15-the-mysql-script-running-scripts-reports-an-errorsql-engine-reports-an-error" class="table-of-contents__link toc-highlight">Q15: The Mysql script running Scripts reports an errorsql engine reports an error</a></li><li><a href="#q16-the-waiting-time-for-scriptis-to-execute-the-script-is-long" class="table-of-contents__link toc-highlight">Q16: The waiting time for scriptis to execute the script is long</a></li><li><a href="#q17-scriptis-executes-jdbc-script-and-reports-an-error" class="table-of-contents__link toc-highlight">Q17: scriptis executes jdbc script and reports an error</a></li><li><a href="#q18-turn-off-resource-checking" class="table-of-contents__link toc-highlight">Q18: Turn off resource checking</a></li><li><a href="#q19-executing-the-script-reports-an-error" class="table-of-contents__link toc-highlight">Q19: Executing the script reports an error</a></li><li><a href="#q20-scriptis-execute-script-timeoutexception" class="table-of-contents__link toc-highlight">Q20: ScriptIs execute script TimeoutException</a></li><li><a href="#q21-engine-timeout-setting" class="table-of-contents__link toc-highlight">Q21: Engine timeout setting</a></li><li><a href="#q22-when-creating-a-new-workflow-it-prompts-504-gateway-time-out" class="table-of-contents__link toc-highlight">Q22: When creating a new workflow, it prompts &quot;504 Gateway Time-out&quot;</a></li><li><a href="#q23-scripts-execute-python-scripts-the-content-of-the-script-is-very-simple-print-and-execute-successfully-normally-it-can-also-be-executed-successfully-through-the-task-scheduling-system-it-can-also-be-executed-successfully-through-the-job-flow-editing-job-script-page-but-an-error-is-reported-through-job-flow-execution" class="table-of-contents__link toc-highlight">Q23: Scripts execute python scripts (the content of the script is very simple print) and execute successfully normally. It can also be executed successfully through the task scheduling system. It can also be executed successfully through the job flow editing job script page, but an error is reported through job flow execution.</a></li><li><a href="#q24-after-installing-exchangis050-click-on-the-dss-menu-to-enter-a-new-page-and-prompt-sorry-page-not-found-f12-view-has-404-exception" class="table-of-contents__link toc-highlight">Q24: After installing Exchangis0.5.0, click on the dss menu to enter a new page and prompt &quot;Sorry, Page Not Found&quot;. F12 view has 404 exception</a></li><li><a href="#q25-there-is-an-infinite-loop-in-configuring-atlas-in-hive-resulting-in-stack-overflow" class="table-of-contents__link toc-highlight">Q25: There is an infinite loop in configuring atlas in HIVE, resulting in stack overflow</a></li><li><a href="#q26-linkis10x-compiles-based-on-spark3-hadoop3-hive3-or-hdp314-please-refer-to" class="table-of-contents__link toc-highlight">Q26: Linkis1.0.X compiles based on spark3 hadoop3 hive3 or hdp3.1.4, please refer to:</a></li><li><a href="#q27-linkis-cannot-get-user-name-when-executing-jdbc-task" class="table-of-contents__link toc-highlight">Q27 Linkis cannot get user name when executing jdbc task</a></li><li><a href="#q28-after-changing-the-hive-version-in-the-configuration-before-installation-the-configuration-of-the-management-console-still-shows-the-version-as-233" class="table-of-contents__link toc-highlight">Q28: After changing the hive version in the configuration before installation, the configuration of the management console still shows the version as 2.3.3</a></li><li><a href="#q29-when-linkis-cli-submits-a-task-it-prompts-group-by-clause-sql_modeonly_full_group_by-error" class="table-of-contents__link toc-highlight">Q29: When linkis-cli submits a task, it prompts GROUP BY clause; sql_mode=only_full_group_by error</a></li><li><a href="#q30-an-error-is-reported-when-the-flink-engine-starts-and-the-tokencache-is-found" class="table-of-contents__link toc-highlight">Q30: An error is reported when the flink engine starts and the TokenCache is found</a></li><li><a href="#q31-when-starting-the-flink-enginespark-engine-the-engine-entrance-reports-an-error-orgjson4sjsonastjnothing-cannot-be-cast-to-orgjson4sjsonastjstring" class="table-of-contents__link toc-highlight">Q31: When starting the flink engine/spark engine, the engine-entrance reports an error org.json4s.JsonAST$JNothing$ cannot be cast to org.json4s.JsonAST$JString</a></li><li><a href="#q32-classnotfoundexception-is-reported-when-the-function-script-is-executed" class="table-of-contents__link toc-highlight">Q32: ClassNotFoundException is reported when the function script is executed</a></li><li><a href="#q33-failed-to-start-bean-webserverstartstop-when-linkis-executes-spark-task-in-cdh-environment" class="table-of-contents__link toc-highlight">Q33: Failed to start bean &#39;webServerStartStop when Linkis executes Spark task in CDH environment</a></li><li><a href="#q34-an-error-is-reported-when-running-the-flink-task-failed-to-create-engineconnplugin-comwebankwedataspherelinkisenginepluginhivehiveengineconnpluginjavalangclassnotfoundexception-comwebankwedataspherelinkisenginepluginhivehiveengineconnplugin" class="table-of-contents__link toc-highlight">Q34: An error is reported when running the flink task: Failed to create engineConnPlugin: com.webank.wedatasphere.linkis.engineplugin.hive.HiveEngineConnPluginjava.lang.ClassNotFoundException: com.webank.wedatasphere.linkis.engineplugin.hive.HiveEngineConnPlugin</a></li></ul></div></div></div></div></main></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Linkis</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/latest/about/introduction">Document</a></li><li class="footer__item"><a class="footer__link-item" href="/faq/main">FAQ</a></li><li class="footer__item"><a href="https://github.com/apache/linkis/releases" target="_blank" rel="noopener noreferrer" class="footer__link-item">Releases</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/apache/linkis" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub</a></li><li class="footer__item"><a href="https://github.com/apache/linkis/issues" target="_blank" rel="noopener noreferrer" class="footer__link-item">Issue Tracker</a></li><li class="footer__item"><a href="https://github.com/apache/linkis/pulls" target="_blank" rel="noopener noreferrer" class="footer__link-item">Pull Requests</a></li></ul></div><div class="col footer__col"><div class="footer__title">Subscribe Mailing List</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/community/how-to-subscribe">How to Subscribe</a></li><li class="footer__item"><a href="mailto:dev-subscribe@linkis.apache.org" target="_blank" rel="noopener noreferrer" class="footer__link-item">Subscribe Mail</a></li><li class="footer__item"><a href="https://lists.apache.org/list.html?dev@linkis.apache.org" target="_blank" rel="noopener noreferrer" class="footer__link-item">Mail Archive</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright"><div><img style="height:50px" alt="Apache Software Foundation" src="/img/incubator-logo.svg"><p style="color: #999999;  padding: 0 20px 30px;font-weight:400;text-align:left">Apache Linkis is an effort undergoing incubation at The Apache Software Foundation (ASF), sponsored by the Apache Incubator. Incubation is required of all newly accepted projects until a further review indicates that the infrastructure, communications, and decision making process have stabilized in a manner consistent with other successful ASF projects. While incubation status is not necessarily a reflection of the completeness or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF.</p><p></p>
             <p style="padding: 0 20px 30px;color: #999999;font-weight: 400;"> Copyright © 2023 The Apache Software Foundation. Licensed under the Apache License, Version 2.0. Apache Linkis, Apache Incubator, Apache, the Apache feather logo, the Apache Linkis logo and the Apache Incubator project logo are trademarks of The Apache Software Foundation.</p>
             <div></div></div></div></div></div></footer></div>
<script src="/assets/js/runtime~main.4d57b696.js"></script>
<script src="/assets/js/main.6d8daa6a.js"></script>
</body>
</html>