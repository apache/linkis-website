<!doctype html>
<html class="docs-version-current" lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.14">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Apache Linkis Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Apache Linkis Blog Atom Feed">
<link rel="search" type="application/opensearchdescription+xml" title="Apache Linkis" href="/opensearch.xml"><title data-react-helmet="true">Q&amp;A | Apache Linkis</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://linkis.incubator.apache.org/faq/main"><meta data-react-helmet="true" name="docsearch:language" content="en"><meta data-react-helmet="true" name="docsearch:version" content="current"><meta data-react-helmet="true" name="docsearch:docusaurus_tag" content="docs-faq-current"><meta data-react-helmet="true" property="og:title" content="Q&amp;A | Apache Linkis"><meta data-react-helmet="true" name="description" content="Linkis1.0 the latest Q&amp;A document//docs.qq.com/doc/DWlN4emlJeEJxWlR0"><meta data-react-helmet="true" property="og:description" content="Linkis1.0 the latest Q&amp;A document//docs.qq.com/doc/DWlN4emlJeEJxWlR0"><link data-react-helmet="true" rel="shortcut icon" href="/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://linkis.incubator.apache.org/faq/main"><link data-react-helmet="true" rel="alternate" href="https://linkis.incubator.apache.org/faq/main" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://linkis.incubator.apache.org/zh-CN/faq/main" hreflang="zh-CN"><link data-react-helmet="true" rel="alternate" href="https://linkis.incubator.apache.org/faq/main" hreflang="x-default"><link data-react-helmet="true" rel="preconnect" href="https://AE29KQB3IA-dsn.algolia.net" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.192d006d.css">
<link rel="preload" href="/assets/js/runtime~main.4a9f2810.js" as="script">
<link rel="preload" href="/assets/js/main.959844b8.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div><a href="#" class="skipToContent_OuoZ">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><img src="/img/logo.png" alt="Apache Linkis Logo" class="themedImage_TMUO themedImage--light_4Vu1 navbar__logo"><img src="/img/logo.png" alt="Apache Linkis Logo" class="themedImage_TMUO themedImage--dark_uzRr navbar__logo"><b class="navbar__title">Apache Linkis(Incubating)</b></a><a class="navbar__item navbar__link" href="/">Home</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/faq/main">FAQ</a><a class="navbar__item navbar__link" href="/download/main">Download</a><a class="navbar__item navbar__link" href="/community/how-to-subscribe">Community</a><a class="navbar__item navbar__link" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/team">Team</a><a class="navbar__item navbar__link" href="/user">Users</a><div class="navbar__item dropdown dropdown--hoverable"><a class="navbar__link">ASF</a><ul class="dropdown__menu"><li><a href="https://www.apache.org/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Foundation</a></li><li><a href="https://www.apache.org/licenses/" target="_blank" rel="noopener noreferrer" class="dropdown__link">License</a></li><li><a href="https://www.apache.org/events/current-event" target="_blank" rel="noopener noreferrer" class="dropdown__link">Events</a></li><li><a href="https://www.apache.org/security/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Security</a></li><li><a href="https://www.apache.org/foundation/sponsorship.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">Sponsorship</a></li><li><a href="https://www.apache.org/foundation/policies/privacy.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">Privacy</a></li><li><a href="https://www.apache.org/foundation/thanks.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">Thanks</a></li></ul></div></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a class="navbar__link">Doc</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/docs/1.1.2/introduction">Next-1.1.2 (WIP)</a></li><li><a class="dropdown__link" href="/docs/latest/introduction">1.1.1</a></li><li><a class="dropdown__link" href="/docs/1.1.0/introduction">1.1.0</a></li><li><a class="dropdown__link" href="/docs/1.0.3/introduction">1.0.3</a></li><li><a class="dropdown__link" href="/docs/1.0.2/introduction">1.0.2</a></li><li><a class="dropdown__link" href="/docs/0.11.0/introduction">0.11.0</a></li><li><a class="dropdown__link" href="/versions/">All Versions</a></li></ul></div><a href="https://github.com/apache/incubator-linkis" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub"></a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" class="navbar__link"><span><svg t="1631348384596" class="iconLanguage_EbrZ" viewBox="0 0 1024 1024" version="1.1" p-id="557" width="20" height="20"><path d="M547.797333 638.208l-104.405333-103.168 1.237333-1.28a720.170667 720.170667 0 0 0 152.490667-268.373333h120.448V183.082667h-287.744V100.906667H347.605333v82.218666H59.818667V265.386667h459.178666a648.234667 648.234667 0 0 1-130.304 219.946666 643.242667 643.242667 0 0 1-94.976-137.728H211.541333a722.048 722.048 0 0 0 122.453334 187.434667l-209.194667 206.378667 58.368 58.368 205.525333-205.525334 127.872 127.829334 31.232-83.84m231.424-208.426667h-82.218666l-184.96 493.312h82.218666l46.037334-123.306667h195.242666l46.464 123.306667h82.218667l-185.002667-493.312m-107.690666 287.744l66.56-178.005333 66.602666 178.005333z" fill="currentColor" p-id="558"></path></svg><span>English</span></span></a><ul class="dropdown__menu"><li><a href="/faq/main" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" style="text-transform:capitalize">English</a></li><li><a href="/zh-CN/faq/main" target="_self" rel="noopener noreferrer" class="dropdown__link" style="text-transform:capitalize">简体中文</a></li></ul></div><div class="searchBox_Bc3W"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper docs-wrapper docs-doc-page"><div class="docPage_lDyR"><button class="clean-btn backToTopButton_i9tI" type="button"><svg viewBox="0 0 24 24" width="28"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z" fill="currentColor"></path></svg></button><aside class="docSidebarContainer_0YBq"><div class="sidebar_a3j0"><nav class="menu thin-scrollbar menu_cyFh menuWithAnnouncementBar_+O1J"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link menu__link--active" aria-current="page" href="/faq/main">Q&amp;A</a></li></ul></nav></div></aside><main class="docMainContainer_r8cw"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_zHA2"><div class="docItemContainer_oiyr"><article><div class="tocCollapsible_aw-L theme-doc-toc-mobile tocMobile_Tx6Y"><button type="button" class="clean-btn tocCollapsibleButton_zr6a">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Q&amp;A</h1></header><blockquote><p>Linkis1.0 the latest Q&amp;A document: <a href="https://docs.qq.com/doc/DWlN4emlJeEJxWlR0" target="_blank" rel="noopener noreferrer">https://docs.qq.com/doc/DWlN4emlJeEJxWlR0</a></p></blockquote><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q1-linkis-startup-error-nosuchmethoderrorgetsessionmanagerlorgeclipsejettyserversessionmanager"></a>Q1, linkis startup error: NoSuchMethodErrorgetSessionManager()Lorg/eclipse/jetty/server/SessionManager<a class="hash-link" href="#q1-linkis-startup-error-nosuchmethoderrorgetsessionmanagerlorgeclipsejettyserversessionmanager" title="Direct link to heading">#</a></h4><p>Specific stack:</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI"><pre tabindex="0" class="prism-code language-undefined codeBlock_rtdJ thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#F8F8F2"><span class="token plain">Failed startup of context osbwejJettyEmbeddedWebAppContext@6c6919ff{application,/,[file:///tmp/jetty-docbase.9102.6375358926927953589/],UNAVAILABLE} java.lang.NoSuchMethodError: org.eclipse.jetty.server.session.SessionHandler.getSessionManager ()Lorg/eclipse/jetty/server/SessionManager;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.eclipse.jetty.servlet.ServletContextHandler\$Context.getSessionCookieConfig(ServletContextHandler.java:1415) ~[jetty-servlet-9.3.20.v20170531.jar:9.3.20.v20170531]</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><p>Solution: jetty-servlet and jetty-security versions need to be upgraded from 9.3.20 to 9.4.20;</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q2-when-starting-the-microservice-linkis-ps-cs-report-debuggclasswriter-overrides-final-method-visit"></a>Q2. When starting the microservice linkis-ps-cs, report DebuggClassWriter overrides final method visit<a class="hash-link" href="#q2-when-starting-the-microservice-linkis-ps-cs-report-debuggclasswriter-overrides-final-method-visit" title="Direct link to heading">#</a></h4><p>Specific exception stack:</p><p><img alt="linkis-exception-01.png" src="/assets/images/linkis-exception-01-3ce5a64d164882814935b610d226d5d6.png"></p><p>Solution: jar package conflict, delete asm-5.0.4.jar;</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q3-when-starting-the-microservice-linkis-ps-datasource-jdbcutilsgetdriverclassname-npe"></a>Q3. When starting the microservice linkis-ps-datasource, JdbcUtils.getDriverClassName NPE<a class="hash-link" href="#q3-when-starting-the-microservice-linkis-ps-datasource-jdbcutilsgetdriverclassname-npe" title="Direct link to heading">#</a></h4><p>Specific exception stack:</p><p><img alt="linkis-exception-02.png" src="/assets/images/linkis-exception-02-70fdd83cebfd9f535617f4ada1aa0e66.png"></p><p>Solution: caused by the Linkis-datasource configuration problem, modify the three parameters at the beginning of linkis.properties hive.meta:</p><p><img alt="hive-config-01.png" src="/assets/images/hive-config-01-38139d9e535f185bee3e17535a5ec327.png"></p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q4-when-starting-the-microservice-linkis-ps-datasource-the-following-exception-classnotfoundexception-httpclient-is-reported"></a>Q4. When starting the microservice linkis-ps-datasource, the following exception ClassNotFoundException HttpClient is reported:<a class="hash-link" href="#q4-when-starting-the-microservice-linkis-ps-datasource-the-following-exception-classnotfoundexception-httpclient-is-reported" title="Direct link to heading">#</a></h4><p>Specific exception stack:</p><p><img alt="linkis-exception-03.png" src="/assets/images/linkis-exception-03-36fb649e7ef97ceeb949ec89a9b8ffb9.png"></p><p>Solution: There is a problem with linkis-metadata-dev-1.0.0.jar compiled in 1.0, and it needs to be recompiled and packaged.</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q5-click-scriptis-database-no-data-is-returned-the-phenomenon-is-as-follows"></a>Q5. Click scriptis-database, no data is returned, the phenomenon is as follows:<a class="hash-link" href="#q5-click-scriptis-database-no-data-is-returned-the-phenomenon-is-as-follows" title="Direct link to heading">#</a></h4><p><img alt="page-show-01.png" src="/assets/images/page-show-01-cbec3b1161e52e05e9bcdecadd9de3c1.png"></p><p>Solution: The reason is that hive is not authorized to Hadoop users. The authorization data is as follows:</p><p><img alt="db-config-01.png" src="/assets/images/db-config-01-148b2d1dd324a8082543a67b8a61d031.png"></p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q6-shell-engine-scheduling-execution-the-page-reports-insufficient-resource-requesting-available-engine-timeout-eneningeconnmanager-linkisout-and-the-following-error-is-reported"></a>Q6, shell engine scheduling execution, the page reports Insufficient resource, requesting available engine timeout, eneningeconnmanager linkis.out, and the following error is reported:<a class="hash-link" href="#q6-shell-engine-scheduling-execution-the-page-reports-insufficient-resource-requesting-available-engine-timeout-eneningeconnmanager-linkisout-and-the-following-error-is-reported" title="Direct link to heading">#</a></h4><p><img alt="linkis-exception-04.png" src="/assets/images/linkis-exception-04-90263ffdfacbfc69cd63e59955452217.png"></p><p>Solution: The reason Hadoop did not create /appcom/tmp/hadoop/workDir. Create it in advance through the root user, and then authorize the Hadoop user.</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q7-when-the-shell-engine-is-scheduled-for-execution-the-engine-execution-directory-reports-the-following-error-binjava-no-such-file-or-directory"></a>Q7. When the shell engine is scheduled for execution, the engine execution directory reports the following error /bin/java: No such file or directory:<a class="hash-link" href="#q7-when-the-shell-engine-is-scheduled-for-execution-the-engine-execution-directory-reports-the-following-error-binjava-no-such-file-or-directory" title="Direct link to heading">#</a></h4><p><img alt="shell-error-01.png" src="/assets/images/shell-error-01-170fd7884890c07287d87460366b51c6.png"></p><p>Solution: There is a problem with the local java environment variables, and you need to make a symbolic link to the java command.</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q8-hive-engine-scheduling-the-following-error-is-reported-engineconnpluginnotfoundexceptionerrorcode70063"></a>Q8, hive engine scheduling, the following error is reported EngineConnPluginNotFoundException:errorCode:70063<a class="hash-link" href="#q8-hive-engine-scheduling-the-following-error-is-reported-engineconnpluginnotfoundexceptionerrorcode70063" title="Direct link to heading">#</a></h4><p><img alt="linkis-exception-05.png" src="/assets/images/linkis-exception-05-79ebb69bb11102bfe287ef83ab4131f9.png"></p><p>Solution: It is caused by not modifying the version of the corresponding engine during installation, so the engine type inserted into the db by default is the default version, and the compiled version is not caused by the default version. Specific modification steps: cd /appcom/Install/dss-linkis/linkis/lib/linkis-engineconn-plugins/, modify the v2.1.1 directory name in the dist directory to v1.2.1 modify the subdirectory name in the plugin directory 2.1. 1 is 1.2.1 of the default version. If it is Spark, you need to modify dist/v2.4.3 and plugin/2.4.3 accordingly. Finally restart the engineplugin service.</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q9-after-the-linkis-microservice-is-started-the-following-error-is-reported-load-balancer-does-not-have-available-server-for-client"></a>Q9. After the linkis microservice is started, the following error is reported: Load balancer does not have available server for client:<a class="hash-link" href="#q9-after-the-linkis-microservice-is-started-the-following-error-is-reported-load-balancer-does-not-have-available-server-for-client" title="Direct link to heading">#</a></h4><p><img alt="page-show-02.png" src="/assets/images/page-show-02-f1fe09ca6bd0a2b2d7236e033c51a5de.png"></p><p>Solution: This is because the linkis microservice has just started and the registration has not been completed. Wait for 1~2 minutes and try again.</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q10-when-the-hive-engine-is-scheduled-for-execution-the-following-error-is-reported-operation-failed-nullpointerexception"></a>Q10. When the hive engine is scheduled for execution, the following error is reported: operation failed NullPointerException:<a class="hash-link" href="#q10-when-the-hive-engine-is-scheduled-for-execution-the-following-error-is-reported-operation-failed-nullpointerexception" title="Direct link to heading">#</a></h4><p><img alt="linkis-exception-06.png" src="/assets/images/linkis-exception-06-a8da09412508967d9b87712a6e97d74a.png"></p><p>Solution: The server lacks environment variables, add export HIVE_CONF_DIR=/etc/hive/conf in /etc/profile;</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q11-when-hive-engine-is-scheduled-the-error-log-of-engineconnmanager-is-as-follows-method-did-not-exist-sessionhandler"></a>Q11. When hive engine is scheduled, the error log of engineConnManager is as follows method did not exist: SessionHandler:<a class="hash-link" href="#q11-when-hive-engine-is-scheduled-the-error-log-of-engineconnmanager-is-as-follows-method-did-not-exist-sessionhandler" title="Direct link to heading">#</a></h4><p><img alt="linkis-exception-07.png" src="/assets/images/linkis-exception-07-437193907ead2d47135f7761017e8730.png"></p><p>Solution: Under the hive engine lib, the jetty jar package conflicts, replace jetty-security and jetty-server with 9.4.20;</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="after-q12-hive-engine-restarts-the-jar-package-of-jetty-94-is-always-replaced-by-93"></a>After Q12, hive engine restarts, the jar package of jetty 9.4 is always replaced by 9.3<a class="hash-link" href="#after-q12-hive-engine-restarts-the-jar-package-of-jetty-94-is-always-replaced-by-93" title="Direct link to heading">#</a></h4><p>Solution: When the engine instance is generated, there will be a jar package cache. First, you need to delete the records related to the table linkis_engine_conn_plugin_bml_resources hive, and then delete the records under the directory /appcom/Install/dss-linkis/linkis/lib/linkis-engineconn-plugins/hive/dist 1.2.1.zip, finally restart the engineplugin service, the jar package of lib will be updated successfully.</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q13-when-the-hive-engine-is-executed-the-following-error-is-reported-lcomgooglecommoncollectunmodifiableiterator"></a>Q13. When the hive engine is executed, the following error is reported: Lcom/google/common/collect/UnmodifiableIterator:<a class="hash-link" href="#q13-when-the-hive-engine-is-executed-the-following-error-is-reported-lcomgooglecommoncollectunmodifiableiterator" title="Direct link to heading">#</a></h4><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI"><pre tabindex="0" class="prism-code language-undefined codeBlock_rtdJ thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#F8F8F2"><span class="token plain">2021-03-16 13:32:23.304 ERROR [pool-2-thread-1] com.webank.wedatasphere.linkis.engineplugin.hive.executor.HiveEngineConnExecutor 140 run-query failed, reason: java.lang.IllegalAccessError: tried to access method com.google.common.collect.Iterators.emptyIterator() Lcom/google/common/collect/UnmodifiableIterator; from class org.apache.hadoop.hive.ql.exec.FetchOperator</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.hadoop.hive.ql.exec.FetchOperator.&lt;init&gt;(FetchOperator.java:108) ~[hive-exec-2.1.1-cdh6.1.0.jar:2.1.1-cdh6.1.0]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.hadoop.hive.ql.exec.FetchTask.initialize(FetchTask.java:86) ~[hive-exec-2.1.1-cdh6.1.0.jar:2.1.1-cdh6.1.0]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:629) ~[hive-exec-2.1.1-cdh6.1.0.jar:2.1.1-cdh6.1.0]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1414) ~[hive-exec-2.1.1-cdh6.1.0.jar:2.1.1-cdh6.1.0]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1543) ~[hive-exec-2.1.1-cdh6.1.0.jar:2.1.1-cdh6.1.0]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1332) ~[hive-exec-2.1.1-cdh6.1.0.jar:2.1.1-cdh6.1.0]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1321) ~[hive-exec-2.1.1-cdh6.1.0.jar:2.1.1-cdh6.1.0]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at com.webank.wedatasphere.linkis.engineplugin.hive.executor.HiveEngineConnExecutor$$anon$1.run(HiveEngineConnExecutor.scala:152) [linkis-engineplugin-hive-dev-1.0.0.jar:?]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at com.webank.wedatasphere.linkis.engineplugin.hive.executor.HiveEngineConnExecutor$$anon$1.run(HiveEngineConnExecutor.scala:126) [linkis-engineplugin-hive-dev-1.0.0.jar:?]</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><p>Solution: guava package conflict, kill guava-25.1-jre.jar under hive/dist/v1.2.1/lib;</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q14-when-the-hive-engine-is-executed-the-error-is-reported-as-follows-taskexecutionserviceimpl-59-error-orgapachecuratorconnectionconnectionhandlingpolicy"></a>Q14. When the hive engine is executed, the error is reported as follows: TaskExecutionServiceImpl 59 error-org/apache/curator/connection/ConnectionHandlingPolicy:<a class="hash-link" href="#q14-when-the-hive-engine-is-executed-the-error-is-reported-as-follows-taskexecutionserviceimpl-59-error-orgapachecuratorconnectionconnectionhandlingpolicy" title="Direct link to heading">#</a></h4><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI"><pre tabindex="0" class="prism-code language-undefined codeBlock_rtdJ thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#F8F8F2"><span class="token plain">2021-03-16 16:17:40.649 INFO [pool-2-thread-1] com.webank.wedatasphere.linkis.engineplugin.hive.executor.HiveEngineConnExecutor 42 info-com.webank.wedatasphere.linkis.engineplugin.hive. executor.HiveEngineConnExecutor@36a7c96f change status Busy =&gt; Idle.</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">2021-03-16 16:17:40.661 ERROR [pool-2-thread-1] com.webank.wedatasphere.linkis.engineconn.computation.executor.service.TaskExecutionServiceImpl 59 error-org/apache/curator/connection/ConnectionHandlingPolicy java .lang.NoClassDefFoundError: org/apache/curator/connection/ConnectionHandlingPolicy at org.apache.curator.framework.CuratorFrameworkFactory.builder(CuratorFrameworkFactory.java:78) ~[curator-framework-4.0.1.jar:4.0.1]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.hadoop.hive.ql.lockmgr.zookeeper.CuratorFrameworkSingleton.getInstance(CuratorFrameworkSingleton.java:59) ~[hive-exec-2.1.1-cdh6.1.0.jar:2.1.1-cdh6.1.0]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager.setContext(ZooKeeperHiveLockManager.java:98) ~[hive-exec-2.1.1-cdh6.1.0.jar:2.1.1-cdh6.1.0]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.hadoop.hive.ql.lockmgr.DummyTxnManager.getLockManager(DummyTxnManager.java:87) ~[hive-exec-2.1.1-cdh6.1.0.jar:2.1.1-cdh6.1.0]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.hadoop.hive.ql.lockmgr.DummyTxnManager.acquireLocks(DummyTxnManager.java:121) ~[hive-exec-2.1.1-cdh6.1.0.jar:2.1.1-cdh6.1.0]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.hadoop.hive.ql.Driver.acquireLocksAndOpenTxn(Driver.java:1237) ~[hive-exec-2.1.1-cdh6.1.0.jar:2.1.1-cdh6.1.0]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1607) ~[hive-exec-2.1.1-cdh6.1.0.jar:2.1.1-cdh6.1.0]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1332) ~[hive-exec-2.1.1-cdh6.1.0.jar:2.1.1-cdh6.1.0]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1321) ~[hive-exec-2.1.1-cdh6.1.0.jar:2.1.1-cdh6.1.0]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at com.webank.wedatasphere.linkis.engineplugin.hive.executor.HiveEngineConnExecutor$$anon$1.run(HiveEngineConnExecutor.scala:152) ~[linkis-engineplugin-hive-dev-1.0.0.jar:?]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at com.webank.wedatasphere.linkis.engineplugin.hive.executor.HiveEngineConnExecutor$$anon$1.run(HiveEngineConnExecutor.scala:126) ~[linkis-engineplugin-hive-dev-1.0.0.jar:?]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_181]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at javax.security.auth.Subject.doAs(Subject.java:422) ~[?:1.8.0_181]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875) ~[hadoop-common-3.0.0-cdh6.3.2.jar:?]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at com.webank.wedatasphere.linkis.engineplugin.hive.executor.HiveEngineConnExecutor.executeLine(HiveEngineConnExecutor.scala:126) ~[linkis-engineplugin-hive-dev-1.0.0.jar:?]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at com.webank.wedatasphere.linkis.engineconn.computation.executor.execute.ComputationExecutor$$anonfun$execute$1$$anonfun$apply$9$$anonfun$apply$10.apply(ComputationExecutor.scala:145) ~[linkis-computation -engineconn-dev-1.0.0.jar:?]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at com.webank.wedatasphere.linkis.engineconn.computation.executor.execute.ComputationExecutor$$anonfun$execute$1$$anonfun$apply$9$$anonfun$apply$10.apply(ComputationExecutor.scala:144) ~[linkis-computation -engineconn-dev-1.0.0.jar:?]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at com.webank.wedatasphere.linkis.common.utils.Utils$.tryCatch(Utils.scala:48) ~[linkis-common-dev-1.0.0.jar:?]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at com.webank.wedatasphere.linkis.engineconn.computation.executor.execute.ComputationExecutor$$anonfun$execute$1$$anonfun$apply$9.apply(ComputationExecutor.scala:146) ~[linkis-computation-engineconn-dev-1.0 .0.jar:?]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at com.webank.wedatasphere.linkis.engineconn.computation.executor.execute.ComputationExecutor$$anonfun$execute$1$$anonfun$apply$9.apply(ComputationExecutor.scala:140) ~[linkis-computation-engineconn-dev-1.0 .0.jar:?]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at scala.collection.immutable.Range.foreach(Range.scala:160) ~[scala-library-2.11.8.jar:?]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at com.webank.wedatasphere.linkis.engineconn.computation.executor.execute.ComputationExecutor$$anonfun$execute$1.apply(ComputationExecutor.scala:139) ~[linkis-computation-engineconn-dev-1.0.0.jar:? ]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at com.webank.wedatasphere.linkis.engineconn.computation.executor.execute.ComputationExecutor$$anonfun$execute$1.apply(ComputationExecutor.scala:114) ~[linkis-computation-engineconn-dev-1.0.0.jar:? ]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at com.webank.wedatasphere.linkis.common.utils.Utils$.tryFinally(Utils.scala:62) ~[linkis-common-dev-1.0.0.jar:?]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at com.webank.wedatasphere.linkis.engineconn.acessible.executor.entity.AccessibleExecutor.ensureIdle(AccessibleExecutor.scala:42) ~[linkis-accessible-executor-dev-1.0.0.jar:?]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at com.webank.wedatasphere.linkis.engineconn.acessible.executor.entity.AccessibleExecutor.ensureIdle(AccessibleExecutor.scala:36) ~[linkis-accessible-executor-dev-1.0.0.jar:?]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at com.webank.wedatasphere.linkis.engineconn.computation.executor.execute.ComputationExecutor.ensureOp(ComputationExecutor.scala:103) ~[linkis-computation-engineconn-dev-1.0.0.jar:?]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at com.webank.wedatasphere.linkis.engineconn.computation.executor.execute.ComputationExecutor.execute(ComputationExecutor.scala:114) ~[linkis-computation-engineconn-dev-1.0.0.jar:?]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at com.webank.wedatasphere.linkis.engineconn.computation.executor.service.TaskExecutionServiceImpl$$anon$1$$anonfun$run$1.apply$mcV$sp(TaskExecutionServiceImpl.scala:139) [linkis-computation-engineconn-dev- 1.0.0.jar:?]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at com.webank.wedatasphere.linkis.engineconn.computation.executor.service.TaskExecutionServiceImpl$$anon$1$$anonfun$run$1.apply(TaskExecutionServiceImpl.scala:138) [linkis-computation-engineconn-dev-1.0.0. jar:?]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at com.webank.wedatasphere.linkis.engineconn.computation.executor.service.TaskExecutionServiceImpl$$anon$1$$anonfun$run$1.apply(TaskExecutionServiceImpl.scala:138) [linkis-computation-engineconn-dev-1.0.0. jar:?]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at com.webank.wedatasphere.linkis.common.utils.Utils$.tryCatch(Utils.scala:48) [linkis-common-dev-1.0.0.jar:?]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at com.webank.wedatasphere.linkis.common.utils.Utils$.tryAndWarn(Utils.scala:74) [linkis-common-dev-1.0.0.jar:?]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at com.webank.wedatasphere.linkis.engineconn.computation.executor.service.TaskExecutionServiceImpl$$anon$1.run(TaskExecutionServiceImpl.scala:138) [linkis-computation-engineconn-dev-1.0.0.jar:?]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_181]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_181]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_181]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_181]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at java.lang.Thread.run(Thread.java:748) [?:1.8.0_181]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Caused by: java.lang.ClassNotFoundException: org.apache.curator.connection.ConnectionHandlingPolicy atjava.net.URLClassLoader.findClass(URLClassLoader.java:381) ~[?:1.8.0_181]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at java.lang.ClassLoader.loadClass(ClassLoader.java:424) ~[?:1.8.0_181]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349) ~[?:1.8.0_181]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ~[?:1.8.0_181]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">... 39 more</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><p>Solution: The reason is that there is a corresponding relationship between the version of Curator and the version of zookeeper. For Curator2.X, it supports Zookeeper3.4.X for Curator2.X, so if you are currently Zookeeper3.4.X, you should still use Curator2.X, for example: 2.7.0. Reference link: <a href="https://blog.csdn.net/muyingmiao/article/details/100183768" target="_blank" rel="noopener noreferrer">https://blog.csdn.net/muyingmiao/article/details/100183768</a></p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q15-when-the-python-engine-is-scheduled-the-following-error-is-reported-python-proces-is-not-alive"></a>Q15. When the python engine is scheduled, the following error is reported: Python proces is not alive:<a class="hash-link" href="#q15-when-the-python-engine-is-scheduled-the-following-error-is-reported-python-proces-is-not-alive" title="Direct link to heading">#</a></h4><p><img alt="linkis-exception-08.png" src="/assets/images/linkis-exception-08-b615151d4fc8aab21d01bb3bb17ae685.png"></p><p>Solution: The server installed the anaconda3 package manager. After debugging python, two problems were found: (1) lack of pandas and matplotlib modules, which need to be installed manually; (2) when the new version of the python engine is executed, it depends on the higher version of python, first install python3, Next, make a symbolic link (as shown in the figure below) and restart the engineplugin service.</p><p><img alt="shell-error-02.png" src="/assets/images/shell-error-02-7a0828687b976e93aeda516f0d11b8cf.png"></p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q16-when-the-spark-engine-is-executed-the-following-error-noclassdeffounderror-orgapachehadoophiveqlioorcorcfile-is-reported"></a>Q16. When the spark engine is executed, the following error NoClassDefFoundError: org/apache/hadoop/hive/ql/io/orc/OrcFile is reported:<a class="hash-link" href="#q16-when-the-spark-engine-is-executed-the-following-error-noclassdeffounderror-orgapachehadoophiveqlioorcorcfile-is-reported" title="Direct link to heading">#</a></h4><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI"><pre tabindex="0" class="prism-code language-undefined codeBlock_rtdJ thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#F8F8F2"><span class="token plain">2021-03-19 15:12:49.227 INFO [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler 57 logInfo -ShuffleMapStage 5 (show at &lt;console&gt;:69) failed in 21.269 s due to Job aborted due to stage failure: Task 1 in stage 5.0 failed 4 times, most recent failure: Lost task 1.3 in stage 5.0 (TID 139, cdh03, executor 6): java.lang.NoClassDefFoundError: org/apache/hadoop/hive/ql /io/orc/OrcFile</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.spark.sql.hive.orc.OrcFileOperator$$anonfun$getFileReader$2.apply(OrcFileOperator.scala:75)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.spark.sql.hive.orc.OrcFileOperator$$anonfun$getFileReader$2.apply(OrcFileOperator.scala:73)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at scala.collection.TraversableOnce$class.collectFirst(TraversableOnce.scala:145)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at scala.collection.AbstractIterator.collectFirst(Iterator.scala:1334)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.spark.sql.hive.orc.OrcFileOperator$.getFileReader(OrcFileOperator.scala:90)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.spark.sql.hive.orc.OrcFileOperator$$anonfun$readSchema$2.apply(OrcFileOperator.scala:99)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.spark.sql.hive.orc.OrcFileOperator$$anonfun$readSchema$2.apply(OrcFileOperator.scala:99)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at scala.collection.TraversableOnce$class.collectFirst(TraversableOnce.scala:145)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at scala.collection.AbstractIterator.collectFirst(Iterator.scala:1334)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.spark.sql.hive.orc.OrcFileOperator$.readSchema(OrcFileOperator.scala:99)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.spark.sql.hive.orc.OrcFileFormat$$anonfun$buildReader$2.apply(OrcFileFormat.scala:160)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.spark.sql.hive.orc.OrcFileFormat$$anonfun$buildReader$2.apply(OrcFileFormat.scala:151)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.spark.sql.execution.datasources.FileFormat$$anon$1.apply(FileFormat.scala:148)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.spark.sql.execution.datasources.FileFormat$$anon$1.apply(FileFormat.scala:132)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:126)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:179)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:103)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(UnknownSource)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:624)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.spark.scheduler.Task.run(Task.scala:121)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.spark.executor.Executor$TaskRunner$$anonfun$11.apply(Executor.scala:407)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1408)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:413)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at java.lang.Thread.run(Thread.java:748)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.io.orc.OrcFile</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at java.net.URLClassLoader.findClass(URLClassLoader.java:381)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at java.lang.ClassLoader.loadClass(ClassLoader.java:424)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at java.lang.ClassLoader.loadClass(ClassLoader.java:357)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">... 33 more</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><p>Solution: cdh6.3.2 cluster spark engine classpath only has /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/spark/jars, need to add hive-exec-2.1.1- cdh6.1.0.jar, then restart spark.</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q17-when-the-spark-engine-starts-it-reports-queue-default-is-not-exists-in-yarn-the-specific-information-is-as-follows"></a>Q17. When the spark engine starts, it reports queue default is not exists in YARN, the specific information is as follows:<a class="hash-link" href="#q17-when-the-spark-engine-starts-it-reports-queue-default-is-not-exists-in-yarn-the-specific-information-is-as-follows" title="Direct link to heading">#</a></h4><p><img alt="linkis-exception-09.png" src="/assets/images/linkis-exception-09-015f3ba93f42edda9be668ee5e570a79.png"></p><p>Solution: When the 1.0 linkis-resource-manager-dev-1.0.0.jar pulls queue information, there is a compatibility problem in parsing json. After the official classmates optimize it, re-provide a new package. The jar package path: /appcom/Install/dss- linkis/linkis/lib/linkis-computation-governance/linkis-cg-linkismanager/.</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q18-when-the-spark-engine-starts-an-error-is-reported-get-the-yarn-queue-information-excepiton-get-the-yarn-queue-information-abnormal-and-http-link-abnormal"></a>Q18, when the spark engine starts, an error is reported get the Yarn queue information excepiton. (get the Yarn queue information abnormal) and http link abnormal<a class="hash-link" href="#q18-when-the-spark-engine-starts-an-error-is-reported-get-the-yarn-queue-information-excepiton-get-the-yarn-queue-information-abnormal-and-http-link-abnormal" title="Direct link to heading">#</a></h4><p>Solution: To migrate the address configuration of yarn to the DB configuration, the following configuration needs to be added:</p><p><img alt="db-config-02.png" src="/assets/images/db-config-02-f13268fb7c543733a5c359d9150963fc.png"></p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q19-when-the-spark-engine-is-scheduled-it-can-be-executed-successfully-for-the-first-time-and-if-executed-again-it-will-report-spark-application-sc-has-already-stopped-please-restart-it-the-specific-errors-are-as-follows"></a>Q19. When the spark engine is scheduled, it can be executed successfully for the first time, and if executed again, it will report Spark application sc has already stopped, please restart it. The specific errors are as follows:<a class="hash-link" href="#q19-when-the-spark-engine-is-scheduled-it-can-be-executed-successfully-for-the-first-time-and-if-executed-again-it-will-report-spark-application-sc-has-already-stopped-please-restart-it-the-specific-errors-are-as-follows" title="Direct link to heading">#</a></h4><p><img alt="page-show-03.png" src="/assets/images/page-show-03-e7a453a712bf9c6b8a580be432de8ab3.png"></p><p>Solution: The background is that the architecture of the linkis1.0 engine has been adjusted. After the spark session is created, in order to avoid overhead and improve execution efficiency, the session is reused. When we execute spark.scala for the first time, there is spark.stop() in our script. This command will cause the newly created session to be closed. When executed again, it will prompt that the session is closed, please restart it. Solution: first remove stop() from all scripts, and then execute the order: execute default.sql first, then execute scalaspark and pythonspark.</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q20-pythonspark-scheduling-execution-error-initialize-python-executor-failed-classnotfoundexception-orgslf4jimplstaticloggerbinder-as-follows"></a>Q20, pythonspark scheduling execution, error: initialize python executor failed ClassNotFoundException org.slf4j.impl.StaticLoggerBinder, as follows:<a class="hash-link" href="#q20-pythonspark-scheduling-execution-error-initialize-python-executor-failed-classnotfoundexception-orgslf4jimplstaticloggerbinder-as-follows" title="Direct link to heading">#</a></h4><p><img alt="linkis-exception-10.png" src="/assets/images/linkis-exception-10-592b3282c47555a50b0abfe3cafaa6cf.png"></p><p>Solution: The reason is that the spark server lacks slf4j-log4j12-1.7.25.jar, copy the above jar and report to /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/spark/jars .</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q21-pythonspark-scheduling-execution-error-initialize-python-executor-failed-submit-version-error-as-follows"></a>Q21, pythonspark scheduling execution, error: initialize python executor failed, submit-version error, as follows:<a class="hash-link" href="#q21-pythonspark-scheduling-execution-error-initialize-python-executor-failed-submit-version-error-as-follows" title="Direct link to heading">#</a></h4><p><img alt="shell-error-03.png" src="/assets/images/shell-error-03-477fba3073827e78efc5a1c3dd76c47a.png"></p><p>Solution: The reason is that the linkis1.0 pythonSpark engine has a bug in obtaining the spark version code. The fix is ​​as follows:</p><p><img alt="code-fix-01.png" src="/assets/images/code-fix-01-d9c67cd0e98241135164e4d6ebb06d1e.png"></p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q22-when-pythonspark-is-scheduled-to-execute-it-reports-typeerror-an-integer-is-required-got-type-bytes-executed-separately-from-the-command-to-pull-up-the-engine-the-details-are-as-follows"></a>Q22. When pythonspark is scheduled to execute, it reports TypeError: an integer is required (got type bytes) (executed separately from the command to pull up the engine), the details are as follows:<a class="hash-link" href="#q22-when-pythonspark-is-scheduled-to-execute-it-reports-typeerror-an-integer-is-required-got-type-bytes-executed-separately-from-the-command-to-pull-up-the-engine-the-details-are-as-follows" title="Direct link to heading">#</a></h4><p><img alt="shell-error-04.png" src="/assets/images/shell-error-04-3a4c1335ed0c7060e3d9ac6bb2aa08c2.png"></p><p>Solution: The reason is that the system spark and python versions are not compatible, python is 3.8, spark is 2.4.0-cdh6.3.2, spark requires python version&lt;=3.6, reduce python to 3.6, comment file /opt/cloudera/parcels/CDH/ The following lines of lib/spark/python/lib/pyspark.zip/pyspark/context.py:</p><p><img alt="shell-error-05.png" src="/assets/images/shell-error-05-44d72941580d17df2297f7a41ef45390.png"></p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q23-spark-engine-is-240cdh632-python-engine-was-previously-lacking-pandas-matplotlib-upgraded-local-python-to-38-but-spark-does-not-support-python38-only-supports-below-36"></a>Q23, spark engine is 2.4.0+cdh6.3.2, python engine was previously lacking pandas, matplotlib upgraded local python to 3.8, but spark does not support python3.8, only supports below 3.6;<a class="hash-link" href="#q23-spark-engine-is-240cdh632-python-engine-was-previously-lacking-pandas-matplotlib-upgraded-local-python-to-38-but-spark-does-not-support-python38-only-supports-below-36" title="Direct link to heading">#</a></h4><p>Solution: reinstall the python package manager anaconda2, reduce python to 2.7, install pandas, matplotlib modules, python engine and spark engine can be scheduled normally.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/apache/incubator-linkis-website/edit/dev/faq/main.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_mS5F" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_mt2f"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><div class="pagination-nav__item"></div><div class="pagination-nav__item pagination-nav__item--next"></div></nav></div></div><div class="col col--3"><div class="tableOfContents_vrFS thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#q1-linkis-startup-error-nosuchmethoderrorgetsessionmanagerlorgeclipsejettyserversessionmanager" class="table-of-contents__link">Q1, linkis startup error: NoSuchMethodErrorgetSessionManager()Lorg/eclipse/jetty/server/SessionManager</a></li><li><a href="#q2-when-starting-the-microservice-linkis-ps-cs-report-debuggclasswriter-overrides-final-method-visit" class="table-of-contents__link">Q2. When starting the microservice linkis-ps-cs, report DebuggClassWriter overrides final method visit</a></li><li><a href="#q3-when-starting-the-microservice-linkis-ps-datasource-jdbcutilsgetdriverclassname-npe" class="table-of-contents__link">Q3. When starting the microservice linkis-ps-datasource, JdbcUtils.getDriverClassName NPE</a></li><li><a href="#q4-when-starting-the-microservice-linkis-ps-datasource-the-following-exception-classnotfoundexception-httpclient-is-reported" class="table-of-contents__link">Q4. When starting the microservice linkis-ps-datasource, the following exception ClassNotFoundException HttpClient is reported:</a></li><li><a href="#q5-click-scriptis-database-no-data-is-returned-the-phenomenon-is-as-follows" class="table-of-contents__link">Q5. Click scriptis-database, no data is returned, the phenomenon is as follows:</a></li><li><a href="#q6-shell-engine-scheduling-execution-the-page-reports-insufficient-resource-requesting-available-engine-timeout-eneningeconnmanager-linkisout-and-the-following-error-is-reported" class="table-of-contents__link">Q6, shell engine scheduling execution, the page reports Insufficient resource, requesting available engine timeout, eneningeconnmanager linkis.out, and the following error is reported:</a></li><li><a href="#q7-when-the-shell-engine-is-scheduled-for-execution-the-engine-execution-directory-reports-the-following-error-binjava-no-such-file-or-directory" class="table-of-contents__link">Q7. When the shell engine is scheduled for execution, the engine execution directory reports the following error /bin/java: No such file or directory:</a></li><li><a href="#q8-hive-engine-scheduling-the-following-error-is-reported-engineconnpluginnotfoundexceptionerrorcode70063" class="table-of-contents__link">Q8, hive engine scheduling, the following error is reported EngineConnPluginNotFoundException:errorCode:70063</a></li><li><a href="#q9-after-the-linkis-microservice-is-started-the-following-error-is-reported-load-balancer-does-not-have-available-server-for-client" class="table-of-contents__link">Q9. After the linkis microservice is started, the following error is reported: Load balancer does not have available server for client:</a></li><li><a href="#q10-when-the-hive-engine-is-scheduled-for-execution-the-following-error-is-reported-operation-failed-nullpointerexception" class="table-of-contents__link">Q10. When the hive engine is scheduled for execution, the following error is reported: operation failed NullPointerException:</a></li><li><a href="#q11-when-hive-engine-is-scheduled-the-error-log-of-engineconnmanager-is-as-follows-method-did-not-exist-sessionhandler" class="table-of-contents__link">Q11. When hive engine is scheduled, the error log of engineConnManager is as follows method did not exist: SessionHandler:</a></li><li><a href="#after-q12-hive-engine-restarts-the-jar-package-of-jetty-94-is-always-replaced-by-93" class="table-of-contents__link">After Q12, hive engine restarts, the jar package of jetty 9.4 is always replaced by 9.3</a></li><li><a href="#q13-when-the-hive-engine-is-executed-the-following-error-is-reported-lcomgooglecommoncollectunmodifiableiterator" class="table-of-contents__link">Q13. When the hive engine is executed, the following error is reported: Lcom/google/common/collect/UnmodifiableIterator:</a></li><li><a href="#q14-when-the-hive-engine-is-executed-the-error-is-reported-as-follows-taskexecutionserviceimpl-59-error-orgapachecuratorconnectionconnectionhandlingpolicy" class="table-of-contents__link">Q14. When the hive engine is executed, the error is reported as follows: TaskExecutionServiceImpl 59 error-org/apache/curator/connection/ConnectionHandlingPolicy:</a></li><li><a href="#q15-when-the-python-engine-is-scheduled-the-following-error-is-reported-python-proces-is-not-alive" class="table-of-contents__link">Q15. When the python engine is scheduled, the following error is reported: Python proces is not alive:</a></li><li><a href="#q16-when-the-spark-engine-is-executed-the-following-error-noclassdeffounderror-orgapachehadoophiveqlioorcorcfile-is-reported" class="table-of-contents__link">Q16. When the spark engine is executed, the following error NoClassDefFoundError: org/apache/hadoop/hive/ql/io/orc/OrcFile is reported:</a></li><li><a href="#q17-when-the-spark-engine-starts-it-reports-queue-default-is-not-exists-in-yarn-the-specific-information-is-as-follows" class="table-of-contents__link">Q17. When the spark engine starts, it reports queue default is not exists in YARN, the specific information is as follows:</a></li><li><a href="#q18-when-the-spark-engine-starts-an-error-is-reported-get-the-yarn-queue-information-excepiton-get-the-yarn-queue-information-abnormal-and-http-link-abnormal" class="table-of-contents__link">Q18, when the spark engine starts, an error is reported get the Yarn queue information excepiton. (get the Yarn queue information abnormal) and http link abnormal</a></li><li><a href="#q19-when-the-spark-engine-is-scheduled-it-can-be-executed-successfully-for-the-first-time-and-if-executed-again-it-will-report-spark-application-sc-has-already-stopped-please-restart-it-the-specific-errors-are-as-follows" class="table-of-contents__link">Q19. When the spark engine is scheduled, it can be executed successfully for the first time, and if executed again, it will report Spark application sc has already stopped, please restart it. The specific errors are as follows:</a></li><li><a href="#q20-pythonspark-scheduling-execution-error-initialize-python-executor-failed-classnotfoundexception-orgslf4jimplstaticloggerbinder-as-follows" class="table-of-contents__link">Q20, pythonspark scheduling execution, error: initialize python executor failed ClassNotFoundException org.slf4j.impl.StaticLoggerBinder, as follows:</a></li><li><a href="#q21-pythonspark-scheduling-execution-error-initialize-python-executor-failed-submit-version-error-as-follows" class="table-of-contents__link">Q21, pythonspark scheduling execution, error: initialize python executor failed, submit-version error, as follows:</a></li><li><a href="#q22-when-pythonspark-is-scheduled-to-execute-it-reports-typeerror-an-integer-is-required-got-type-bytes-executed-separately-from-the-command-to-pull-up-the-engine-the-details-are-as-follows" class="table-of-contents__link">Q22. When pythonspark is scheduled to execute, it reports TypeError: an integer is required (got type bytes) (executed separately from the command to pull up the engine), the details are as follows:</a></li><li><a href="#q23-spark-engine-is-240cdh632-python-engine-was-previously-lacking-pandas-matplotlib-upgraded-local-python-to-38-but-spark-does-not-support-python38-only-supports-below-36" class="table-of-contents__link">Q23, spark engine is 2.4.0+cdh6.3.2, python engine was previously lacking pandas, matplotlib upgraded local python to 3.8, but spark does not support python3.8, only supports below 3.6;</a></li></ul></div></div></div></div></main></div></div><footer class="footer"><div class="container"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Linkis</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/docs/latest/introduction">Document</a></li><li class="footer__item"><a class="footer__link-item" href="/faq/main">FAQ</a></li><li class="footer__item"><a href="https://github.com/apache/incubator-linkis/releases" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Releases<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items"><li class="footer__item"><a href="https://github.com/apache/incubator-linkis" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://github.com/apache/incubator-linkis/issues" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Issue Tracker<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://github.com/apache/incubator-linkis/pulls" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Pull Requests<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><div class="col footer__col"><div class="footer__title">Subscribe Mailing List</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/community/how-to-subscribe">How to Subscribe</a></li><li class="footer__item"><a href="mailto:dev-subscribe@linkis.apache.org" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Subscribe Mail<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://lists.apache.org/list.html?dev@linkis.apache.org" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Mail Archive<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright"><div><img style="height:50px" alt="Apache Software Foundation" src="/img/incubator-logo.svg"><p style="color: #999999;  padding: 0 20px 30px;font-weight:400;text-align:left">Apache Linkis is an effort undergoing incubation at The Apache Software Foundation (ASF), sponsored by the Apache Incubator. Incubation is required of all newly accepted projects until a further review indicates that the infrastructure, communications, and decision making process have stabilized in a manner consistent with other successful ASF projects. While incubation status is not necessarily a reflection of the completeness or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF.</p><p></p>
             <p style="padding: 0 20px 30px;color: #999999;font-weight: 400;"> Copyright © 2022 The Apache Software Foundation. Licensed under the Apache License, Version 2.0. Apache Linkis, Apache Incubator, Apache, the Apache feather logo, the Apache Linkis logo and the Apache Incubator project logo are trademarks of The Apache Software Foundation.</p>
             <div></div></div></div></div></div></footer></div>
<script src="/assets/js/runtime~main.4a9f2810.js"></script>
<script src="/assets/js/main.959844b8.js"></script>
</body>
</html>