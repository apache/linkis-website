<!doctype html>
<html class="docs-version-current" lang="zh-CN" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.14">
<link rel="alternate" type="application/rss+xml" href="/zh-CN/blog/rss.xml" title="Apache Linkis Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/zh-CN/blog/atom.xml" title="Apache Linkis Blog Atom Feed">
<link rel="search" type="application/opensearchdescription+xml" title="Apache Linkis" href="/zh-CN/opensearch.xml"><title data-react-helmet="true">Q&amp;A | Apache Linkis</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://linkis.incubator.apache.org/zh-CN/faq/main"><meta data-react-helmet="true" name="docsearch:language" content="zh-CN"><meta data-react-helmet="true" name="docsearch:version" content="current"><meta data-react-helmet="true" name="docsearch:docusaurus_tag" content="docs-faq-current"><meta data-react-helmet="true" property="og:title" content="Q&amp;A | Apache Linkis"><meta data-react-helmet="true" name="description" content="Linkis1.0常见问题和解决办法：https://docs.qq.com/doc/DWlN4emlJeEJxWlR0"><meta data-react-helmet="true" property="og:description" content="Linkis1.0常见问题和解决办法：https://docs.qq.com/doc/DWlN4emlJeEJxWlR0"><link data-react-helmet="true" rel="shortcut icon" href="/zh-CN/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://linkis.incubator.apache.org/zh-CN/faq/main"><link data-react-helmet="true" rel="alternate" href="https://linkis.incubator.apache.org/faq/main" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://linkis.incubator.apache.org/zh-CN/faq/main" hreflang="zh-CN"><link data-react-helmet="true" rel="alternate" href="https://linkis.incubator.apache.org/faq/main" hreflang="x-default"><link data-react-helmet="true" rel="preconnect" href="https://AE29KQB3IA-dsn.algolia.net" crossorigin="anonymous"><link rel="stylesheet" href="/zh-CN/assets/css/styles.91a78464.css">
<link rel="preload" href="/zh-CN/assets/js/runtime~main.9262477f.js" as="script">
<link rel="preload" href="/zh-CN/assets/js/main.a77b6c29.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div><a href="#" class="skipToContent_OuoZ">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/zh-CN/"><img src="/zh-CN/img/logo.png" alt="Apache Linkis Logo" class="themedImage_TMUO themedImage--light_4Vu1 navbar__logo"><img src="/zh-CN/img/logo.png" alt="Apache Linkis Logo" class="themedImage_TMUO themedImage--dark_uzRr navbar__logo"><b class="navbar__title">Apache Linkis(Incubating)</b></a><a class="navbar__item navbar__link" href="/zh-CN/">首页</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/zh-CN/faq/main">FAQ</a><a class="navbar__item navbar__link" href="/zh-CN/download/main">下载</a><a class="navbar__item navbar__link" href="/zh-CN/community/how-to-subscribe">社区</a><a class="navbar__item navbar__link" href="/zh-CN/blog">博客</a><a class="navbar__item navbar__link" href="/zh-CN/team">团队</a><a class="navbar__item navbar__link" href="/zh-CN/user">用户</a><div class="navbar__item dropdown dropdown--hoverable"><a class="navbar__link">Apache</a><ul class="dropdown__menu"><li><a href="https://www.apache.org/" target="_blank" rel="noopener noreferrer" class="dropdown__link">基金会</a></li><li><a href="https://www.apache.org/licenses/" target="_blank" rel="noopener noreferrer" class="dropdown__link">证书</a></li><li><a href="https://www.apache.org/events/current-event" target="_blank" rel="noopener noreferrer" class="dropdown__link">事件</a></li><li><a href="https://www.apache.org/security/" target="_blank" rel="noopener noreferrer" class="dropdown__link">安全</a></li><li><a href="https://www.apache.org/foundation/sponsorship.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">赞助</a></li><li><a href="https://www.apache.org/foundation/policies/privacy.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">Privacy</a></li><li><a href="https://www.apache.org/foundation/thanks.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">致谢</a></li></ul></div></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a class="navbar__link" href="/zh-CN/docs/latest/introduction">1.1.1</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/zh-CN/docs/1.1.2/introduction">Next</a></li><li><a class="dropdown__link" href="/zh-CN/docs/latest/introduction">1.1.1</a></li><li><a class="dropdown__link" href="/zh-CN/docs/1.1.0/introduction">1.1.0</a></li><li><a class="dropdown__link" href="/zh-CN/docs/1.0.3/introduction">1.0.3</a></li><li><a class="dropdown__link" href="/zh-CN/docs/1.0.2/introduction">1.0.2</a></li><li><a class="dropdown__link" href="/zh-CN/docs/0.11.0/introduction">0.11.0</a></li><li><a class="dropdown__link" href="/zh-CN/versions">All versions</a></li></ul></div><a href="https://github.com/apache/incubator-linkis" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub"></a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" class="navbar__link"><span><svg t="1631348384596" class="iconLanguage_EbrZ" viewBox="0 0 1024 1024" version="1.1" p-id="557" width="20" height="20"><path d="M547.797333 638.208l-104.405333-103.168 1.237333-1.28a720.170667 720.170667 0 0 0 152.490667-268.373333h120.448V183.082667h-287.744V100.906667H347.605333v82.218666H59.818667V265.386667h459.178666a648.234667 648.234667 0 0 1-130.304 219.946666 643.242667 643.242667 0 0 1-94.976-137.728H211.541333a722.048 722.048 0 0 0 122.453334 187.434667l-209.194667 206.378667 58.368 58.368 205.525333-205.525334 127.872 127.829334 31.232-83.84m231.424-208.426667h-82.218666l-184.96 493.312h82.218666l46.037334-123.306667h195.242666l46.464 123.306667h82.218667l-185.002667-493.312m-107.690666 287.744l66.56-178.005333 66.602666 178.005333z" fill="currentColor" p-id="558"></path></svg><span>简体中文</span></span></a><ul class="dropdown__menu"><li><a href="/faq/main" target="_self" rel="noopener noreferrer" class="dropdown__link" style="text-transform:capitalize">English</a></li><li><a href="/zh-CN/faq/main" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" style="text-transform:capitalize">简体中文</a></li></ul></div><div class="searchBox_Bc3W"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper docs-wrapper docs-doc-page"><div class="docPage_lDyR"><button class="clean-btn backToTopButton_i9tI" type="button"><svg viewBox="0 0 24 24" width="28"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z" fill="currentColor"></path></svg></button><aside class="docSidebarContainer_0YBq"><div class="sidebar_a3j0"><nav class="menu thin-scrollbar menu_cyFh menuWithAnnouncementBar_+O1J"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link menu__link--active" aria-current="page" href="/zh-CN/faq/main">Q&amp;A</a></li></ul></nav></div></aside><main class="docMainContainer_r8cw"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_zHA2"><div class="docItemContainer_oiyr"><article><div class="tocCollapsible_aw-L theme-doc-toc-mobile tocMobile_Tx6Y"><button type="button" class="clean-btn tocCollapsibleButton_zr6a">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Q&amp;A</h1></header><blockquote><p>Linkis1.0常见问题和解决办法：<a href="https://docs.qq.com/doc/DWlN4emlJeEJxWlR0" target="_blank" rel="noopener noreferrer">https://docs.qq.com/doc/DWlN4emlJeEJxWlR0</a></p></blockquote><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q1-linkis的ps-cs服务日志报这个错-figservletwebserverapplicationcontext-559"></a>Q1: linkis的ps-cs服务日志报这个错： figServletWebServerApplicationContext (559)<a class="hash-link" href="#q1-linkis的ps-cs服务日志报这个错-figservletwebserverapplicationcontext-559" title="Direct link to heading">#</a></h4><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI"><pre tabindex="0" class="prism-code language-undefined codeBlock_rtdJ thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#F8F8F2"><span class="token plain">[refresh] - Exception encountered during context initi</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">alization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name &#x27;eurekaInstanceLabelClient&#x27;: Invocation of initkaba method failed; nested exception is java.lang.RuntimeException: com.netflix.client.ClientException: Load balancer does not have available server for client: linkis-ps-publicservice</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><p>A:这个是因为publicservice服务没有启动成功导致，建议手动重启下publicservice sh/sbin/linkis-dameo.sh restart ps-publicservice</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q2--linkis-eureka调试说明"></a>Q2:  Linkis-eureka调试说明<a class="hash-link" href="#q2--linkis-eureka调试说明" title="Direct link to heading">#</a></h4><p>A:  如需要调试eureka程序，需要先进行一些配置，如下图
application-eureka.yml需要去掉部分注释配置，正常启动配置如下图：
<img alt="1639466558031" src="/zh-CN/assets/images/q2_1-697a210422acb1835076820356a56df5.png"></p><p><img alt="1639466558031" src="/zh-CN/assets/images/q2_2-0b84185f007116f30800e4c4f5639004.png"></p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q3-eureka-第一次启动-自动停止需要手工重新启动的问题"></a>Q3: eureka 第一次启动 自动停止，需要手工重新启动的问题<a class="hash-link" href="#q3-eureka-第一次启动-自动停止需要手工重新启动的问题" title="Direct link to heading">#</a></h4><p>A: 这个是因为eureka的启动Java进程时没有使用nohup当会话退出后，被操作系统自动清理了任务，需要修改下eureka的启动脚本，加上nohup：</p><p><img src="/zh-CN/assets/images/q3_1-d1ab012f4d757efb95241370f4e2e3e1.png"></p><p>可以参考PR：<a href="https://github.com/apache/incubator-linkis/pull/837/files" target="_blank" rel="noopener noreferrer">https://github.com/apache/incubator-linkis/pull/837/files</a></p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q4-linkis-entrance-logwriter-缺依赖包"></a>Q4: Linkis Entrance LogWriter 缺依赖包<a class="hash-link" href="#q4-linkis-entrance-logwriter-缺依赖包" title="Direct link to heading">#</a></h4><p>A: Hadoop 3需修改linkis-hadoop-common pom文件，详见：<a href="https://linkis.apache.org/zh-CN/docs/next/development/linkis_compile_and_package/" target="_blank" rel="noopener noreferrer">https://linkis.apache.org/zh-CN/docs/next/development/linkis_compile_and_package/</a></p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q5-linkis10-执行任务报-select-list-is-not-in--group-by-clause"></a>Q5: Linkis1.0 执行任务报： select list is not in  group by clause<a class="hash-link" href="#q5-linkis10-执行任务报-select-list-is-not-in--group-by-clause" title="Direct link to heading">#</a></h4><p><img alt="1639466558031" src="/zh-CN/assets/images/q5_1-0ee7a3e215d17b5032fba9039eaf41f9.jpg"></p><p><img alt="1639466558031" src="/zh-CN/assets/images/q5_2-7c44e577054f2a65c49d197babf7a702.png"></p><p>这个问题是在mysql 5.8版本时，由于全局设置的模式默认值导致，需要在mysql cli里面执行下这行就行：</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI"><pre tabindex="0" class="prism-code language-undefined codeBlock_rtdJ thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#F8F8F2"><span class="token plain">SET GLOBAL sql_mode=(SELECT REPLACE(@@sql_mode,&#x27;ONLY_FULL_GROUP_BY&#x27;,&#x27;&#x27;));</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q6-部署后执行脚执行命令收集结果时遇到这样的报错ioexception-file-header-type-must-be-dolphin"></a>Q6: 部署后执行脚，执行命令，收集结果时，遇到这样的报错，IOException: File header type must be dolphin:<a class="hash-link" href="#q6-部署后执行脚执行命令收集结果时遇到这样的报错ioexception-file-header-type-must-be-dolphin" title="Direct link to heading">#</a></h4><p>A:这个应该是重复安装导致的，导致结果集写到同一个文件里面了，之前的Linkis 0.X 版本采用的结果集写是append，1.0已经修改为新增了，可以清理下结果集的目录：配置参数为wds.linkis.resultSet.store.path，可以清理下这个目录</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q7-script-左侧数据库刷不出来"></a>Q7: Script 左侧数据库刷不出来<a class="hash-link" href="#q7-script-左侧数据库刷不出来" title="Direct link to heading">#</a></h4><p>解决方案:
a.	原因可能是linkis-metatdata服务没有读取到HIVE_CONF_DIR的错误，可以通过配置linkis-metadata的参数：对应为元数据库的JDBC连接串</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI"><pre tabindex="0" class="prism-code language-undefined codeBlock_rtdJ thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#F8F8F2"><span class="token plain">hive.meta.url=</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">hive.meta.user=</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">hive.meta.password=</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q8scriptis的右侧刷不出来数据库一直在刷新中需要注意的是linkis的metadata暂时不支持对接sentry和ranger只支持hive原生的权限控制错误信息-前端数据库tab一直处于刷新状态"></a>Q8.Scriptis的右侧刷不出来数据库，一直在刷新中（需要注意的是linkis的metadata暂时不支持对接sentry和Ranger只支持hive原生的权限控制），错误信息: 前端数据库tab一直处于刷新状态<a class="hash-link" href="#q8scriptis的右侧刷不出来数据库一直在刷新中需要注意的是linkis的metadata暂时不支持对接sentry和ranger只支持hive原生的权限控制错误信息-前端数据库tab一直处于刷新状态" title="Direct link to heading">#</a></h4><p>解决方案:
这是因为右侧的数据库我们是限制了权限的，而这个依赖hive开启授权访问：</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI"><pre tabindex="0" class="prism-code language-undefined codeBlock_rtdJ thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#F8F8F2"><span class="token plain">hive.security.authorization.enabled=true; </span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><p>具体可以参考：<a href="https://blog.csdn.net/yancychas/article/details/84202400" target="_blank" rel="noopener noreferrer">https://blog.csdn.net/yancychas/article/details/84202400</a>
开启如果配置了该参数还没有的话，那就需要给这个用户授予相应的库表权限，执行grant语句，可以参考相同的链接授权部分。</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI"><pre tabindex="0" class="prism-code language-undefined codeBlock_rtdJ thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#F8F8F2"><span class="token plain"># 授权参考以hadoop为例:</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># 进入hive client 查看hadoop用户数据库授权情况：</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">show grant user hadoop on database default;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># 给用户数据库授权情况：</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">grant all on database default to user hadoop;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><p>如果不想开启权限控制，即每个用户都可以看到库表，可以修改：com/webank/wedatasphere/linkis/metadata/hive/dao/impl/HiveMetaDao.xml的sql去掉权限控制部分</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q9-scriptis工作空间-登录scriptis时报根目录不存在存在工作空间和hdfs两个跟目录错误信息-在登录进入后前端弹出如下信息用户本地目录不存在请联系管理员添加"></a>Q9. <!-- -->[<!-- -->Scriptis]<!-- -->[工作空间]<!-- --> 登录Scriptis时报根目录不存在，存在工作空间和HDFS两个跟目录:错误信息: 在登录进入后，前端弹出如下信息(用户本地目录不存在，请联系管理员添加)<a class="hash-link" href="#q9-scriptis工作空间-登录scriptis时报根目录不存在存在工作空间和hdfs两个跟目录错误信息-在登录进入后前端弹出如下信息用户本地目录不存在请联系管理员添加" title="Direct link to heading">#</a></h4><p>解决方案:</p><ul><li>a.确认linkis-ps-publicservice的conf目录下linkis.properties参数：wds.linkis.workspace.filesystem.localuserrootpath=file:///tmp/linkis/ 是不是file://开头。</li><li>b.确认wds.linkis.workspace.filesystem.hdfsuserrootpath.prefix=hdfs:///tmp/linkis/ 是不是hdfs://开头</li><li>c.确认/tmp/linkis目录下是不是有用户目录，这里的用户是指前端登录用户，比如hadoop用户登录，那么要建立：/tmp/linkis/hadoop目录，如果目录存在确认目录权限登录用户可以操作，如果还是不行可以参考publicservice的报错，错误会说明权限还是路径问题</li></ul><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q10管理台设置怎么调整任务使用的yarn队列错误信息-执行sql任务时报1获取yarn队列信息异常-或者-用户xx不能提交到队列"></a>Q10.<!-- -->[<!-- -->管理台]<!-- -->[设置]<!-- -->怎么调整任务使用的yarn队列?错误信息: 执行sql任务时报1.获取Yarn队列信息异常 或者 用户XX不能提交到队列<a class="hash-link" href="#q10管理台设置怎么调整任务使用的yarn队列错误信息-执行sql任务时报1获取yarn队列信息异常-或者-用户xx不能提交到队列" title="Direct link to heading">#</a></h4><p>解决方案:
在前端—管理台—设置—通用设置—Yarn队列 配置登录用户有权限的队列</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q11hive查询的时候报找不到zk相关的类比如orgapachecurator错误信息-执行hive任务时日志报找不到orgapachecurator开头的类classnotfound"></a>Q11.Hive查询的时候报：找不到zk相关的类比如：org.apache.curator.<em>,错误信息: 执行hive任务时，日志报找不到org.apache.curator.</em>开头的类，classNotFound<a class="hash-link" href="#q11hive查询的时候报找不到zk相关的类比如orgapachecurator错误信息-执行hive任务时日志报找不到orgapachecurator开头的类classnotfound" title="Direct link to heading">#</a></h4><p>解决方案:
这是因为开启了hive事务，可以在linkis的机器上面修改hive-site.xml关掉事务配置，参考hive事务：<a href="https://www.jianshu.com/p/aa0f0fdd234c" target="_blank" rel="noopener noreferrer">https://www.jianshu.com/p/aa0f0fdd234c</a>
或者将相关包放到引擎插件目录中lib/linkis-engineplugins/hive/dist/version/lib</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q12linkis如何支持kerberos"></a>Q12.Linkis如何支持kerberos<a class="hash-link" href="#q12linkis如何支持kerberos" title="Direct link to heading">#</a></h4><p>解决方案：
在linkis中获取Hadoop的FileSystem都是通过HDFSUtils类进行实现的，所以我们将kerberos放在该类，用户可以看下该类的逻辑，现在支持的登录模式如下：</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI"><pre tabindex="0" class="prism-code language-undefined codeBlock_rtdJ thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#F8F8F2"><span class="token plain">if(KERBEROS_ENABLE.getValue) {</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      val path = new File(</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      TAB_FILE.getValue ， userName + &quot;.keytab&quot;).getPath</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      val user = getKerberosUser(userName)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      UserGroupInformation.setConfiguration(getConfiguration(userName))</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      UserGroupInformation.loginUserFromKeytabAndReturnUGI(user， path)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    } else {</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      UserGroupInformation.createRemoteUser(userName)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><p>用户只要在配置文linkis.properties配置以下参数即可：</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI"><pre tabindex="0" class="prism-code language-undefined codeBlock_rtdJ thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#F8F8F2"><span class="token plain">wds.linkis.keytab.enable=true</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">wds.linkis.keytab.file=/appcom/keytab/ #keytab放置目录，该目录存储的是多个用户的username.keytab的文件</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">wds.linkis.keytab.host.enabled=false #是否带上principle客户端认证</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">wds.linkis.keytab.host=127.0.0.1 #principle认证需要带上的客户端IP</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q13关于linkis除了支持部署用户登录可以配置其他用户登录吗"></a>Q13.关于Linkis除了支持部署用户登录可以配置其他用户登录吗?<a class="hash-link" href="#q13关于linkis除了支持部署用户登录可以配置其他用户登录吗" title="Direct link to heading">#</a></h4><p>解决方案：
当然可以。部署用户只是为了方便使用的用户。linkis-mg-gateway支持通过配置LDAP服务和SSO服务进行访问，本身没有用户校验体系，比如要开启LDAP服务访问，你只要在配置linkis-mg-gateway.properties您的LDAP服务端的配置如下：</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI"><pre tabindex="0" class="prism-code language-undefined codeBlock_rtdJ thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#F8F8F2"><span class="token plain">wds.linkis.ldap.proxy.url=ldap://127.0.0.1:389/#您的LDAP服务URL</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">wds.linkis.ldap.proxy.baseDN=dc=webank，dc=com#您的LDAP服务的配置</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><p>用户如果需要执行任务，还需在linux服务器上面建立相应用户名的用户，如果是标准版本该用户需要能执行Spark和hive任务，并需要在本地工作空间和HDFS目录/tmp/linkis建立对应的用户名目录。</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q14-spark版本不一致导致的json4s包冲突问题报错如下错误信息caused-by-javalangnosuchmethoderror-orgjson4sjacksonjsonmethod"></a>Q14. Spark版本不一致导致的json4s包冲突问题，报错如下：错误信息:caused by: java.lang.NoSuchMethodError: org.json4s.jackson.jsonMethod$<a class="hash-link" href="#q14-spark版本不一致导致的json4s包冲突问题报错如下错误信息caused-by-javalangnosuchmethoderror-orgjson4sjacksonjsonmethod" title="Direct link to heading">#</a></h4><p>解决方案:
这个是因为Spark jars的json4s和lib/linkis-engineplugins/spark/dist/version/lib
包里面的json4s版本不一致，官方发布release时会在后面注明Spark的支持版本，如果不一致会存在该问题。
解决办法将Spark jars里面的json4s的包替换掉lib/linkis-engineplugins/spark/dist/version/lib
包里面的json4s版本。另外netty包也可能存在冲突，可按Json4s的方法进行处理.然后重启ecp服务即可：sh sbin/linkis-damon.sh restart cg-engineplugin</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q15linkis管理台管理员页面ecm和微服务管理怎么-开启"></a>Q15.Linkis管理台，管理员页面ECM和微服务管理怎么 开启？<a class="hash-link" href="#q15linkis管理台管理员页面ecm和微服务管理怎么-开启" title="Direct link to heading">#</a></h4><p><img src="/zh-CN/assets/images/q15_1-7df6cf4928b02cb4cf2335fabbdaa193.png"></p><p>解决方案：需要在conf/linkis.properties文件里面设置管理员：</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI"><pre tabindex="0" class="prism-code language-undefined codeBlock_rtdJ thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#F8F8F2"><span class="token plain">wds.linkis.governance.station.admin=hadoop,peacewong</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><p>设置完成后，重启下publicservice服务即可</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q16linkis10执行任务时ecp服务抛出如下错误caused-by-javautilnosuchelementexception-noneget"></a>Q.16Linkis1.0执行任务时，ECP服务抛出如下错误:Caused by: java.util.NoSuchElementException: None.get？<a class="hash-link" href="#q16linkis10执行任务时ecp服务抛出如下错误caused-by-javautilnosuchelementexception-noneget" title="Direct link to heading">#</a></h4><p>错误详细日志：</p><p>解决办法：
这个时因为对应引擎版本物料没有在数据库表中存在对应的记录，可能时ecp服务启动的时候有误导致，您可以重启下ecp服务，看是否在上传BML的时候存在错误，对应的表为：linkis_cg_engine_conn_plugin_bml_resources</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q17linkis1x提示资源不足的通用排查方法"></a>Q17.Linkis1.X提示资源不足的通用排查方法<a class="hash-link" href="#q17linkis1x提示资源不足的通用排查方法" title="Direct link to heading">#</a></h4><p>资源不足分为两种情况：</p><ol><li>服务器本身的资源不足 </li><li>用户自身的资源不足(linkis会对用户资源进行管控)。
这两种资源在linkis1.X中都记录在linkis_cg_manager_label_resource和linkis_cg_manager_linkis_resource中，前者为label和resource的关联表，后者为resource表
通常情况下，linkis1.0对资源的高并发管控是安全的，不建议通过修改表记录的方式去强行重置用户资源记录。但是由于安装调试过程中，linkis的执行环境有所不同，所以会出现引擎启动失败，或在引擎启动过程中对微服务的反复重启导致资源没有安全释放，或者监控器没来得及自动清理（有小时级的延迟），就可能会出现资源不足的问题，严重时会导致用户的大部分资源处于上锁状态。因此对于排查资源不足可以参考以下步骤：
a.在管理台确认ECM的剩余资源是否大于引擎的请求资源，如果ECM剩余的资源非常少，那么就会导致请求新的引擎失败，需要手动在ECM中关掉部分闲置的引擎，linkis对引擎也有闲时自动释放的机制，但这个时间默认设置的相对较长。
b.如果ECM资源充足，则必定是用户剩余资源不足以请求新的引擎，首先确定用户的执行任务时产生的label标签，例如用户hadoop在Scriptis上执行spark2.4.3脚本，则在linkis_cg_manager_label表中对应下条记录
我们拿到这条label的id值，在关联表linkis_cg_manager_label_resource中找到对应的resourceId，通过resourceId在linkis_cg_manager_linkis_resource中就能找到对应的label的resource记录，可以检查下这条记录中的剩余资源</li></ol><p>如果这条资源排查判定是异常情况，即不符合实际引擎启动产生的资源。可以进行以下操作恢复：
在确认该label下所有引擎已经关停的情况下，可以将这条资源和关联表linkis_cg_manager_label_resource对应的关联记录直接删除，再次请求时则会自动重置这条资源。
注意：该label所有引擎已经关停在上个例子中是指的hadoop用户在Scriptis上启动的spark2.4.3的引擎已经全部关停，可以在管理台的资源管理中看到该用户启动的所有引擎实例。否则可能还会出现该label的资源记录异常。</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q18linkis1x在cdh5161版本提交spark-sql任务时404的问题排查方法"></a>Q18.Linkis1.X在CDH5.16.1版本提交spark sql任务时，404的问题排查方法<a class="hash-link" href="#q18linkis1x在cdh5161版本提交spark-sql任务时404的问题排查方法" title="Direct link to heading">#</a></h4><p>主要报错信息如下：</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI"><pre tabindex="0" class="prism-code language-undefined codeBlock_rtdJ thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#F8F8F2"><span class="token plain">21304, Task is Failed,errorMsg: errCode: 12003 ,desc: ip:port_x Failed to async get EngineNode FeignException.NotFound: status 404 reading RPCReceiveRemote#receiveAndReply(Message) ,ip: xxxxx ,port: 9104 ,serviceKind: linkis-cg-entrance</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">org.apache.jasper.servlet.JspServlet 89 warn - PWC6117: File &quot;/home/hadoop/dss1.0/tmp/hadoop/workDir/7c3b796f-aadd-46a5-b515-0779e523561a/tmp/jetty-docbase.1802511762054502345.46019/api/rest_j/v1/rpc/receiveAndReply&quot; not found</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><p>以上报错信息主要是由于cdh环境变量中的jar冲突导致的，需要查找org.apache.jasper.servlet.JspServlet这个类所在的jar包，本地cdh的环境变量路径为：/opt/cloudera/parcels/CDH-5.16.1-1.cdh5.16.1.p0.3/jars，删除了该目录下面的对应的jasper-compile-${version}.jar和jsp-${version}.jar这两类jar包，服务不需要重启，即可重新运行spark sql任务，问题解决。</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q20-运行报错缺包matplotlib"></a>Q20 运行报错缺包matplotlib<a class="hash-link" href="#q20-运行报错缺包matplotlib" title="Direct link to heading">#</a></h4><p>标准的python环境，需要安装好anaconda2和anaconda3，并且默认anaconda为anaconda2。这里面包含了常见大多数python库。</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q21linkis启动报错nosuchmethoderrorgetsessionmanagerlorgeclipsejettyserversessionmanager"></a>Q21、linkis启动报错：NoSuchMethodErrorgetSessionManager()Lorg/eclipse/jetty/server/SessionManager<a class="hash-link" href="#q21linkis启动报错nosuchmethoderrorgetsessionmanagerlorgeclipsejettyserversessionmanager" title="Direct link to heading">#</a></h4><p>具体堆栈：</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI"><pre tabindex="0" class="prism-code language-undefined codeBlock_rtdJ thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#F8F8F2"><span class="token plain">startup of context o.s.b.w.e.j.JettyEmbeddedWebAppContext@6c6919ff{application,/,[file:///tmp/jetty-docbase.9102.6375358926927953589/],UNAVAILABLE} java.lang.NoSuchMethodError: org.eclipse.jetty.server.session.SessionHandler.getSessionManager()Lorg/eclipse/jetty/server/SessionManager;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.eclipse.jetty.servlet.ServletContextHandler\$Context.getSessionCookieConfig(ServletContextHandler.java:1415) ~[jetty-servlet-9.3.20.v20170531.jar:9.3.20.v20170531]</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><p>解法：jetty-servlet  和 jetty-security版本需要从9.3.20升级为9.4.20；</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q22启动微服务linkis-ps-cs时报debuggclasswriter-overrides-final-method-visit"></a>Q22、启动微服务linkis-ps-cs时，报DebuggClassWriter overrides final method visit<a class="hash-link" href="#q22启动微服务linkis-ps-cs时报debuggclasswriter-overrides-final-method-visit" title="Direct link to heading">#</a></h4><p>具体异常栈：</p><p>解法:jar包冲突，删除asm-5.0.4. jar;</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q23启动微服务linkis-ps-publicservice时kjdbcutilsgetdriverclassname-npe"></a>Q23、启动微服务linkis-ps-publicservice时，kJdbcUtils.getDriverClassName NPE<a class="hash-link" href="#q23启动微服务linkis-ps-publicservice时kjdbcutilsgetdriverclassname-npe" title="Direct link to heading">#</a></h4><p>具体异常栈：ExternalResourceProvider</p><p><img src="/zh-CN/assets/images/q23_1-9745a8c9c95053318ee900d53cb50771.png"></p><p>解法：linkis-ps-publicservice配置问题导致的，修改linkis.properties hive.meta开头的三个参数：</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q24shell引擎调度执行时引擎执行目录报如下错误binjavano-such-file-or-directory"></a>Q24、shell引擎调度执行时，引擎执行目录报如下错误/bin/java:No such file or directory：<a class="hash-link" href="#q24shell引擎调度执行时引擎执行目录报如下错误binjavano-such-file-or-directory" title="Direct link to heading">#</a></h4><p><img src="/zh-CN/assets/images/q24_1-ba0715c637d27f81c926e66cc6858102.png"></p><p>解法：本地java的环境变量有问题，需要对java命令做下符号链接。</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q25hive引擎调度时报如下错误engineconnpluginnotfoundexceptionerrorcode70063"></a>Q25、hive引擎调度时，报如下错误EngineConnPluginNotFoundException:errorCode:70063<a class="hash-link" href="#q25hive引擎调度时报如下错误engineconnpluginnotfoundexceptionerrorcode70063" title="Direct link to heading">#</a></h4><p><img src="/zh-CN/assets/images/q25_1-feffb49fb454a8fc0b0fd32dd2fe8c1a.png"></p><p>解法：安装的时候没有修改对应引擎的Version导致，所以默认插入到db里面的引擎类型为默认版本，而编译出来的版本不是默认版本导致。</p><p>具体修改步骤：</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI"><pre tabindex="0" class="prism-code language-undefined codeBlock_rtdJ thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd /appcom/Install/dss-linkis/linkis/lib/linkis-engineconn-plugins/，</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">修改dist目录下的v2.1.1 目录名 修改为v1.2.1 </span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">修改plugin目录下的子目录名2.1.1 为 默认版本的1.2.1</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">如果是Spark需要相应修改dist/v2.4.3 和plugin/2.4.3</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">最后重启engineplugin服务。</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q26hive引擎调度执行时报错如下opertion-failed-nullpointerexception"></a>Q26、hive引擎调度执行时，报错如下opertion failed NullPointerException：<a class="hash-link" href="#q26hive引擎调度执行时报错如下opertion-failed-nullpointerexception" title="Direct link to heading">#</a></h4><p><img src="/zh-CN/assets/images/q26_1-3ce3dfd6f40af09fce2c891b647df7d1.png"></p><p>解法：服务器缺少环境变量，/etc/profile增加<code>export HIVE_CONF_DIR=/etc/hive/conf;</code></p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q27hive引擎调度时engineconnmanager的错误日志如下method-did-not--existsessionhandler"></a>Q27、hive引擎调度时，engineConnManager的错误日志如下method did not  exist:SessionHandler：<a class="hash-link" href="#q27hive引擎调度时engineconnmanager的错误日志如下method-did-not--existsessionhandler" title="Direct link to heading">#</a></h4><p><img src="/zh-CN/assets/images/q27_1-9604d3aee4192bf09b279225c011357b.png"></p><p>解法：hive引擎lib下，jetty jar包冲突，jetty-security、 jetty-server替换为9.4.20；</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q28hive引擎执行时报如下错误lcomgooglecommoncollectunmodifiableiterator"></a>Q28、hive引擎执行时，报如下错误Lcom/google/common/collect/UnmodifiableIterator：<a class="hash-link" href="#q28hive引擎执行时报如下错误lcomgooglecommoncollectunmodifiableiterator" title="Direct link to heading">#</a></h4><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI"><pre tabindex="0" class="prism-code language-undefined codeBlock_rtdJ thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#F8F8F2"><span class="token plain">2021-03-16 13:32:23.304 ERROR [pool-2-thread-1]com.webank.wedatasphere.linkis.engineplugin.hive.executor.HiveEngineConnExecutor 140 run - query failed, reason : java.lang.AccessError: tried to access method com.google.common.collect.Iterators.emptyIterator() Lcom/google/common/collect/UnmodifiableIterator; from class org.apache.hadoop.hive.ql.exec.FetchOperator </span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.hadoop.hive.ql.exec.FetchOperator.&lt;init&gt;(FetchOperator.java:108) ~[hive-exec-2.1.1-cdh6.1.0.jar:2.1.1-cdh6.1.0]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.hadoop.hive.ql.exec.FetchTask.initialize(FetchTask.java:86) ~[hive-exec-2.1.1-cdh6.1.0.jar:2.1.1-cdh6.1.0]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.hadoop.hive.ql..compile(Driver.java:629) ~[hive-exec-2.1.1-cdh6.1.0.jar:2.1.1-cdh6.1.0]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1414) ~[hive-exec-2.1.1-cdh6.1.0.jar:2.1.1-cdh6.1.0]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1543) ~[hive-exec-2.1.1-cdh6.1.0.jar:2.1.1-cdh6.1.0]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1332) ~[hive-exec-2.1.1-cdh6.1.0.jar:2.1.1-cdh6.1.0]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1321) ~[hive-exec-2.1.1-cdh6.1.0.jar:2.1.1-cdh6.1.0]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">atcom.webank.wedatasphere.linkis.engineplugin.hive.executor.HiveEngineConnExecutor$$anon$1.run(HiveEngineConnExecutor.scala:152) [linkis-engineplugin-hive-dev-1.0.0.jar:?]</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">atcom.webank.wedatasphere.linkis.engineplugin.hive.executor.HiveEngineConnExecutor$$anon$1.run(HiveEngineConnExecutor.scala:126) [linkis-engineplugin-hive-dev-1.0.0.jar:?]</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><p>解法：guava包冲突，干掉hive/dist/v1.2.1/lib下的guava-25.1-jre.jar；</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q29引擎调度时报如下错误python-proces-is-not-alive"></a>Q29、引擎调度时，报如下错误Python proces is not alive：<a class="hash-link" href="#q29引擎调度时报如下错误python-proces-is-not-alive" title="Direct link to heading">#</a></h4><p><img src="/zh-CN/assets/images/q29_1-1787e33057b87430ad3e23f25c945720.png"></p><p>解法：服务器安装anaconda3 包管理器，经过对python调试，发现两个问题：（1）缺乏pandas、matplotlib模块，需要手动安装;(2)新版python引擎执行时，依赖python高版本，首先安装python3，其次做下符号链接（如下图），重启engineplugin服务。</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q30-spark引擎执行时报如下错误noclassdeffounderror-orgapachehadoophiveqlioorcorcfile"></a>Q30. spark引擎执行时，报如下错误NoClassDefFoundError: org/apache/hadoop/hive/ql/io/orc/OrcFile：<a class="hash-link" href="#q30-spark引擎执行时报如下错误noclassdeffounderror-orgapachehadoophiveqlioorcorcfile" title="Direct link to heading">#</a></h4><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI"><pre tabindex="0" class="prism-code language-undefined codeBlock_rtdJ thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#F8F8F2"><span class="token plain">2021-03-19 15:12:49.227 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler 57 logInfo -ShuffleMapStage 5 (show at &lt;console&gt;:69) failed in 21.269 s due to Job aborted due to stage failure: Task 1 in stage 5.0 failed 4 times, most recent failure: Lost task 1.3 in stage 5.0 (TID 139, cdh03, executor 6):java.lang.NoClassDefFoundError: org/apache/hadoop/hive/ql/io/orc/OrcFile </span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><p>解法：cdh6.3.2集群spark引擎classpath只有/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/spark/jars，需要新增hive-exec-2.1.1-cdh6.1.0.jar，然后重启spark。</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q31spark引擎启动时报错-get-the-queue-information-excepiton获取yarn队列信息异常以及http链接异常"></a>Q31、spark引擎启动时，报错 get the queue information excepiton.(获取Yarn队列信息异常)以及http链接异常<a class="hash-link" href="#q31spark引擎启动时报错-get-the-queue-information-excepiton获取yarn队列信息异常以及http链接异常" title="Direct link to heading">#</a></h4><p>解法：yarn的地址配置迁移DB配置，需要增加如下配置：</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI"><pre tabindex="0" class="prism-code language-undefined codeBlock_rtdJ thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#F8F8F2"><span class="token plain">INSERT INTO `linkis_cg_rm_external_resource_provider` (`resource_type`, `name`, `labels`, `config`) VALUES (&#x27;Yarn&#x27;, &#x27;sit&#x27;, NULL, &#x27;{\r\n&quot;rmWebAddress&quot;: &quot;http://xxip:xxport&quot;,\r\n&quot;hadoopVersion&quot;: &quot;2.7.2&quot;,\r\n&quot;authorEnable&quot;:true,\r\n&quot;user&quot;:&quot;hadoop&quot;,\r\n&quot;pwd&quot;:&quot;xxxx&quot;\r\n}&#x27;);</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">config 字段示例</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">{</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">&quot;rmWebAddress&quot;: &quot;http://10.10.10.10:8080&quot;,</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">&quot;hadoopVersion&quot;: &quot;2.7.2&quot;,</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">&quot;authorEnable&quot;:true,</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">&quot;user&quot;:&quot;hadoop&quot;,</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">&quot;pwd&quot;:&quot;passwordxxx&quot;</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><p><img src="/zh-CN/assets/images/q31_1-82ad7f3ad31c7ce507e41fa27f939e2a.png"></p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q32-pythonspark调度执行报错initialize-python-executor-failed-classnotfoundexception-orgslf4jimplstaticloggerbinder"></a>Q32. pythonspark调度执行，报错：initialize python executor failed ClassNotFoundException org.slf4j.impl.StaticLoggerBinder<a class="hash-link" href="#q32-pythonspark调度执行报错initialize-python-executor-failed-classnotfoundexception-orgslf4jimplstaticloggerbinder" title="Direct link to heading">#</a></h4><p>具体 如下： </p><p><img src="/zh-CN/assets/images/q32_2-6771db328f6fedb7edde749b18e26be6.png"></p><p>解法：原因是spark服务端缺少 slf4j-log4j12-1.7.25.jar,copy上述jar报到/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/spark/jars。</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q33常见包冲突问题"></a>Q33.常见包冲突问题：<a class="hash-link" href="#q33常见包冲突问题" title="Direct link to heading">#</a></h4><ol><li>java.lang.NoSuchMethodError: javax.ws.rs.core.Application.getProperties()Ljava/util/Map;
冲突包为：jsr311-api-1.1.1.jar也有可能jessery冲突</li><li>java.lang.BootstrapMethodError: java.lang.NoSuchMethodError: javax.servlet.ServletContext.setInitParameter(Ljava/lang/String;Ljava/lang/String;)Z
冲突包为：servlet-api.jar</li><li>org/eclipse/jetty/util/processorUtils
冲突包为：jetty-util-9.4.11.v20180605.jar 这个是正确版本</li><li>java.lang.NoClassDefFoundError: Could not initialize class dispatch.Http$
冲突包为需要拷入：netty-3.6.2.Final.jar</li><li>hive-exec带入的其他jar导致的冲突calcite-avatica-1.6.0.jar也有可能带入jackson包的冲突，导致com.fasterxml.jackson.databind相关的错误
Cannot inherit from final class 是因为calcite-avatica-1.6.0.jar导致</li><li>LZO压缩问题hadoop-lzo的jar
7.org.eclipse.jetty.server.session.SessionHandler.getSessionManager()Lorg/eclipse/jetty/server/SessionManager;
需要将冲突包：jetty-servlet 和 jetty-security  替换为9.4.20</li></ol><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q34运行scripts的mysql脚本报错sql引擎报错"></a>Q34.运行Scripts的Mysql脚本报错\sql引擎报错<a class="hash-link" href="#q34运行scripts的mysql脚本报错sql引擎报错" title="Direct link to heading">#</a></h4><p>MYSQL脚本：运行sql报错：</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI"><pre tabindex="0" class="prism-code language-undefined codeBlock_rtdJ thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#F8F8F2"><span class="token plain">com.webank.wedatasphere.linkis.orchestrator.ecm.exception.ECMPluginErrorException: errCode: 12003 ,desc: localhost:9101_0 Failed  to async get EngineNode RMErrorException: errCode: 11006 ,desc: Failed to request external resourceClassCastException: org.json4s.JsonAST$JNothing$ cannot be cast to org.json4s.JsonAST$JString ,ip: localhost ,port: 9101 ,serviceKind: linkis-cg-linkismanager ,ip: localhost ,port: 9104 ,serviceKind: linkis-cg-entrance</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    at com.webank.wedatasphere.linkis.orchestrator.ecm.ComputationEngineConnManager.getEngineNodeAskManager(ComputationEngineConnManager.scala:157) ~[linkis-orchestrator-ecm-plugin-1.0.2.jar:?]</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><p>解决办法：linkis_cg_rm_external_resource_provider表修改正确的yarn地址</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q35scriptis执行脚本等待时间长"></a>Q35.scriptis执行脚本等待时间长<a class="hash-link" href="#q35scriptis执行脚本等待时间长" title="Direct link to heading">#</a></h4><p><img src="/zh-CN/assets/images/q35_1-c00cc3df2f86dd1c3eee9a152d93bb2a.png"></p><p>scriptis执行脚本等待时间长，报错Failed  to async get EngineNode TimeoutException:
解决办法：可以检查linkismanager的日志，一般是因为引擎启动超时</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q36scriptis执行jdbc脚本报错"></a>Q36.scriptis执行jdbc脚本，报错<a class="hash-link" href="#q36scriptis执行jdbc脚本报错" title="Direct link to heading">#</a></h4><p>scriptis执行jdbc脚本，报错</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI"><pre tabindex="0" class="prism-code language-undefined codeBlock_rtdJ thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#F8F8F2"><span class="token plain">Failed  to async get EngineNode ErrorException: errCode: 0 ,desc: operation failed(操作失败)s！the reason(原因)：EngineConnPluginNotFoundException: errCode: 70063 ,desc: No plugin foundjdbc-4please check your configuration </span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><p>解决办法
需要安装下对应的引擎插件，可以参考：<a href="/zh-CN/docs/latest/deployment/engine_conn_plugin_installation">引擎安装指引</a></p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q37关闭资源检查"></a>Q37.关闭资源检查<a class="hash-link" href="#q37关闭资源检查" title="Direct link to heading">#</a></h4><p>报错现象：资源不足
linkismanager服务修改下这个配置：wds.linkis.manager.rm.request.enable=false
可以清理下资源记录，或者设置小点的资源
或者关闭检测
linkismanager服务修改下这个配置：wds.linkis.manager.rm.request.enable=false</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q38-dss-framework-project-serve-启动失败"></a>Q38. dss-framework-project-serve 启动失败<a class="hash-link" href="#q38-dss-framework-project-serve-启动失败" title="Direct link to heading">#</a></h4><p>问题现象：
dss-framework-project-serve 启动失败</p><p>日志：</p><p>2021-10-12 11:52:49.122 ERROR <!-- -->[main]<!-- --> org.springframework.boot.SpringApplication 837 reportFailure - Application run failed org.springframework.beans.factory.BeanCreationException: Error creating bean with name &#x27;appConnManagerRestfulApi&#x27;: Invocation of init method failed; nested exception is LinkisException{errCode=100000, desc=&#x27;errCode: 90003 ,desc: /opt/dss/Install/dss-dev/dss-appconns/orchestrator-framework to zip file failed ,ip:  ,port: 9002,serviceKind: dss-framework-project-server&#x27;, ip=&#x27;, port=9002, serviceKind=&#x27;dss-framework-project-server&#x27;}</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q39-执行脚本报错"></a>Q39 执行脚本报错<a class="hash-link" href="#q39-执行脚本报错" title="Direct link to heading">#</a></h4><p>执行脚本报错</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI"><pre tabindex="0" class="prism-code language-undefined codeBlock_rtdJ thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#F8F8F2"><span class="token plain">GatewayErrorException: errCode: 11012 ,desc: Cannot find an instance in the routing chain of serviceId [linkis-cg-entrance], please retry ,ip: localhost ,port: 9001 ,serviceKind: linkis-mg-gateway</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><p><img src="/zh-CN/assets/images/q39_1-764160ac65a63a31c9cc9e2ea6f36f5c.png"></p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q40-dss开头的接口全部报错"></a>Q40 DSS开头的接口全部报错<a class="hash-link" href="#q40-dss开头的接口全部报错" title="Direct link to heading">#</a></h4><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI"><pre tabindex="0" class="prism-code language-undefined codeBlock_rtdJ thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#F8F8F2"><span class="token plain">报错内容TooManyServiceException: errCode: 11010 ,desc: Cannot find a correct serviceId for parsedServiceId dss, service list is: List(dss-framework-project-server, dss-framework-orchestrator-server-dev, dss-apiservice-server, dss-datapipe-server, dss-workflow-server-dev, dss-flow-entrance)</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><p><img src="/zh-CN/assets/images/q40_1-7913a0b62ea774bc0ecd9649e185a673.png"></p><p><img src="/zh-CN/assets/images/q40_2-02a2a343b70c4353b023aea308a4feb5.png"></p><p><img src="/zh-CN/assets/images/q40_3-a3e425c5e9ff95f5f94a0f580c17b76a.png"></p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q41-scriptis执行脚本-timeoutexception"></a>Q41 ScriptIs执行脚本 TimeoutException<a class="hash-link" href="#q41-scriptis执行脚本-timeoutexception" title="Direct link to heading">#</a></h4><p><img src="/zh-CN/assets/images/q41_1-fc7fee9a7949d93925853282d6b34519.png"></p><p>linkis-cg-linkismanager.log中， 重复打印Need a ServiceInstance(linkis-cg-entrance, localhost:9104), but cannot find in DiscoveryClient refresh list.
这是因为实例被强制关闭了，而数据库当中持久化认为这个实例还存在导致的，解决方案是停止服务后，清空 linkis_cg_manager_service_instance 和 linkis_cg_manager_service_instance_metrics 这两张表。</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q42-配置默认jdbc"></a>Q42 配置默认jdbc<a class="hash-link" href="#q42-配置默认jdbc" title="Direct link to heading">#</a></h4><p><img src="/zh-CN/assets/images/q42_1-3363de276b5fb3f67fa34f7900fa26e8.png"></p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q43-引擎超时时间设置"></a>Q43 引擎超时时间设置<a class="hash-link" href="#q43-引擎超时时间设置" title="Direct link to heading">#</a></h4><p><img src="/zh-CN/assets/images/q43_1-2eab821fc930ab31beb6990a6c5db7a1.png"></p><p>①管理台参数配置，可以对应引擎参数，可以修改超时时间。保存后kill现有引擎即可。
②如未显示超时配置，需要手动修改 linkis-engineplugins目录下，对应引擎插件目录 如 spark/dist/v2.4.3/conf/linkis-engineconn.properties ，默认配置 wds.linkis.engineconn.max.free.time=1h ，表示1h超时，可带单位m 、h。0表示不超时，不会自动kill。改完需要重启ecp，并且kill现有引擎，跑新任务起引擎即可生效。</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q44-新建工作流的时候提示504-gateway-time-out"></a>Q44 新建工作流的时候，提示“504 Gateway Time-out”<a class="hash-link" href="#q44-新建工作流的时候提示504-gateway-time-out" title="Direct link to heading">#</a></h4><p><img src="/zh-CN/assets/images/q44_1-bf45a4798e444d605dacf795803cbd9c.png"></p><p>错误信息：The instance 05f211cb021e:9108 of application linkis-ps-cs is not exists. ,ip: 5d30e4bb2f42 ,port: 9001 ,serviceKind: linkis-mg-gateway，如下图：</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q45-scripts执行python脚本脚本内容是很简单的print正常执行成功通过任务调度系统也可以执行成功通过作业流的编辑作业脚本页面也可执行成功但是通过作业流执行时报错"></a>Q45 Scripts执行python脚本(脚本内容是很简单的print)正常执行成功，通过任务调度系统也可以执行成功，通过作业流的编辑作业脚本页面也可执行成功，但是通过作业流执行时报错<a class="hash-link" href="#q45-scripts执行python脚本脚本内容是很简单的print正常执行成功通过任务调度系统也可以执行成功通过作业流的编辑作业脚本页面也可执行成功但是通过作业流执行时报错" title="Direct link to heading">#</a></h4><p>错误信息：</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI"><pre tabindex="0" class="prism-code language-undefined codeBlock_rtdJ thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#F8F8F2"><span class="token plain">You can go to this path(/opt/kepler/work/engine/hadoop/workDir/9c28976e-63ba-4d9d-b85e-b37d84144596/logs) to find the reason or ask the administrator for help ,ip: host1 ,port: 9101 ,serviceKind: linkis-cg-linkismanager ,ip: host1 ,port: 9104 ,serviceKind: linkis-cg-entrance</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Exception in thread &quot;main&quot; java.lang.NullPointerException</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    at com.webank.wedatasphere.linkis.rpc.sender.SpringCloudFeignConfigurationCache$.getClient(SpringCloudFeignConfigurationCache.scala:73)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    at com.webank.wedatasphere.linkis.rpc.sender.SpringMVCRPCSender.doBuilder(SpringMVCRPCSender.scala:49)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=250m; support was removed in 8.0</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Java HotSpot(TM) 64-Bit Server VM warning: ignoring option PermSize=128m; support was removed in 8.0</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Exception in thread &quot;main&quot; java.lang.NullPointerException</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    at com.webank.wedatasphere.linkis.rpc.sender.SpringCloudFeignConfigurationCache$.getClient(SpringCloudFeignConfigurationCache.scala:73)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    at com.webank.wedatasphere.linkis.rpc.sender.SpringMVCRPCSender.doBuilder(SpringMVCRPCSender.scala:49)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    at com.webank.wedatasphere.linkis.rpc.BaseRPCSender.newRPC(BaseRPCSender.scala:67)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    at com.webank.wedatasphere.linkis.rpc.BaseRPCSender.com$webank$wedatasphere$linkis$rpc$BaseRPCSender$$getRPC(BaseRPCSender.scala:54)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    at com.webank.wedatasphere.linkis.rpc.BaseRPCSender.send(BaseRPCSender.scala:105)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    at com.webank.wedatasphere.linkis.engineconn.callback.service.AbstractEngineConnStartUpCallback.callback(EngineConnCallback.scala:39)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    at com.webank.wedatasphere.linkis.engineconn.callback.hook.CallbackEngineConnHook.afterEngineServerStartFailed(CallbackEngineConnHook.scala:63)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    at com.webank.wedatasphere.linkis.engineconn.launch.EngineConnServer$$anonfun$main$15.apply(EngineConnServer.scala:64)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    at com.webank.wedatasphere.linkis.engineconn.launch.EngineConnServer$$anonfun$main$15.apply(EngineConnServer.scala:64)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    at com.webank.wedatasphere.linkis.engineconn.launch.EngineConnServer$.main(EngineConnServer.scala:64)</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    at com.webank.wedatasphere.linkis.engineconn.launch.EngineConnServer.main(EngineConnServer.scala)</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><p>解决方案：/opt/kepler/work/engine/hadoop/workDir/9c28976e-63ba-4d9d-b85e-b37d84144596目录下conf为空导致的。lib和conf是在微服务启动时，由系统检查到（linkis/lib/linkis-engineconn-plugins/python）python引擎物料包zip变化，自动上传至engine/engineConnPublickDir/目录下。临时解决问题是将linkis/lib/linkis-engineconn-plugins/python下的lib和conf内容复制到engine/engineConnPublickDir/对应的目录（即workDir/9c28976e-63ba-4d9d-b85e-b37d84144596里的外链接引用的目录）下。正式方案需解决物料包变化未能成功上传到engineConnPublickDir的问题。</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q46-安装exchangis050后通过dss菜单点击进入新页面提示sorry-page-not-foundf12查看有404异常"></a>Q46 安装Exchangis0.5.0后通过dss菜单点击进入新页面提示“Sorry, Page Not Found”。F12查看有404异常<a class="hash-link" href="#q46-安装exchangis050后通过dss菜单点击进入新页面提示sorry-page-not-foundf12查看有404异常" title="Direct link to heading">#</a></h4><p>错误信息：F12查看到vue.runtime.esm.js:6785 GET <a href="http://10.0.xx.xx:29008/udes/auth?redirect=http%3A%2F%2F10.0.xx.xx%3A29008&amp;dssurl=http%3A%2F%2F10.0.xx.xx%3A8088&amp;cookies=bdp-user-ticket-id%3DM7UZXQP9Ld1xeftV5DUGYeHdOc9oAFgW2HLiVea4FcQ%3D%3B%20workspaceId%3D225" target="_blank" rel="noopener noreferrer">http://10.0.xx.xx:29008/udes/auth?redirect=http%3A%2F%2F10.0.xx.xx%3A29008&amp;dssurl=http%3A%2F%2F10.0.xx.xx%3A8088&amp;cookies=bdp-user-ticket-id%3DM7UZXQP9Ld1xeftV5DUGYeHdOc9oAFgW2HLiVea4FcQ%3D%3B%20workspaceId%3D225</a> 404 (Not Found)</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q47-hive-里面配置atlas出现死循环导致堆栈溢出"></a>Q47 HIVE 里面配置atlas出现死循环导致堆栈溢出<a class="hash-link" href="#q47-hive-里面配置atlas出现死循环导致堆栈溢出" title="Direct link to heading">#</a></h4><p>需要将${ATLAS_HOME}/atlas/hook/hive/ 下所有内容jar包及子目录加入到hive engine 的 lib目录下，不然AtlasPluginClassLoader找不到正确的实现类而找到的是hive-bridge-shim下的类，导致死循环
但是Linkis（1.0.2）现在的执行方式不支持lib下有子目录，需要修改代码，参考：
<a href="https://github.com/apache/incubator-linkis/pull/1058" target="_blank" rel="noopener noreferrer">https://github.com/apache/incubator-linkis/pull/1058</a></p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q48-linkis10x基于-spark3-hadoop3-hive3-或-hdp314-编译需要修改的地方请参考"></a>Q48 Linkis1.0.X基于 spark3 hadoop3 hive3 或 hdp3.1.4 编译需要修改的地方请参考：<a class="hash-link" href="#q48-linkis10x基于-spark3-hadoop3-hive3-或-hdp314-编译需要修改的地方请参考" title="Direct link to heading">#</a></h4><p><a href="https://github.com/lordk911/Linkis/commits/master" target="_blank" rel="noopener noreferrer">https://github.com/lordk911/Linkis/commits/master</a>
编译好之后DSS请依据编译好的包重新编译，scala保持版本一致，web模块用全家桶的就行</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q49-linkis-执行jdbc任务无法获取到用户名"></a>Q49 linkis 执行jdbc任务无法获取到用户名<a class="hash-link" href="#q49-linkis-执行jdbc任务无法获取到用户名" title="Direct link to heading">#</a></h4><p>2021-10-31 05:16:54.016 ERROR Task is Failed,errorMsg: NullPointerException: jdbc.username cannot be null.
源代码：com.webank.wedatasphere.linkis.manager.engineplugin.jdbc.executer.JDBCEngineConnExecutor 接收到的val properties = engineExecutorContext.getProperties.asInstanceOf[util.Map<!-- -->[String, String]<!-- -->] 没有jdbc.username 参数</p><p>解决方法1：
文档：JDBC问题临时修复方法.note
链接：<a href="http://note.youdao.com/noteshare?id=08163f429dd2e226a13877eba8bad1e3&amp;sub=4ADEE86F433B4A59BBB20621A1C4B2AE" target="_blank" rel="noopener noreferrer">http://note.youdao.com/noteshare?id=08163f429dd2e226a13877eba8bad1e3&amp;sub=4ADEE86F433B4A59BBB20621A1C4B2AE</a>
解决方法2：对比修改此文件
<a href="https://github.com/apache/incubator-linkis/blob/319213793881b0329022cf4137ee8d4c502395c7/linkis-engineconn-plugins/engineconn-plugins/jdbc/src/main/scala/com/webank/wedatasphere/linkis/manager/engineplugin/jdbc/executer/JDBCEngineConnExecutor.scala" target="_blank" rel="noopener noreferrer">https://github.com/apache/incubator-linkis/blob/319213793881b0329022cf4137ee8d4c502395c7/linkis-engineconn-plugins/engineconn-plugins/jdbc/src/main/scala/com/webank/wedatasphere/linkis/manager/engineplugin/jdbc/executer/JDBCEngineConnExecutor.scala</a></p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q50-安装前更改配置中的hive版本后管理台的配置中仍然显示版本为233"></a>Q50. 安装前更改配置中的hive版本后，管理台的配置中仍然显示版本为2.3.3<a class="hash-link" href="#q50-安装前更改配置中的hive版本后管理台的配置中仍然显示版本为233" title="Direct link to heading">#</a></h4><p><img src="/zh-CN/assets/images/q50_1-da3747bd98c7849f807cf006c80fc4d0.png"></p><p>方案一：确定为安装install.sh脚本存在bug，请将此处的hive-1.2.1改成hive-2.3.3后重新安装即可。
方案二：如果不想重新安装，则需要在linkis_cg_manager_label表中label_value包含hive-2.3.3的所有值改成希望的hive版本即可
Note：欢迎将此问题在github Linkis项目提交PR进行修复，然后告知我们，我们会尽快review并合并到代码中（目前未修复，Deadline 2021年11月30日）</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q51-linkis-cli-提交任务提示group-by-clause-sql_modeonly_full_group_by错误"></a>Q51. linkis-cli 提交任务，提示GROUP BY clause; sql_mode=only_full_group_by错误<a class="hash-link" href="#q51-linkis-cli-提交任务提示group-by-clause-sql_modeonly_full_group_by错误" title="Direct link to heading">#</a></h4><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI"><pre tabindex="0" class="prism-code language-undefined codeBlock_rtdJ thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#F8F8F2"><span class="token plain">_8_codeExec_8 com.webank.wedatasphere.linkis.orchestrator.ecm.exception.ECMPluginErrorException: errCode: 12003 ,desc: uathadoop01:9101_8 Failed  to async get EngineNode MySQLSyntaxErrorException: Expression #6 of SELECT list is not in GROUP BY clause and contains nonaggregated column &#x27;dss_linkis.si.name&#x27; which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode=only_full_group_by ,ip: uathadoop01 ,port: 9104 ,serviceKind: linkis-cg-entrance</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><p>原因：这个错误发生在mysql 5.7 版本及以上版本会出现的问题：因为配置严格执行了&quot;SQL92标准&quot;，解决方法：进入/etc/mysql目录下修改my.cnf文件 在 <!-- -->[mysqld]<!-- --> 下面添加代码：
sql_mode = STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q52flink引擎启动时报错找到tokencache"></a>Q52、flink引擎启动时报错找到TokenCache<a class="hash-link" href="#q52flink引擎启动时报错找到tokencache" title="Direct link to heading">#</a></h4><p>ERROR <!-- -->[main]<!-- --> com.webank.wedatasphere.linkis.engineconn.computation.executor.hook.ComputationEngineConnHook 57 error - EngineConnSever start failed! now exit. java.lang.NoClassDefFoundError: org/apache/hadoop/mapreduce/security/TokenCache
原因：flink-enginecon lib下缺少hadoop-mapreduce-client-core.jar这个jar包，从hadoop的lib下拷贝一份即可。</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q53运行flink任务时报错failed-to-create-engineconnplugin-comwebankwedataspherelinkisenginepluginhivehiveengineconnpluginjavalangclassnotfoundexception-comwebankwedataspherelinkisenginepluginhivehiveengineconnplugin"></a>Q53、运行flink任务时报错：Failed to create engineConnPlugin: com.webank.wedatasphere.linkis.engineplugin.hive.HiveEngineConnPluginjava.lang.ClassNotFoundException: com.webank.wedatasphere.linkis.engineplugin.hive.HiveEngineConnPlugin<a class="hash-link" href="#q53运行flink任务时报错failed-to-create-engineconnplugin-comwebankwedataspherelinkisenginepluginhivehiveengineconnpluginjavalangclassnotfoundexception-comwebankwedataspherelinkisenginepluginhivehiveengineconnplugin" title="Direct link to heading">#</a></h4><p><img src="/zh-CN/assets/images/q53_1-e521f8846a09ef0f3e8bf245174ca474.png"></p><p>原因：flink引擎目录下的conf里的配置文件为空，读取了默认的配置（默认读取hived引擎的配置），删除配置表中关于flink的conf 然后重启ecp</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q54启动flink引擎spark引擎时engine-entrance报错orgjson4sjsonastjnothing-cannot-be-cast-to-orgjson4sjsonastjstring"></a>Q54、启动flink引擎/spark引擎时，engine-entrance报错org.json4s.JsonAST$JNothing$ cannot be cast to org.json4s.JsonAST$JString<a class="hash-link" href="#q54启动flink引擎spark引擎时engine-entrance报错orgjson4sjsonastjnothing-cannot-be-cast-to-orgjson4sjsonastjstring" title="Direct link to heading">#</a></h4><p>原因是linkis-manager里面报错yarn队列获取异常
解决办法：修改linkis_cg_rm_external_resource_provider表中修改对应config的yarn队列信息</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_y2LR" id="q55函数脚本执行时报classnotfoundexception"></a>Q55、函数脚本执行时报ClassNotFoundException<a class="hash-link" href="#q55函数脚本执行时报classnotfoundexception" title="Direct link to heading">#</a></h4><p><img src="/zh-CN/assets/images/q55_1-dcb8abee478065f48183c591ca54f431.png"></p><p>原因：linkis创建函数的方式是通过把函数所在的路径加入到classPath下，再执行create temporary function。。。语句，此种方式往yarn集群上提交任务时并不会把函数的jar包上传到hdfs上，造成类加载失败！</p><p>解决办法：修改生成函数语句的方法，或者利用HiveAddJarsEngineHook解决，这里修改JarUdfEngineHook的constructCode方法。打包后替换所有的</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI"><pre tabindex="0" class="prism-code language-undefined codeBlock_rtdJ thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#F8F8F2"><span class="token plain">  override protected def constructCode(udfInfo: UDFInfo): String = {</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;%sql\n&quot; + &quot;add jar &quot; + udfInfo.getPath + &quot;\n%sql\n&quot; + udfInfo.getRegisterFormat</span></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  }</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/apache/incubator-linkis-website/edit/dev/i18n/zh-CN/main.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_mS5F" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>编辑</a></div><div class="col lastUpdated_mt2f"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><div class="pagination-nav__item"></div><div class="pagination-nav__item pagination-nav__item--next"></div></nav></div></div><div class="col col--3"><div class="tableOfContents_vrFS thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#q1-linkis的ps-cs服务日志报这个错-figservletwebserverapplicationcontext-559" class="table-of-contents__link">Q1: linkis的ps-cs服务日志报这个错： figServletWebServerApplicationContext (559)</a></li><li><a href="#q2--linkis-eureka调试说明" class="table-of-contents__link">Q2:  Linkis-eureka调试说明</a></li><li><a href="#q3-eureka-第一次启动-自动停止需要手工重新启动的问题" class="table-of-contents__link">Q3: eureka 第一次启动 自动停止，需要手工重新启动的问题</a></li><li><a href="#q4-linkis-entrance-logwriter-缺依赖包" class="table-of-contents__link">Q4: Linkis Entrance LogWriter 缺依赖包</a></li><li><a href="#q5-linkis10-执行任务报-select-list-is-not-in--group-by-clause" class="table-of-contents__link">Q5: Linkis1.0 执行任务报： select list is not in  group by clause</a></li><li><a href="#q6-部署后执行脚执行命令收集结果时遇到这样的报错ioexception-file-header-type-must-be-dolphin" class="table-of-contents__link">Q6: 部署后执行脚，执行命令，收集结果时，遇到这样的报错，IOException: File header type must be dolphin:</a></li><li><a href="#q7-script-左侧数据库刷不出来" class="table-of-contents__link">Q7: Script 左侧数据库刷不出来</a></li><li><a href="#q8scriptis的右侧刷不出来数据库一直在刷新中需要注意的是linkis的metadata暂时不支持对接sentry和ranger只支持hive原生的权限控制错误信息-前端数据库tab一直处于刷新状态" class="table-of-contents__link">Q8.Scriptis的右侧刷不出来数据库，一直在刷新中（需要注意的是linkis的metadata暂时不支持对接sentry和Ranger只支持hive原生的权限控制），错误信息: 前端数据库tab一直处于刷新状态</a></li><li><a href="#q9-scriptis工作空间-登录scriptis时报根目录不存在存在工作空间和hdfs两个跟目录错误信息-在登录进入后前端弹出如下信息用户本地目录不存在请联系管理员添加" class="table-of-contents__link">Q9. [Scriptis]工作空间 登录Scriptis时报根目录不存在，存在工作空间和HDFS两个跟目录:错误信息: 在登录进入后，前端弹出如下信息(用户本地目录不存在，请联系管理员添加)</a></li><li><a href="#q10管理台设置怎么调整任务使用的yarn队列错误信息-执行sql任务时报1获取yarn队列信息异常-或者-用户xx不能提交到队列" class="table-of-contents__link">Q10.[管理台]设置怎么调整任务使用的yarn队列?错误信息: 执行sql任务时报1.获取Yarn队列信息异常 或者 用户XX不能提交到队列</a></li><li><a href="#q11hive查询的时候报找不到zk相关的类比如orgapachecurator错误信息-执行hive任务时日志报找不到orgapachecurator开头的类classnotfound" class="table-of-contents__link">Q11.Hive查询的时候报：找不到zk相关的类比如：org.apache.curator.<em>,错误信息: 执行hive任务时，日志报找不到org.apache.curator.</em>开头的类，classNotFound</a></li><li><a href="#q12linkis如何支持kerberos" class="table-of-contents__link">Q12.Linkis如何支持kerberos</a></li><li><a href="#q13关于linkis除了支持部署用户登录可以配置其他用户登录吗" class="table-of-contents__link">Q13.关于Linkis除了支持部署用户登录可以配置其他用户登录吗?</a></li><li><a href="#q14-spark版本不一致导致的json4s包冲突问题报错如下错误信息caused-by-javalangnosuchmethoderror-orgjson4sjacksonjsonmethod" class="table-of-contents__link">Q14. Spark版本不一致导致的json4s包冲突问题，报错如下：错误信息:caused by: java.lang.NoSuchMethodError: org.json4s.jackson.jsonMethod$</a></li><li><a href="#q15linkis管理台管理员页面ecm和微服务管理怎么-开启" class="table-of-contents__link">Q15.Linkis管理台，管理员页面ECM和微服务管理怎么 开启？</a></li><li><a href="#q16linkis10执行任务时ecp服务抛出如下错误caused-by-javautilnosuchelementexception-noneget" class="table-of-contents__link">Q.16Linkis1.0执行任务时，ECP服务抛出如下错误:Caused by: java.util.NoSuchElementException: None.get？</a></li><li><a href="#q17linkis1x提示资源不足的通用排查方法" class="table-of-contents__link">Q17.Linkis1.X提示资源不足的通用排查方法</a></li><li><a href="#q18linkis1x在cdh5161版本提交spark-sql任务时404的问题排查方法" class="table-of-contents__link">Q18.Linkis1.X在CDH5.16.1版本提交spark sql任务时，404的问题排查方法</a></li><li><a href="#q20-运行报错缺包matplotlib" class="table-of-contents__link">Q20 运行报错缺包matplotlib</a></li><li><a href="#q21linkis启动报错nosuchmethoderrorgetsessionmanagerlorgeclipsejettyserversessionmanager" class="table-of-contents__link">Q21、linkis启动报错：NoSuchMethodErrorgetSessionManager()Lorg/eclipse/jetty/server/SessionManager</a></li><li><a href="#q22启动微服务linkis-ps-cs时报debuggclasswriter-overrides-final-method-visit" class="table-of-contents__link">Q22、启动微服务linkis-ps-cs时，报DebuggClassWriter overrides final method visit</a></li><li><a href="#q23启动微服务linkis-ps-publicservice时kjdbcutilsgetdriverclassname-npe" class="table-of-contents__link">Q23、启动微服务linkis-ps-publicservice时，kJdbcUtils.getDriverClassName NPE</a></li><li><a href="#q24shell引擎调度执行时引擎执行目录报如下错误binjavano-such-file-or-directory" class="table-of-contents__link">Q24、shell引擎调度执行时，引擎执行目录报如下错误/bin/java:No such file or directory：</a></li><li><a href="#q25hive引擎调度时报如下错误engineconnpluginnotfoundexceptionerrorcode70063" class="table-of-contents__link">Q25、hive引擎调度时，报如下错误EngineConnPluginNotFoundException:errorCode:70063</a></li><li><a href="#q26hive引擎调度执行时报错如下opertion-failed-nullpointerexception" class="table-of-contents__link">Q26、hive引擎调度执行时，报错如下opertion failed NullPointerException：</a></li><li><a href="#q27hive引擎调度时engineconnmanager的错误日志如下method-did-not--existsessionhandler" class="table-of-contents__link">Q27、hive引擎调度时，engineConnManager的错误日志如下method did not  exist:SessionHandler：</a></li><li><a href="#q28hive引擎执行时报如下错误lcomgooglecommoncollectunmodifiableiterator" class="table-of-contents__link">Q28、hive引擎执行时，报如下错误Lcom/google/common/collect/UnmodifiableIterator：</a></li><li><a href="#q29引擎调度时报如下错误python-proces-is-not-alive" class="table-of-contents__link">Q29、引擎调度时，报如下错误Python proces is not alive：</a></li><li><a href="#q30-spark引擎执行时报如下错误noclassdeffounderror-orgapachehadoophiveqlioorcorcfile" class="table-of-contents__link">Q30. spark引擎执行时，报如下错误NoClassDefFoundError: org/apache/hadoop/hive/ql/io/orc/OrcFile：</a></li><li><a href="#q31spark引擎启动时报错-get-the-queue-information-excepiton获取yarn队列信息异常以及http链接异常" class="table-of-contents__link">Q31、spark引擎启动时，报错 get the queue information excepiton.(获取Yarn队列信息异常)以及http链接异常</a></li><li><a href="#q32-pythonspark调度执行报错initialize-python-executor-failed-classnotfoundexception-orgslf4jimplstaticloggerbinder" class="table-of-contents__link">Q32. pythonspark调度执行，报错：initialize python executor failed ClassNotFoundException org.slf4j.impl.StaticLoggerBinder</a></li><li><a href="#q33常见包冲突问题" class="table-of-contents__link">Q33.常见包冲突问题：</a></li><li><a href="#q34运行scripts的mysql脚本报错sql引擎报错" class="table-of-contents__link">Q34.运行Scripts的Mysql脚本报错sql引擎报错</a></li><li><a href="#q35scriptis执行脚本等待时间长" class="table-of-contents__link">Q35.scriptis执行脚本等待时间长</a></li><li><a href="#q36scriptis执行jdbc脚本报错" class="table-of-contents__link">Q36.scriptis执行jdbc脚本，报错</a></li><li><a href="#q37关闭资源检查" class="table-of-contents__link">Q37.关闭资源检查</a></li><li><a href="#q38-dss-framework-project-serve-启动失败" class="table-of-contents__link">Q38. dss-framework-project-serve 启动失败</a></li><li><a href="#q39-执行脚本报错" class="table-of-contents__link">Q39 执行脚本报错</a></li><li><a href="#q40-dss开头的接口全部报错" class="table-of-contents__link">Q40 DSS开头的接口全部报错</a></li><li><a href="#q41-scriptis执行脚本-timeoutexception" class="table-of-contents__link">Q41 ScriptIs执行脚本 TimeoutException</a></li><li><a href="#q42-配置默认jdbc" class="table-of-contents__link">Q42 配置默认jdbc</a></li><li><a href="#q43-引擎超时时间设置" class="table-of-contents__link">Q43 引擎超时时间设置</a></li><li><a href="#q44-新建工作流的时候提示504-gateway-time-out" class="table-of-contents__link">Q44 新建工作流的时候，提示“504 Gateway Time-out”</a></li><li><a href="#q45-scripts执行python脚本脚本内容是很简单的print正常执行成功通过任务调度系统也可以执行成功通过作业流的编辑作业脚本页面也可执行成功但是通过作业流执行时报错" class="table-of-contents__link">Q45 Scripts执行python脚本(脚本内容是很简单的print)正常执行成功，通过任务调度系统也可以执行成功，通过作业流的编辑作业脚本页面也可执行成功，但是通过作业流执行时报错</a></li><li><a href="#q46-安装exchangis050后通过dss菜单点击进入新页面提示sorry-page-not-foundf12查看有404异常" class="table-of-contents__link">Q46 安装Exchangis0.5.0后通过dss菜单点击进入新页面提示“Sorry, Page Not Found”。F12查看有404异常</a></li><li><a href="#q47-hive-里面配置atlas出现死循环导致堆栈溢出" class="table-of-contents__link">Q47 HIVE 里面配置atlas出现死循环导致堆栈溢出</a></li><li><a href="#q48-linkis10x基于-spark3-hadoop3-hive3-或-hdp314-编译需要修改的地方请参考" class="table-of-contents__link">Q48 Linkis1.0.X基于 spark3 hadoop3 hive3 或 hdp3.1.4 编译需要修改的地方请参考：</a></li><li><a href="#q49-linkis-执行jdbc任务无法获取到用户名" class="table-of-contents__link">Q49 linkis 执行jdbc任务无法获取到用户名</a></li><li><a href="#q50-安装前更改配置中的hive版本后管理台的配置中仍然显示版本为233" class="table-of-contents__link">Q50. 安装前更改配置中的hive版本后，管理台的配置中仍然显示版本为2.3.3</a></li><li><a href="#q51-linkis-cli-提交任务提示group-by-clause-sql_modeonly_full_group_by错误" class="table-of-contents__link">Q51. linkis-cli 提交任务，提示GROUP BY clause; sql_mode=only_full_group_by错误</a></li><li><a href="#q52flink引擎启动时报错找到tokencache" class="table-of-contents__link">Q52、flink引擎启动时报错找到TokenCache</a></li><li><a href="#q53运行flink任务时报错failed-to-create-engineconnplugin-comwebankwedataspherelinkisenginepluginhivehiveengineconnpluginjavalangclassnotfoundexception-comwebankwedataspherelinkisenginepluginhivehiveengineconnplugin" class="table-of-contents__link">Q53、运行flink任务时报错：Failed to create engineConnPlugin: com.webank.wedatasphere.linkis.engineplugin.hive.HiveEngineConnPluginjava.lang.ClassNotFoundException: com.webank.wedatasphere.linkis.engineplugin.hive.HiveEngineConnPlugin</a></li><li><a href="#q54启动flink引擎spark引擎时engine-entrance报错orgjson4sjsonastjnothing-cannot-be-cast-to-orgjson4sjsonastjstring" class="table-of-contents__link">Q54、启动flink引擎/spark引擎时，engine-entrance报错org.json4s.JsonAST$JNothing$ cannot be cast to org.json4s.JsonAST$JString</a></li><li><a href="#q55函数脚本执行时报classnotfoundexception" class="table-of-contents__link">Q55、函数脚本执行时报ClassNotFoundException</a></li></ul></div></div></div></div></main></div></div><footer class="footer"><div class="container"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Linkis</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/zh-CN/docs/latest/introduction">文档</a></li><li class="footer__item"><a class="footer__link-item" href="/zh-CN/faq/main">FAQ</a></li><li class="footer__item"><a href="https://github.com/apache/incubator-linkis/releases" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>版本<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><div class="col footer__col"><div class="footer__title">社区</div><ul class="footer__items"><li class="footer__item"><a href="https://github.com/apache/incubator-linkis" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://github.com/apache/incubator-linkis/issues" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Issue Tracker<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://github.com/apache/incubator-linkis/pulls" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Pull Requests<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><div class="col footer__col"><div class="footer__title">订阅邮件组</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/zh-CN/community/how-to-subscribe">如何订阅</a></li><li class="footer__item"><a href="mailto:dev-subscribe@linkis.apache.org" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>订阅邮件<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://lists.apache.org/list.html?dev@linkis.apache.org" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>邮件归档<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright"><div style="text-align: left;">
          <div>
            <p style="font-family: Avenir-Medium;font-size: 14px;color: #999;line-height: 20px;">Apache Linkis (incubating) is an effort undergoing incubation at The Apache Software Foundation (ASF), sponsored by Incubator. Incubation is required of all newly accepted projects until a further review indicates that the infrastructure, communications, and decision making process have stabilized in a manner consistent with other successful ASF projects. While incubation status is not necessarily a reflection of the completeness or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF.</p>
          </div>
          <div style="border-top: 1px solid #ccc;min-height: 60px;line-height: 20px;text-align: center;font-family: Avenir-Medium;font-size: 14px;color: #999;display: flex;align-items: center;"><span>Copyright © 2019-2020 The Apache Software Foundation. Apache Linkis, Linkis, and its feather logo are trademarks of The Apache Software Foundation.</span></div>
        </div></div></div></div></footer></div>
<script src="/zh-CN/assets/js/runtime~main.9262477f.js"></script>
<script src="/zh-CN/assets/js/main.a77b6c29.js"></script>
</body>
</html>