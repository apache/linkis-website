"use strict";(self.webpackChunklinkis_web_apache=self.webpackChunklinkis_web_apache||[]).push([[61992],{3905:(e,n,a)=>{a.d(n,{Zo:()=>d,kt:()=>m});var t=a(67294);function r(e,n,a){return n in e?Object.defineProperty(e,n,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[n]=a,e}function s(e,n){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),a.push.apply(a,t)}return a}function i(e){for(var n=1;n<arguments.length;n++){var a=null!=arguments[n]?arguments[n]:{};n%2?s(Object(a),!0).forEach((function(n){r(e,n,a[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):s(Object(a)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(a,n))}))}return e}function p(e,n){if(null==e)return{};var a,t,r=function(e,n){if(null==e)return{};var a,t,r={},s=Object.keys(e);for(t=0;t<s.length;t++)a=s[t],n.indexOf(a)>=0||(r[a]=e[a]);return r}(e,n);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(t=0;t<s.length;t++)a=s[t],n.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var l=t.createContext({}),o=function(e){var n=t.useContext(l),a=n;return e&&(a="function"==typeof e?e(n):i(i({},n),e)),a},d=function(e){var n=o(e.components);return t.createElement(l.Provider,{value:n},e.children)},c="mdxType",u={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},k=t.forwardRef((function(e,n){var a=e.components,r=e.mdxType,s=e.originalType,l=e.parentName,d=p(e,["components","mdxType","originalType","parentName"]),c=o(a),k=r,m=c["".concat(l,".").concat(k)]||c[k]||u[k]||s;return a?t.createElement(m,i(i({ref:n},d),{},{components:a})):t.createElement(m,i({ref:n},d))}));function m(e,n){var a=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var s=a.length,i=new Array(s);i[0]=k;var p={};for(var l in n)hasOwnProperty.call(n,l)&&(p[l]=n[l]);p.originalType=e,p[c]="string"==typeof e?e:r,i[1]=p;for(var o=2;o<s;o++)i[o]=a[o];return t.createElement.apply(null,i)}return t.createElement.apply(null,a)}k.displayName="MDXCreateElement"},90527:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>u,frontMatter:()=>s,metadata:()=>p,toc:()=>o});var t=a(87462),r=(a(67294),a(3905));const s={title:"\u96c6\u6210 Spark\u8840\u7f18",sidebar_position:1},i=void 0,p={unversionedId:"deployment/integrated/spark-lineage",id:"version-1.5.0/deployment/integrated/spark-lineage",title:"\u96c6\u6210 Spark\u8840\u7f18",description:"\u672c\u6587\u4e3b\u8981\u4ecb\u7ecd\u5728 Linkis \u4e2d\uff0c Spark \u5f15\u64ce\u8840\u7f18\u91c7\u96c6\u65b9\u6848\u3002",source:"@site/i18n/zh-CN/docusaurus-plugin-content-docs/version-1.5.0/deployment/integrated/spark-lineage.md",sourceDirName:"deployment/integrated",slug:"/deployment/integrated/spark-lineage",permalink:"/zh-CN/docs/latest/deployment/integrated/spark-lineage",draft:!1,editUrl:"https://github.com/apache/linkis-website/edit/dev/i18n/zh-CN/docusaurus-plugin-content-docs/version-1.5.0/deployment/integrated/spark-lineage.md",tags:[],version:"1.5.0",sidebarPosition:1,frontMatter:{title:"\u96c6\u6210 Spark\u8840\u7f18",sidebar_position:1},sidebar:"version-1.5.0/tutorialSidebar",previous:{title:"\u96c6\u6210 Hive\u8840\u7f18",permalink:"/zh-CN/docs/latest/deployment/integrated/hive-lineage"},next:{title:"\u96c6\u6210 Scriptis",permalink:"/zh-CN/docs/latest/deployment/integrated/install-scriptis"}},l={},o=[{value:"1. \u4ecb\u7ecd",id:"1-\u4ecb\u7ecd",level:2},{value:"2. \u4e0b\u8f7d<code>spline-spark-agent</code>\u6240\u9700jar\u5305",id:"2-\u4e0b\u8f7dspline-spark-agent\u6240\u9700jar\u5305",level:2},{value:"3. \u5c06spark\u8840\u7f18\u91c7\u96c6\u81f3\u65e5\u5fd7",id:"3-\u5c06spark\u8840\u7f18\u91c7\u96c6\u81f3\u65e5\u5fd7",level:2},{value:"3.1 \u4fee\u6539<code>spark-defaults.conf</code>",id:"31-\u4fee\u6539spark-defaultsconf",level:3},{value:"3.2 \u6570\u636e\u51c6\u5907",id:"32-\u6570\u636e\u51c6\u5907",level:3},{value:"3.3 \u63d0\u4ea4\u4efb\u52a1",id:"33-\u63d0\u4ea4\u4efb\u52a1",level:3},{value:"3.4 \u67e5\u770b\u65e5\u5fd7",id:"34-\u67e5\u770b\u65e5\u5fd7",level:3},{value:"4. \u5c06spark\u8840\u7f18\u91c7\u96c6\u81f3kafka",id:"4-\u5c06spark\u8840\u7f18\u91c7\u96c6\u81f3kafka",level:2},{value:"4.1 \u4fee\u6539<code>spark-defaults.conf</code>",id:"41-\u4fee\u6539spark-defaultsconf",level:3},{value:"4.2 \u63d0\u4ea4\u4efb\u52a1",id:"42-\u63d0\u4ea4\u4efb\u52a1",level:3},{value:"4.3 \u67e5\u770btopic",id:"43-\u67e5\u770btopic",level:3},{value:"5. \u66f4\u591a\u65b9\u5f0f",id:"5-\u66f4\u591a\u65b9\u5f0f",level:2}],d={toc:o},c="wrapper";function u(e){let{components:n,...s}=e;return(0,r.kt)(c,(0,t.Z)({},d,s,{components:n,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"\u672c\u6587\u4e3b\u8981\u4ecb\u7ecd\u5728 ",(0,r.kt)("inlineCode",{parentName:"p"},"Linkis")," \u4e2d\uff0c ",(0,r.kt)("inlineCode",{parentName:"p"},"Spark")," \u5f15\u64ce\u8840\u7f18\u91c7\u96c6\u65b9\u6848\u3002"),(0,r.kt)("h2",{id:"1-\u4ecb\u7ecd"},"1. \u4ecb\u7ecd"),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"spline-spark-agent"),"\u662f\u4e00\u4e2a\u7528\u4e8e\u5728Spark\u5e94\u7528\u7a0b\u5e8f\u4e2d\u542f\u7528\u8840\u7f18\u8ddf\u8e2a\uff08Lineage Tracking\uff09\u7684\u7ec4\u4ef6\u3002\u5b83\u662fSpline\u9879\u76ee\u7684\u4e00\u90e8\u5206\uff0c\u65e8\u5728\u5bf9Spark\u4f5c\u4e1a\u8fdb\u884c\u5b9e\u65f6\u7684\u8840\u7f18\u6570\u636e\u6536\u96c6"),(0,r.kt)("p",null,"github\u5730\u5740"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"https://github.com/AbsaOSS/spline-spark-agent\n")),(0,r.kt)("h2",{id:"2-\u4e0b\u8f7dspline-spark-agent\u6240\u9700jar\u5305"},"2. \u4e0b\u8f7d",(0,r.kt)("inlineCode",{parentName:"h2"},"spline-spark-agent"),"\u6240\u9700jar\u5305"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"cd $SPARK_HOME/jars\n\nwget https://repo1.maven.org/maven2/za/co/absa/spline/agent/spark/spark-3.2-spline-agent-bundle_2.12/2.0.0/spark-3.2-spline-agent-bundle_2.12-2.0.0.jar\n")),(0,r.kt)("p",null,"\u4e0b\u8f7d\u5b8c\u6210\u540e ",(0,r.kt)("inlineCode",{parentName:"p"},"$SPARK_HOME/jars")," \u4f1a\u51fa\u73b0 ",(0,r.kt)("inlineCode",{parentName:"p"},"spark-3.2-spline-agent-bundle_2.12-2.0.0.jar")),(0,r.kt)("h2",{id:"3-\u5c06spark\u8840\u7f18\u91c7\u96c6\u81f3\u65e5\u5fd7"},"3. \u5c06spark\u8840\u7f18\u91c7\u96c6\u81f3\u65e5\u5fd7"),(0,r.kt)("h3",{id:"31-\u4fee\u6539spark-defaultsconf"},"3.1 \u4fee\u6539",(0,r.kt)("inlineCode",{parentName:"h3"},"spark-defaults.conf")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"vim $SPARK_HOME/conf/spark-defaults.conf\n\n\u589e\u52a0\u5982\u4e0b\u914d\u7f6e\nspark.sql.queryExecutionListeners=za.co.absa.spline.harvester.listener.SplineQueryExecutionListener\nspark.spline.lineageDispatcher=log\nspark.spline.lineageDispatcher.log.level=INFO\nspark.spline.lineageDispatcher.log.className=za.co.absa.spline.harvester.dispatcher.LoggingLineageDispatcher\n")),(0,r.kt)("h3",{id:"32-\u6570\u636e\u51c6\u5907"},"3.2 \u6570\u636e\u51c6\u5907"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},'\u521b\u5efa\u8f93\u5165\u6587\u4ef6\u5e76\u4e0a\u4f20\u81f3hdfs\n\nvim read.json\n\n{"name":"linkis","age":"5"}\n\nhadoop fs -put read.json /tmp\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"\u521b\u5efa\u8f93\u51fa\u76ee\u5f55\nhadoop fs -mkdir /tmp/jsonWrite\n")),(0,r.kt)("h3",{id:"33-\u63d0\u4ea4\u4efb\u52a1"},"3.3 \u63d0\u4ea4\u4efb\u52a1"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"sh ./bin/linkis-cli -engineType spark-3.2.1 -codeType sql -code \\\n\"CREATE TEMPORARY VIEW jsonReadTable\nUSING org.apache.spark.sql.json\nOPTIONS (\n  path '/tmp/read.json'\n);\nINSERT OVERWRITE DIRECTORY '/tmp/jsonWrite' SELECT * FROM jsonReadTable;\"  \\\n-submitUser hadoop -proxyUser hadoop\n")),(0,r.kt)("h3",{id:"34-\u67e5\u770b\u65e5\u5fd7"},"3.4 \u67e5\u770b\u65e5\u5fd7"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"cat /appcom/tmp/hadoop/20230829/spark/117ca887-f9d6-4923-8ca1-cef7155ee0e7/logs/stdout \n")),(0,r.kt)("p",null,"\u8f93\u51fa\u7ed3\u679c\u5982\u4e0b:\n",(0,r.kt)("img",{alt:"spark-lineage-log",src:a(45908).Z,width:"1624",height:"214"})),(0,r.kt)("p",null,"\u8be6\u7ec6\u4fe1\u606f\u5982\u4e0b:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-json"},'{\n    "id":"a5b273b3-a87f-5a30-8ced-c8eeff2d1458",\n    "name":"Linkis-EngineConn-Spark_LINKISCLI",\n    "operations":{\n        "write":{\n            "outputSource":"/tmp/jsonWrite",\n            "append":false,\n            "id":"op-0",\n            "name":"InsertIntoHiveDirCommand",\n            "childIds":[\n                "op-1"\n            ],\n            "extra":{\n                "destinationType":"hive"\n            }\n        },\n        "reads":[\n            {\n                "inputSources":[\n                    "hdfs://linkishdfs/tmp/read.json"\n                ],\n                "id":"op-4",\n                "name":"LogicalRelation",\n                "output":[\n                    "attr-0",\n                    "attr-1"\n                ],\n                "params":{\n                    "path":"/tmp/read.json"\n                },\n                "extra":{\n                    "sourceType":"json"\n                }\n            }\n        ],\n        "other":[\n            {\n                "id":"op-3",\n                "name":"View",\n                "childIds":[\n                    "op-4"\n                ],\n                "output":[\n                    "attr-0",\n                    "attr-1"\n                ],\n                "params":{\n                    "desc":"CatalogTable(\\nTable: jsonReadTable\\nCreated Time: Tue Aug 29 11:52:10 CST 2023\\nLast Access: UNKNOWN\\nCreated By: Spark \\nType: VIEW\\nTable Properties: []\\nSchema: root\\n |-- age: string (nullable = true)\\n |-- name: string (nullable = true)\\n)",\n                    "isTempView":true\n                }\n            },\n            {\n                "id":"op-2",\n                "name":"SubqueryAlias",\n                "childIds":[\n                    "op-3"\n                ],\n                "output":[\n                    "attr-0",\n                    "attr-1"\n                ],\n                "params":{\n                    "identifier":"jsonreadtable"\n                }\n            },\n            {\n                "id":"op-1",\n                "name":"Project",\n                "childIds":[\n                    "op-2"\n                ],\n                "output":[\n                    "attr-0",\n                    "attr-1"\n                ],\n                "params":{\n                    "projectList":[\n                        {\n                            "__attrId":"attr-0"\n                        },\n                        {\n                            "__attrId":"attr-1"\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    "attributes":[\n        {\n            "id":"attr-0",\n            "dataType":"e63adadc-648a-56a0-9424-3289858cf0bb",\n            "name":"age"\n        },\n        {\n            "id":"attr-1",\n            "dataType":"e63adadc-648a-56a0-9424-3289858cf0bb",\n            "name":"name"\n        }\n    ],\n    "expressions":{\n\n    },\n    "systemInfo":{\n        "name":"spark",\n        "version":"3.2.1"\n    },\n    "agentInfo":{\n        "name":"spline",\n        "version":"2.0.0"\n    },\n    "extraInfo":{\n        "appName":"Linkis-EngineConn-Spark_LINKISCLI",\n        "dataTypes":[\n            {\n                "id":"e63adadc-648a-56a0-9424-3289858cf0bb",\n                "name":"string",\n                "nullable":true,\n                "_typeHint":"dt.Simple"\n            }\n        ]\n    }\n}\n')),(0,r.kt)("h2",{id:"4-\u5c06spark\u8840\u7f18\u91c7\u96c6\u81f3kafka"},"4. \u5c06spark\u8840\u7f18\u91c7\u96c6\u81f3kafka"),(0,r.kt)("h3",{id:"41-\u4fee\u6539spark-defaultsconf"},"4.1 \u4fee\u6539",(0,r.kt)("inlineCode",{parentName:"h3"},"spark-defaults.conf")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"vim $SPARK_HOME/conf/spark-defaults.conf\n\n\u589e\u52a0\u5982\u4e0b\u914d\u7f6e\nspark.sql.queryExecutionListeners=za.co.absa.spline.harvester.listener.SplineQueryExecutionListener\nspark.spline.lineageDispatcher=kafka\nspark.spline.lineageDispatcher.kafka.topic=linkis_spark_lineage_test\nspark.spline.lineageDispatcher.kafka.producer.bootstrap.servers=localhost:9092\n")),(0,r.kt)("h3",{id:"42-\u63d0\u4ea4\u4efb\u52a1"},"4.2 \u63d0\u4ea4\u4efb\u52a1"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"sh ./bin/linkis-cli -engineType spark-3.2.1 -codeType sql -code \\\n\"CREATE TEMPORARY VIEW jsonReadTable\nUSING org.apache.spark.sql.json\nOPTIONS (\n  path '/tmp/read.json'\n);\nINSERT OVERWRITE DIRECTORY '/tmp/jsonWrite' SELECT * FROM jsonReadTable;\"  \\\n-submitUser hadoop -proxyUser hadoop\n")),(0,r.kt)("h3",{id:"43-\u67e5\u770btopic"},"4.3 \u67e5\u770btopic"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"kafka/bin/kafka-console-consumer.sh  --topic linkis_spark_lineage_test --from-beginning --bootstrap-server localhost:9092\n")),(0,r.kt)("p",null,"\u8f93\u51fa\u7ed3\u679c\u5982\u4e0b:\n",(0,r.kt)("img",{alt:"spark-lineage-kafka",src:a(59705).Z,width:"1628",height:"367"})),(0,r.kt)("p",null,"\u8be6\u7ec6\u4fe1\u606f\u5982\u4e0b:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-json"},'{\n    "id":"3a0e2b8e-11dc-5bd1-9bbc-cfba2fa469e9",\n    "name":"Linkis-EngineConn-Spark_LINKISCLI",\n    "operations":{\n        "write":{\n            "outputSource":"/tmp/jsonWrite",\n            "append":false,\n            "id":"op-0",\n            "name":"InsertIntoHiveDirCommand",\n            "childIds":[\n                "op-1"\n            ],\n            "extra":{\n                "destinationType":"hive"\n            }\n        },\n        "reads":[\n            {\n                "inputSources":[\n                    "hdfs://linkishdfs/tmp/read.json"\n                ],\n                "id":"op-4",\n                "name":"LogicalRelation",\n                "output":[\n                    "attr-0",\n                    "attr-1"\n                ],\n                "params":{\n                    "path":"/tmp/read.json"\n                },\n                "extra":{\n                    "sourceType":"json"\n                }\n            }\n        ],\n        "other":[\n            {\n                "id":"op-3",\n                "name":"View",\n                "childIds":[\n                    "op-4"\n                ],\n                "output":[\n                    "attr-0",\n                    "attr-1"\n                ],\n                "params":{\n                    "desc":"CatalogTable(\\nTable: jsonReadTable\\nCreated Time: Tue Aug 29 14:48:06 CST 2023\\nLast Access: UNKNOWN\\nCreated By: Spark \\nType: VIEW\\nTable Properties: []\\nSchema: root\\n |-- age: string (nullable = true)\\n |-- name: string (nullable = true)\\n)",\n                    "isTempView":true\n                }\n            },\n            {\n                "id":"op-2",\n                "name":"SubqueryAlias",\n                "childIds":[\n                    "op-3"\n                ],\n                "output":[\n                    "attr-0",\n                    "attr-1"\n                ],\n                "params":{\n                    "identifier":"jsonreadtable"\n                }\n            },\n            {\n                "id":"op-1",\n                "name":"Project",\n                "childIds":[\n                    "op-2"\n                ],\n                "output":[\n                    "attr-0",\n                    "attr-1"\n                ],\n                "params":{\n                    "projectList":[\n                        {\n                            "__attrId":"attr-0"\n                        },\n                        {\n                            "__attrId":"attr-1"\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    "attributes":[\n        {\n            "id":"attr-0",\n            "dataType":"e63adadc-648a-56a0-9424-3289858cf0bb",\n            "name":"age"\n        },\n        {\n            "id":"attr-1",\n            "dataType":"e63adadc-648a-56a0-9424-3289858cf0bb",\n            "name":"name"\n        }\n    ],\n    "expressions":{\n\n    },\n    "systemInfo":{\n        "name":"spark",\n        "version":"3.2.1"\n    },\n    "agentInfo":{\n        "name":"spline",\n        "version":"2.0.0"\n    },\n    "extraInfo":{\n        "appName":"Linkis-EngineConn-Spark_LINKISCLI",\n        "dataTypes":[\n            {\n                "id":"e63adadc-648a-56a0-9424-3289858cf0bb",\n                "name":"string",\n                "nullable":true,\n                "_typeHint":"dt.Simple"\n            }\n        ]\n    }\n}\n')),(0,r.kt)("h2",{id:"5-\u66f4\u591a\u65b9\u5f0f"},"5. \u66f4\u591a\u65b9\u5f0f"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-text"},"`spline-spark-agent`\u8fd8\u652f\u6301\u66f4\u591a\u7684\u91c7\u96c6\u65b9\u5f0f\uff0c\u6bd4\u5982:Http\u3001Console,\u8bf7\u53c2\u8003\u5b98\u65b9\u6587\u6863\nhttps://github.com/AbsaOSS/spline-spark-agent/#configuration\n")))}u.isMDXComponent=!0},59705:(e,n,a)=>{a.d(n,{Z:()=>t});const t=a.p+"assets/images/spark-lineage-kafka-068606f3757638694ac31024ac1e22ac.png"},45908:(e,n,a)=>{a.d(n,{Z:()=>t});const t=a.p+"assets/images/spark-lineage-log-d9b6a49b9407a1376fc66fd44703a28b.png"}}]);